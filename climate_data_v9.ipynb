{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benxperia/Dissertation/blob/Climate/climate_data_v9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Integrated Climate Data Retrieval Script\n",
        "\n",
        "This script combines data from multiple climate data sources (NOAA, ERA5, MET Norway/Frost,\n",
        "SeNorge, NVE, CHELSA, and E-OBS) to create the most complete dataset possible for\n",
        "Norwegian glacier study sites.\n"
      ],
      "metadata": {
        "id": "K637tnjy2lQZ"
      },
      "id": "K637tnjy2lQZ"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install netCDF4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuP0A6ePx3Ml",
        "outputId": "3c37dbc1-be82-4c24-e618-74439c103881"
      },
      "id": "nuP0A6ePx3Ml",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting netCDF4\n",
            "  Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting cftime (from netCDF4)\n",
            "  Downloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4) (2025.4.26)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from netCDF4) (2.0.2)\n",
            "Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cftime, netCDF4\n",
            "Successfully installed cftime-1.6.4.post1 netCDF4-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import requests\n",
        "from scipy import stats\n",
        "import xarray as xr\n",
        "import netCDF4 as nc\n",
        "import zipfile\n",
        "import time\n",
        "import warnings\n",
        "import io\n",
        "from shapely.geometry import Point\n",
        "import json\n",
        "from urllib.parse import urlencode\n",
        "from google.colab import drive\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "hV60SK4Bvm5l"
      },
      "id": "hV60SK4Bvm5l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "aOMhu985vqCs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "089e6074-9b7c-4c47-d012-d94ffff65394"
      },
      "id": "aOMhu985vqCs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "OaAnETEtvtz6"
      },
      "id": "OaAnETEtvtz6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_glacier_sites(file_path):\n",
        "    try:\n",
        "        sites_df = pd.read_csv(file_path)\n",
        "        # Rename the first column to 'site_name'\n",
        "        sites_df = sites_df.rename(columns={sites_df.columns[0]: 'site_name'})\n",
        "        # Access latitude and longitude by column index (assuming they are in columns 1 and 2)\n",
        "        sites_df = sites_df.rename(columns={sites_df.columns[1]: 'latitude', sites_df.columns[2]: 'longitude'})\n",
        "        return sites_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading glacier sites: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def setup_cds_api():\n",
        "    \"\"\"\n",
        "    Setup Climate Data Store (CDS) API credentials.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    bool\n",
        "        True if setup was successful, False otherwise\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Install the CDS API client if needed\n",
        "        import os\n",
        "\n",
        "        # Check for API key file\n",
        "        cds_key_file = os.path.expanduser('~/.cdsapirc')\n",
        "        if os.path.exists(cds_key_file):\n",
        "            print(\"CDS API configuration file already exists.\")\n",
        "            # Force recreation\n",
        "            recreate = input(\"Would you like to recreate it? (y/n): \").lower() == 'y'\n",
        "            if not recreate:\n",
        "                return True\n",
        "\n",
        "        print(\"\\nCDS API configuration\")\n",
        "        print(\"Please register at https://cds.climate.copernicus.eu/user/register\")\n",
        "        print(\"Then go to https://cds.climate.copernicus.eu/api-how-to and copy your API key\")\n",
        "\n",
        "        url = input(\"Enter CDS API URL (default: https://cds.climate.copernicus.eu/api/v2): \")\n",
        "        if not url:\n",
        "            url = \"https://cds.climate.copernicus.eu/api/v2\"\n",
        "\n",
        "        key = input(\"Enter your CDS API key: \")\n",
        "\n",
        "        with open(cds_key_file, 'w') as f:\n",
        "            f.write(f\"url: {url}\\n\")\n",
        "            f.write(f\"key: {key}\\n\")\n",
        "\n",
        "        os.chmod(cds_key_file, 0o600)\n",
        "        print(f\"CDS API configuration saved to {cds_key_file}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error setting up CDS API: {str(e)}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "Um2yI6jHv1jp"
      },
      "id": "Um2yI6jHv1jp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_data_availability(sites_df, noaa_token=None, cds_setup=False, frost_client_id=None):\n",
        "    \"\"\"\n",
        "    Verify which variables are available from each data source for each site.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    sites_df : pandas.DataFrame\n",
        "        DataFrame with glacier site information\n",
        "    noaa_token : str, optional\n",
        "        NOAA API token\n",
        "    cds_setup : bool, optional\n",
        "        Whether CDS API is set up\n",
        "    frost_client_id : str, optional\n",
        "        MET Norway Frost API client ID\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    dict\n",
        "        Dictionary of availability by site and source\n",
        "    \"\"\"\n",
        "    availability = {}\n",
        "\n",
        "    for i, site in sites_df.iterrows():\n",
        "        site_name = site['site_name']\n",
        "        lat = site['latitude']\n",
        "        lon = site['longitude']\n",
        "\n",
        "        print(f\"Checking data availability for site: {site_name} ({lat}, {lon})\")\n",
        "\n",
        "        availability[site_name] = {\n",
        "            'noaa': {'available': False, 'variables': {}},\n",
        "            'era5': {'available': False, 'variables': {}},\n",
        "            'frost': {'available': False, 'variables': {}},\n",
        "            'senorge': {'available': False, 'variables': {}},\n",
        "            'nve': {'available': False, 'variables': {}},\n",
        "            'chelsa': {'available': False, 'variables': {}},\n",
        "            'eobs': {'available': False, 'variables': {}}\n",
        "        }\n",
        "\n",
        "        # Check NOAA availability if token provided\n",
        "        if noaa_token:\n",
        "            headers = {'token': noaa_token}\n",
        "            base_url = \"https://www.ncdc.noaa.gov/cdo-web/api/v2\"\n",
        "\n",
        "            # Find nearby stations\n",
        "            station_url = f\"{base_url}/stations\"\n",
        "            params = {\n",
        "                'extent': f\"{lat-1},{lon-1},{lat+1},{lon+1}\",\n",
        "                'limit': 1000\n",
        "            }\n",
        "\n",
        "            try:\n",
        "                print(f\"  Checking NOAA stations near {site_name}...\")\n",
        "                response = requests.get(station_url, headers=headers, params=params, timeout=30)\n",
        "                if response.status_code == 200:\n",
        "                    stations = response.json()\n",
        "                    if 'results' in stations and len(stations['results']) > 0:\n",
        "                        # Found stations, now check data types\n",
        "                        closest_station = min(\n",
        "                            stations['results'],\n",
        "                            key=lambda s: ((lat - float(s['latitude']))**2 + (lon - float(s['longitude']))**2)**0.5\n",
        "                        )\n",
        "                        station_id = closest_station['id']\n",
        "                        station_name = closest_station['name']\n",
        "                        station_lat = closest_station['latitude']\n",
        "                        station_lon = closest_station['longitude']\n",
        "\n",
        "                        print(f\"  Found station: {station_name} ({station_lat}, {station_lon})\")\n",
        "\n",
        "                        # Check for each data type with a small date range\n",
        "                        variables = ['PRCP', 'TMAX', 'TMIN', 'AWND', 'SNOW', 'SNWD', 'ACSH']\n",
        "\n",
        "                        for var in variables:\n",
        "                            data_url = f\"{base_url}/data\"\n",
        "                            # Just check most recent complete year\n",
        "                            current_year = datetime.now().year - 1\n",
        "                            data_params = {\n",
        "                                'datasetid': 'GHCND',\n",
        "                                'stationid': station_id,\n",
        "                                'startdate': f\"{current_year}-01-01\",\n",
        "                                'enddate': f\"{current_year}-12-31\",\n",
        "                                'datatypeid': var,\n",
        "                                'limit': 10\n",
        "                            }\n",
        "\n",
        "                            try:\n",
        "                                var_response = requests.get(data_url, headers=headers, params=data_params, timeout=30)\n",
        "                                if var_response.status_code == 200:\n",
        "                                    var_data = var_response.json()\n",
        "                                    if 'results' in var_data and var_data['results']:\n",
        "                                        availability[site_name]['noaa']['variables'][var] = True\n",
        "                                        print(f\"    Variable {var}: Available\")\n",
        "                                    else:\n",
        "                                        availability[site_name]['noaa']['variables'][var] = False\n",
        "                                        print(f\"    Variable {var}: Not available\")\n",
        "                                else:\n",
        "                                    availability[site_name]['noaa']['variables'][var] = False\n",
        "                                    print(f\"    Variable {var}: Not available (API error)\")\n",
        "                            except Exception as e:\n",
        "                                availability[site_name]['noaa']['variables'][var] = False\n",
        "                                print(f\"    Variable {var}: Error - {str(e)}\")\n",
        "\n",
        "                        availability[site_name]['noaa']['available'] = True\n",
        "                        availability[site_name]['noaa']['station_id'] = station_id\n",
        "                        availability[site_name]['noaa']['station_name'] = station_name\n",
        "                        availability[site_name]['noaa']['station_lat'] = station_lat\n",
        "                        availability[site_name]['noaa']['station_lon'] = station_lon\n",
        "                    else:\n",
        "                        print(f\"  No NOAA stations found near {site_name}\")\n",
        "                else:\n",
        "                    print(f\"  NOAA API error: {response.status_code} - {response.text}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Error checking NOAA data: {str(e)}\")\n",
        "\n",
        "        # Check ERA5 availability if CDS is set up\n",
        "        if cds_setup:\n",
        "            try:\n",
        "                print(f\"  Checking ERA5 data availability for {site_name}...\")\n",
        "                # ERA5 typically has global coverage, so we just need to verify API access\n",
        "                import cdsapi\n",
        "                try:\n",
        "                    c = cdsapi.Client()\n",
        "                    # Just check if the client can be initialized\n",
        "                    availability[site_name]['era5']['available'] = True\n",
        "                    availability[site_name]['era5']['variables'] = {\n",
        "                        't2m': True,  # Temperature\n",
        "                        'tp': True    # Precipitation\n",
        "                    }\n",
        "                    print(f\"  ERA5 data available for {site_name}\")\n",
        "                    print(f\"    Variable t2m (temperature): Available\")\n",
        "                    print(f\"    Variable tp (precipitation): Available\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  Error initializing CDS client: {str(e)}\")\n",
        "                    print(f\"  ERA5 data not available for {site_name} due to client initialization error\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Error checking ERA5 data: {str(e)}\")\n",
        "\n",
        "        # Check MET Norway Frost API availability\n",
        "        if frost_client_id:\n",
        "            try:\n",
        "                print(f\"  Checking MET Norway Frost data availability for {site_name}...\")\n",
        "\n",
        "                # Find nearby weather stations\n",
        "                stations_url = \"https://frost.met.no/sources/v0.jsonld\"\n",
        "                params = {\n",
        "                    'geometry': f'nearest(POINT({lon} {lat}))',\n",
        "                    'nearestmaxcount': 5,\n",
        "                    'types': 'SN',  # Standard Norwegian weather stations\n",
        "                }\n",
        "\n",
        "                r = requests.get(stations_url, params=params, auth=(frost_client_id, ''))\n",
        "\n",
        "                if r.status_code == 200:\n",
        "                    stations_data = r.json()\n",
        "\n",
        "                    if 'data' in stations_data and stations_data['data']:\n",
        "                        station = stations_data['data'][0]\n",
        "                        station_id = station['id']\n",
        "                        station_name = station['name']\n",
        "\n",
        "                        # Check which elements are available\n",
        "                        elements_url = f\"https://frost.met.no/observations/availableTimeSeries/v0.jsonld\"\n",
        "                        elements_params = {\n",
        "                            'sources': station_id\n",
        "                        }\n",
        "\n",
        "                        r = requests.get(elements_url, params=elements_params, auth=(frost_client_id, ''))\n",
        "\n",
        "                        if r.status_code == 200:\n",
        "                            elements_data = r.json()\n",
        "\n",
        "                            # Map element codes to more readable names\n",
        "                            element_mapping = {\n",
        "                                'air_temperature': 'temperature',\n",
        "                                'mean(air_temperature P1D)': 'mean_temperature',\n",
        "                                'min(air_temperature P1D)': 'min_temperature',\n",
        "                                'max(air_temperature P1D)': 'max_temperature',\n",
        "                                'sum(precipitation_amount P1D)': 'precipitation',\n",
        "                                'snow_depth': 'snow_depth',\n",
        "                                'wind_speed': 'wind_speed',\n",
        "                                'max(wind_speed P1D)': 'max_wind_speed'\n",
        "                            }\n",
        "\n",
        "                            # Check each relevant element\n",
        "                            if 'data' in elements_data:\n",
        "                                found_elements = set()\n",
        "                                for item in elements_data['data']:\n",
        "                                    element_id = item.get('elementId')\n",
        "                                    if element_id in element_mapping:\n",
        "                                        found_elements.add(element_id)\n",
        "\n",
        "                                for element_id, variable_name in element_mapping.items():\n",
        "                                    if element_id in found_elements:\n",
        "                                        availability[site_name]['frost']['variables'][variable_name] = True\n",
        "                                        print(f\"    Variable {variable_name}: Available\")\n",
        "                                    else:\n",
        "                                        availability[site_name]['frost']['variables'][variable_name] = False\n",
        "                                        print(f\"    Variable {variable_name}: Not available\")\n",
        "\n",
        "                            availability[site_name]['frost']['available'] = True\n",
        "                            availability[site_name]['frost']['station_id'] = station_id\n",
        "                            availability[site_name]['frost']['station_name'] = station_name\n",
        "                    else:\n",
        "                        print(f\"  No Frost stations found near {site_name}\")\n",
        "                else:\n",
        "                    print(f\"  Frost API error: {r.status_code} - {r.text}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Error checking Frost data: {str(e)}\")\n",
        "\n",
        "        # Check SeNorge data availability - This is a gridded product covering all of Norway\n",
        "        # so it should be available for all Norwegian sites\n",
        "        try:\n",
        "            print(f\"  Checking SeNorge data availability for {site_name}...\")\n",
        "\n",
        "            # SeNorge data is available via Thredds\n",
        "            # For simplicity, we'll just check if the site is within Norway's bounding box\n",
        "            norway_bounds = {\n",
        "                'min_lat': 57.5,\n",
        "                'max_lat': 71.5,\n",
        "                'min_lon': 4.0,\n",
        "                'max_lon': 31.5\n",
        "            }\n",
        "\n",
        "            if (norway_bounds['min_lat'] <= lat <= norway_bounds['max_lat'] and\n",
        "                norway_bounds['min_lon'] <= lon <= norway_bounds['max_lon']):\n",
        "\n",
        "                availability[site_name]['senorge']['available'] = True\n",
        "                availability[site_name]['senorge']['variables'] = {\n",
        "                    'temperature': True,\n",
        "                    'precipitation': True,\n",
        "                    'snow_depth': True\n",
        "                }\n",
        "\n",
        "                print(f\"  SeNorge data available for {site_name}\")\n",
        "                print(f\"    Variable temperature: Available\")\n",
        "                print(f\"    Variable precipitation: Available\")\n",
        "                print(f\"    Variable snow_depth: Available\")\n",
        "            else:\n",
        "                print(f\"  SeNorge data not available for {site_name} (outside Norway)\")\n",
        "        except Exception as e:\n",
        "            print(f\"  Error checking SeNorge data: {str(e)}\")\n",
        "\n",
        "        # Check NVE glacier data availability - This requires knowing the glacier name\n",
        "        try:\n",
        "            print(f\"  Checking NVE glacier data availability for {site_name}...\")\n",
        "\n",
        "            # For simplicity, we'll just check if we can access the NVE API\n",
        "            # In a real scenario, you would search for the specific glacier by name\n",
        "            nve_api_url = \"https://api.nve.no/hydrology/glacier\"\n",
        "\n",
        "            try:\n",
        "                # Try to access the API\n",
        "                r = requests.get(nve_api_url, timeout=10)\n",
        "\n",
        "                if r.status_code == 200:\n",
        "                    availability[site_name]['nve']['available'] = True\n",
        "                    availability[site_name]['nve']['variables'] = {\n",
        "                        'mass_balance': True,\n",
        "                        'length_change': True,\n",
        "                        'terminus_position': True\n",
        "                    }\n",
        "\n",
        "                    print(f\"  NVE glacier data API is accessible\")\n",
        "                    print(f\"    Variable mass_balance: Available (if glacier is monitored)\")\n",
        "                    print(f\"    Variable length_change: Available (if glacier is monitored)\")\n",
        "                    print(f\"    Variable terminus_position: Available (if glacier is monitored)\")\n",
        "                else:\n",
        "                    print(f\"  NVE API error: {r.status_code}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Cannot access NVE API: {str(e)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  Error checking NVE data: {str(e)}\")\n",
        "\n",
        "        # Check CHELSA data availability - Global coverage\n",
        "        try:\n",
        "            print(f\"  Checking CHELSA data availability for {site_name}...\")\n",
        "\n",
        "            # CHELSA is a global dataset, so it should be available for all sites\n",
        "            # We'll just check if we can access the API\n",
        "            chelsa_url = \"https://chelsa-climate.org/downloads/\"\n",
        "\n",
        "            try:\n",
        "                # Try to access the website\n",
        "                r = requests.get(chelsa_url, timeout=10)\n",
        "\n",
        "                if r.status_code == 200:\n",
        "                    availability[site_name]['chelsa']['available'] = True\n",
        "                    availability[site_name]['chelsa']['variables'] = {\n",
        "                        'temperature': True,\n",
        "                        'precipitation': True\n",
        "                    }\n",
        "\n",
        "                    print(f\"  CHELSA data available for {site_name}\")\n",
        "                    print(f\"    Variable temperature: Available\")\n",
        "                    print(f\"    Variable precipitation: Available\")\n",
        "                else:\n",
        "                    print(f\"  CHELSA website error: {r.status_code}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Cannot access CHELSA website: {str(e)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  Error checking CHELSA data: {str(e)}\")\n",
        "\n",
        "        # Check E-OBS data availability - European coverage\n",
        "        try:\n",
        "            print(f\"  Checking E-OBS data availability for {site_name}...\")\n",
        "\n",
        "            # E-OBS covers Europe, so check if site is within Europe's bounding box\n",
        "            europe_bounds = {\n",
        "                'min_lat': 25.0,\n",
        "                'max_lat': 75.0,\n",
        "                'min_lon': -25.0,\n",
        "                'max_lon': 45.0\n",
        "            }\n",
        "\n",
        "            if (europe_bounds['min_lat'] <= lat <= europe_bounds['max_lat'] and\n",
        "                europe_bounds['min_lon'] <= lon <= europe_bounds['max_lon']):\n",
        "\n",
        "                availability[site_name]['eobs']['available'] = True\n",
        "                availability[site_name]['eobs']['variables'] = {\n",
        "                    'temperature': True,\n",
        "                    'precipitation': True\n",
        "                }\n",
        "\n",
        "                print(f\"  E-OBS data available for {site_name}\")\n",
        "                print(f\"    Variable temperature: Available\")\n",
        "                print(f\"    Variable precipitation: Available\")\n",
        "            else:\n",
        "                print(f\"  E-OBS data not available for {site_name} (outside Europe)\")\n",
        "        except Exception as e:\n",
        "            print(f\"  Error checking E-OBS data: {str(e)}\")\n",
        "\n",
        "    return availability"
      ],
      "metadata": {
        "id": "0bzF4nfEwNwx"
      },
      "id": "0bzF4nfEwNwx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_frost_data(sites_df, availability, client_id, start_year=1970, end_year=None, output_dir=\"/content/climate_outputs\"):\n",
        "    \"\"\"\n",
        "    Fetch data from the Norwegian Meteorological Institute's Frost API.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    sites_df : pandas.DataFrame\n",
        "        DataFrame with glacier site information\n",
        "    availability : dict\n",
        "        Dictionary of availability by site and source\n",
        "    client_id : str\n",
        "        Frost API client ID\n",
        "    start_year : int, optional\n",
        "        Start year for data retrieval\n",
        "    end_year : int, optional\n",
        "        End year for data retrieval\n",
        "    output_dir : str, optional\n",
        "        Directory to save output files\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    dict\n",
        "        Dictionary with Frost climate data for each site\n",
        "    \"\"\"\n",
        "    if end_year is None:\n",
        "        end_year = datetime.now().year\n",
        "\n",
        "    frost_results = {}\n",
        "\n",
        "    # Create output directory for raw data\n",
        "    frost_dir = f\"{output_dir}/frost\"\n",
        "    os.makedirs(frost_dir, exist_ok=True)\n",
        "\n",
        "    for i, site in sites_df.iterrows():\n",
        "        site_name = site['site_name']\n",
        "        lat = site['latitude']\n",
        "        lon = site['longitude']\n",
        "\n",
        "        if not availability[site_name]['frost']['available']:\n",
        "            print(f\"Frost data not available for {site_name}, skipping...\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Fetching Frost data for site: {site_name} ({lat}, {lon})\")\n",
        "\n",
        "        station_id = availability[site_name]['frost']['station_id']\n",
        "        station_name = availability[site_name]['frost']['station_name']\n",
        "\n",
        "        frost_results[site_name] = {\n",
        "            'station_info': {\n",
        "                'id': station_id,\n",
        "                'name': station_name\n",
        "            },\n",
        "            'data': {}\n",
        "        }\n",
        "\n",
        "        # Define the elements to retrieve based on availability\n",
        "        available_elements = [elem for elem, is_available in\n",
        "                            availability[site_name]['frost']['variables'].items()\n",
        "                            if is_available]\n",
        "\n",
        "        # Map variable names to Frost element IDs\n",
        "        element_mapping = {\n",
        "            'temperature': 'air_temperature',\n",
        "            'mean_temperature': 'mean(air_temperature P1D)',\n",
        "            'min_temperature': 'min(air_temperature P1D)',\n",
        "            'max_temperature': 'max(air_temperature P1D)',\n",
        "            'precipitation': 'sum(precipitation_amount P1D)',\n",
        "            'snow_depth': 'snow_depth',\n",
        "            'wind_speed': 'wind_speed',\n",
        "            'max_wind_speed': 'max(wind_speed P1D)'\n",
        "        }\n",
        "\n",
        "        # Get the corresponding Frost element IDs\n",
        "        elements = [element_mapping[elem] for elem in available_elements if elem in element_mapping]\n",
        "\n",
        "        if not elements:\n",
        "            print(f\"  No available elements for {site_name}, skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Join elements with comma\n",
        "        elements_str = ','.join(elements)\n",
        "\n",
        "        # Fetch data for each year (to avoid timeout issues)\n",
        "        for year in range(start_year, end_year + 1):\n",
        "            try:\n",
        "                # Define the time range for this year\n",
        "                from_date = f\"{year}-01-01\"\n",
        "                to_date = f\"{year}-12-31\"\n",
        "\n",
        "                print(f\"  Fetching data for year {year}...\")\n",
        "\n",
        "                # Set up the API request\n",
        "                url = \"https://frost.met.no/observations/v0.jsonld\"\n",
        "                params = {\n",
        "                    'sources': station_id,\n",
        "                    'elements': elements_str,\n",
        "                    'referencetime': f\"{from_date}/{to_date}\",\n",
        "                    'timeresolution': 'P1D',  # Daily data\n",
        "                    'fields': 'value,elementId,unit,referenceTime'\n",
        "                }\n",
        "\n",
        "                # Make the request\n",
        "                r = requests.get(url, params=params, auth=(client_id, ''))\n",
        "\n",
        "                if r.status_code == 200:\n",
        "                    data = r.json()\n",
        "\n",
        "                    if 'data' in data:\n",
        "                        # Store the data\n",
        "                        frost_results[site_name]['data'][year] = data['data']\n",
        "                        print(f\"    Retrieved {len(data['data'])} records\")\n",
        "                    else:\n",
        "                        print(f\"    No data returned for {year}\")\n",
        "                else:\n",
        "                    print(f\"    API error for {year}: {r.status_code} - {r.text}\")\n",
        "            except Exception as e:\n",
        "                print(f\"    Error fetching data for {year}: {str(e)}\")\n",
        "\n",
        "            # Add a small delay to avoid rate limiting\n",
        "            time.sleep(0.5)\n",
        "\n",
        "        # Convert to DataFrame for easier processing\n",
        "        all_data = []\n",
        "        for year, year_data in frost_results[site_name]['data'].items():\n",
        "            for obs in year_data:\n",
        "                for obs_data in obs.get('observations', []):\n",
        "                    record = {\n",
        "                        'date': obs.get('referenceTime'),\n",
        "                        'element': obs_data.get('elementId'),\n",
        "                        'value': obs_data.get('value'),\n",
        "                        'unit': obs_data.get('unit')\n",
        "                    }\n",
        "                    all_data.append(record)\n",
        "\n",
        "        df = pd.DataFrame(all_data)\n",
        "\n",
        "        # Save raw data\n",
        "        if not df.empty:\n",
        "            raw_file = f\"{frost_dir}/{site_name}_frost_raw.csv\"\n",
        "            df.to_csv(raw_file, index=False)\n",
        "            print(f\"  Raw Frost data saved to: {raw_file}\")\n",
        "\n",
        "            # Store the DataFrame\n",
        "            frost_results[site_name]['dataframe'] = df\n",
        "\n",
        "    return frost_results"
      ],
      "metadata": {
        "id": "KLh50TGC3JCl"
      },
      "id": "KLh50TGC3JCl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_senorge_data(sites_df, availability, start_year=1970, end_year=None, output_dir=\"/content/climate_outputs\"):\n",
        "    if end_year is None:\n",
        "        end_year = datetime.now().year\n",
        "\n",
        "    senorge_results = {}\n",
        "\n",
        "    # Create output directory for raw data\n",
        "    senorge_dir = f\"{output_dir}/senorge\"\n",
        "    os.makedirs(senorge_dir, exist_ok=True)\n",
        "\n",
        "    for i, site in sites_df.iterrows():\n",
        "        site_name = site['site_name']\n",
        "        lat = site['latitude']\n",
        "        lon = site['longitude']\n",
        "\n",
        "        if not availability[site_name]['senorge']['available']:\n",
        "            print(f\"SeNorge data not available for {site_name}, skipping...\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Fetching SeNorge data for site: {site_name} ({lat}, {lon})\")\n",
        "\n",
        "        senorge_results[site_name] = {\n",
        "            'temperature': {},\n",
        "            'precipitation': {},\n",
        "            'snow_depth': {}\n",
        "        }\n",
        "\n",
        "        # SeNorge data is accessible through Thredds\n",
        "        # For each variable, we need to access a different dataset\n",
        "\n",
        "        # Before trying to access the Thredds server\n",
        "        print(f\"\\n==== DEBUGGING: Accessing SeNorge data for {site_name} ====\")\n",
        "        try:\n",
        "            # Create a test request to the Thredds server\n",
        "            thredds_test_url = \"https://thredds.met.no/thredds/catalog.html\"\n",
        "            print(f\"  Testing connection to Thredds server: {thredds_test_url}\")\n",
        "            test_response = requests.get(thredds_test_url, timeout=10)\n",
        "            print(f\"  Connection test status code: {test_response.status_code}\")\n",
        "\n",
        "            # When constructing the data URL\n",
        "            base_url = \"https://thredds.met.no/thredds/dodsC/senorge/seNorge_2018/Archive\"\n",
        "            print(f\"  Attempting to access SeNorge base URL: {base_url}\")\n",
        "\n",
        "            # After retrieving data (or simulating it)\n",
        "            print(f\"  SeNorge data processing complete\")\n",
        "        except Exception as e:\n",
        "            print(f\"  Exception during SeNorge data access: {str(e)}\")\n",
        "            print(f\"  Exception type: {type(e).__name__}\")\n",
        "\n",
        "        # Temperature data\n",
        "        if availability[site_name]['senorge']['variables'].get('temperature', False):\n",
        "            print(f\"  Fetching temperature data...\")\n",
        "\n",
        "            try:\n",
        "                # Using newer seNorge2018 dataset\n",
        "                base_url = \"https://thredds.met.no/thredds/dodsC/senorge/seNorge_2018/Archive/daily-mean-temperature\"\n",
        "\n",
        "                # Create a list to store annual data\n",
        "                temp_data = []\n",
        "\n",
        "                for year in range(start_year, end_year + 1):\n",
        "                    try:\n",
        "                        print(f\"    Processing year {year}...\")\n",
        "                        url = f\"{base_url}/{year}/seNorge2018_temperature_{year}.nc\"\n",
        "\n",
        "                        # Open the dataset\n",
        "                        ds = xr.open_dataset(url)\n",
        "\n",
        "                        # Extract data for the site location\n",
        "                        # seNorge uses a different coordinate system, so we need to convert\n",
        "                        # For simplicity, we'll use the nearest grid point\n",
        "                        site_data = ds.sel(longitude=lon, latitude=lat, method='nearest')\n",
        "\n",
        "                        # Convert to DataFrame\n",
        "                        df = site_data['tm'].to_dataframe().reset_index()\n",
        "\n",
        "                        # Add to our list\n",
        "                        temp_data.append(df)\n",
        "\n",
        "                        # Close the dataset\n",
        "                        ds.close()\n",
        "                    except Exception as e:\n",
        "                        print(f\"    Error processing temperature data for {year}: {str(e)}\")\n",
        "\n",
        "                if temp_data:\n",
        "                    # Combine all years\n",
        "                    temp_df = pd.concat(temp_data)\n",
        "\n",
        "                    # Save to file\n",
        "                    temp_file = f\"{senorge_dir}/{site_name}_senorge_temperature.csv\"\n",
        "                    temp_df.to_csv(temp_file, index=False)\n",
        "                    print(f\"  Temperature data saved to: {temp_file}\")\n",
        "\n",
        "                    # Store in results\n",
        "                    senorge_results[site_name]['temperature'] = temp_df\n",
        "            except Exception as e:\n",
        "                print(f\"  Error fetching temperature data: {str(e)}\")\n",
        "\n",
        "        # Precipitation data\n",
        "        if availability[site_name]['senorge']['variables'].get('precipitation', False):\n",
        "            print(f\"  Fetching precipitation data...\")\n",
        "\n",
        "            try:\n",
        "                # Using newer seNorge2018 dataset\n",
        "                base_url = \"https://thredds.met.no/thredds/dodsC/senorge/seNorge_2018/Archive/daily-total-precipitation\"\n",
        "\n",
        "                # Create a list to store annual data\n",
        "                precip_data = []\n",
        "\n",
        "                for year in range(start_year, end_year + 1):\n",
        "                    try:\n",
        "                        print(f\"    Processing year {year}...\")\n",
        "                        url = f\"{base_url}/{year}/seNorge2018_precipitation_{year}.nc\"\n",
        "\n",
        "                        # Open the dataset\n",
        "                        ds = xr.open_dataset(url)\n",
        "\n",
        "                        # Extract data for the site location\n",
        "                        site_data = ds.sel(longitude=lon, latitude=lat, method='nearest')\n",
        "\n",
        "                        # Convert to DataFrame\n",
        "                        df = site_data['rr'].to_dataframe().reset_index()\n",
        "\n",
        "                        # Add to our list\n",
        "                        precip_data.append(df)\n",
        "\n",
        "                        # Close the dataset\n",
        "                        ds.close()\n",
        "                    except Exception as e:\n",
        "                        print(f\"    Error processing precipitation data for {year}: {str(e)}\")\n",
        "\n",
        "                if precip_data:\n",
        "                    # Combine all years\n",
        "                    precip_df = pd.concat(precip_data)\n",
        "\n",
        "                    # Save to file\n",
        "                    precip_file = f\"{senorge_dir}/{site_name}_senorge_precipitation.csv\"\n",
        "                    precip_df.to_csv(precip_file, index=False)\n",
        "                    print(f\"  Precipitation data saved to: {precip_file}\")\n",
        "\n",
        "                    # Store in results\n",
        "                    senorge_results[site_name]['precipitation'] = precip_df\n",
        "            except Exception as e:\n",
        "                print(f\"  Error fetching precipitation data: {str(e)}\")\n",
        "\n",
        "        # Snow depth data\n",
        "        if availability[site_name]['senorge']['variables'].get('snow_depth', False):\n",
        "            print(f\"  Fetching snow depth data...\")\n",
        "\n",
        "            try:\n",
        "                # Using newer seNorge2018 dataset\n",
        "                base_url = \"https://thredds.met.no/thredds/dodsC/senorge/seNorge_2018/Archive/daily-snow-depth\"\n",
        "\n",
        "                # Create a list to store annual data\n",
        "                snow_data = []\n",
        "\n",
        "                for year in range(start_year, end_year + 1):\n",
        "                    try:\n",
        "                        print(f\"    Processing year {year}...\")\n",
        "                        url = f\"{base_url}/{year}/seNorge2018_snowdepth_{year}.nc\"\n",
        "\n",
        "                        # Open the dataset\n",
        "                        ds = xr.open_dataset(url)\n",
        "\n",
        "                        # Extract data for the site location\n",
        "                        site_data = ds.sel(longitude=lon, latitude=lat, method='nearest')\n",
        "\n",
        "                        # Convert to DataFrame\n",
        "                        df = site_data['sd'].to_dataframe().reset_index()\n",
        "\n",
        "                        # Add to our list\n",
        "                        snow_data.append(df)\n",
        "\n",
        "                        # Close the dataset\n",
        "                        ds.close()\n",
        "                    except Exception as e:\n",
        "                        print(f\"    Error processing snow depth data for {year}: {str(e)}\")\n",
        "\n",
        "                if snow_data:\n",
        "                    # Combine all years\n",
        "                    snow_df = pd.concat(snow_data)\n",
        "\n",
        "                    # Save to file\n",
        "                    snow_file = f\"{senorge_dir}/{site_name}_senorge_snow_depth.csv\"\n",
        "                    snow_df.to_csv(snow_file, index=False)\n",
        "                    print(f\"  Snow depth data saved to: {snow_file}\")\n",
        "\n",
        "                    # Store in results\n",
        "                    senorge_results[site_name]['snow_depth'] = snow_df\n",
        "            except Exception as e:\n",
        "                print(f\"  Error fetching snow depth data: {str(e)}\")\n",
        "\n",
        "    return senorge_results"
      ],
      "metadata": {
        "id": "H8_n5I9h3M_G"
      },
      "id": "H8_n5I9h3M_G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_nve_glacier_data(sites_df, availability, start_year=1970, end_year=None, output_dir=\"/content/climate_outputs\"):\n",
        "    \"\"\"\n",
        "    Fetch glacier-specific data from NVE's glacier database.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    sites_df : pandas.DataFrame\n",
        "        DataFrame with glacier site information\n",
        "    availability : dict\n",
        "        Dictionary of availability by site and source\n",
        "    start_year : int, optional\n",
        "        Start year for data retrieval\n",
        "    end_year : int, optional\n",
        "        End year for data retrieval\n",
        "    output_dir : str, optional\n",
        "        Directory to save output files\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    dict\n",
        "        Dictionary with NVE glacier data for each site\n",
        "    \"\"\"\n",
        "    if end_year is None:\n",
        "        end_year = datetime.now().year\n",
        "\n",
        "    nve_results = {}\n",
        "\n",
        "    # Create output directory for raw data\n",
        "    nve_dir = f\"{output_dir}/nve\"\n",
        "    os.makedirs(nve_dir, exist_ok=True)\n",
        "\n",
        "    for i, site in sites_df.iterrows():\n",
        "        site_name = site['site_name']\n",
        "\n",
        "        if not availability[site_name]['nve']['available']:\n",
        "            print(f\"NVE glacier data not available for {site_name}, skipping...\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Fetching NVE glacier data for site: {site_name}\")\n",
        "\n",
        "        nve_results[site_name] = {\n",
        "            'mass_balance': None,\n",
        "            'length_change': None,\n",
        "            'terminus_position': None\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Search for glacier by name\n",
        "            # Note: The actual NVE API might have a different structure\n",
        "            search_url = f\"https://api.nve.no/hydrology/glacier/search?name={site_name}\"\n",
        "\n",
        "            r = requests.get(search_url)\n",
        "\n",
        "            if r.status_code == 200:\n",
        "                search_data = r.json()\n",
        "\n",
        "                if search_data and len(search_data) > 0:\n",
        "                    # Found a matching glacier\n",
        "                    glacier_id = search_data[0]['id']\n",
        "                    glacier_name = search_data[0]['name']\n",
        "\n",
        "                    print(f\"  Found glacier: {glacier_name} (ID: {glacier_id})\")\n",
        "\n",
        "                    # Get mass balance data\n",
        "                    if availability[site_name]['nve']['variables'].get('mass_balance', False):\n",
        "                        balance_url = f\"https://api.nve.no/hydrology/glacier/{glacier_id}/massbalance?from={start_year}&to={end_year}\"\n",
        "\n",
        "                        r = requests.get(balance_url)\n",
        "\n",
        "                        if r.status_code == 200:\n",
        "                            balance_data = r.json()\n",
        "\n",
        "                            # Convert to DataFrame\n",
        "                            if balance_data:\n",
        "                                balance_df = pd.DataFrame(balance_data)\n",
        "\n",
        "                                # Save to file\n",
        "                                balance_file = f\"{nve_dir}/{site_name}_nve_mass_balance.csv\"\n",
        "                                balance_df.to_csv(balance_file, index=False)\n",
        "                                print(f\"  Mass balance data saved to: {balance_file}\")\n",
        "\n",
        "                                # Store in results\n",
        "                                nve_results[site_name]['mass_balance'] = balance_df\n",
        "\n",
        "                    # Get length change data\n",
        "                    if availability[site_name]['nve']['variables'].get('length_change', False):\n",
        "                        length_url = f\"https://api.nve.no/hydrology/glacier/{glacier_id}/length?from={start_year}&to={end_year}\"\n",
        "\n",
        "                        r = requests.get(length_url)\n",
        "\n",
        "                        if r.status_code == 200:\n",
        "                            length_data = r.json()\n",
        "\n",
        "                            # Convert to DataFrame\n",
        "                            if length_data:\n",
        "                                length_df = pd.DataFrame(length_data)\n",
        "\n",
        "                                # Save to file\n",
        "                                length_file = f\"{nve_dir}/{site_name}_nve_length_change.csv\"\n",
        "                                length_df.to_csv(length_file, index=False)\n",
        "                                print(f\"  Length change data saved to: {length_file}\")\n",
        "\n",
        "                                # Store in results\n",
        "                                nve_results[site_name]['length_change'] = length_df\n",
        "\n",
        "                    # Get terminus position data\n",
        "                    if availability[site_name]['nve']['variables'].get('terminus_position', False):\n",
        "                        terminus_url = f\"https://api.nve.no/hydrology/glacier/{glacier_id}/terminus?from={start_year}&to={end_year}\"\n",
        "\n",
        "                        r = requests.get(terminus_url)\n",
        "\n",
        "                        if r.status_code == 200:\n",
        "                            terminus_data = r.json()\n",
        "\n",
        "                            # Convert to DataFrame\n",
        "                            if terminus_data:\n",
        "                                terminus_df = pd.DataFrame(terminus_data)\n",
        "\n",
        "                                # Save to file\n",
        "                                terminus_file = f\"{nve_dir}/{site_name}_nve_terminus_position.csv\"\n",
        "                                terminus_df.to_csv(terminus_file, index=False)\n",
        "                                print(f\"  Terminus position data saved to: {terminus_file}\")\n",
        "\n",
        "                                # Store in results\n",
        "                                nve_results[site_name]['terminus_position'] = terminus_df\n",
        "                else:\n",
        "                    print(f\"  No matching glacier found for {site_name}\")\n",
        "            else:\n",
        "                print(f\"  API error: {r.status_code} - {r.text}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  Error fetching NVE data: {str(e)}\")\n",
        "\n",
        "    return nve_results"
      ],
      "metadata": {
        "id": "3OAjUAB83a0t"
      },
      "id": "3OAjUAB83a0t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_chelsa_data(sites_df, availability, output_dir=\"/content/climate_outputs\"):\n",
        "    \"\"\"\n",
        "    Fetch climate data from CHELSA dataset.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    sites_df : pandas.DataFrame\n",
        "        DataFrame with glacier site information\n",
        "    availability : dict\n",
        "        Dictionary of availability by site and source\n",
        "    output_dir : str, optional\n",
        "        Directory to save output files\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    dict\n",
        "        Dictionary with CHELSA climate data for each site\n",
        "    \"\"\"\n",
        "    chelsa_results = {}\n",
        "\n",
        "    # Create output directory for raw data\n",
        "    chelsa_dir = f\"{output_dir}/chelsa\"\n",
        "    os.makedirs(chelsa_dir, exist_ok=True)\n",
        "\n",
        "    # CHELSA V2.1 uses 1981-2010 as the reference period\n",
        "    reference_period = \"1981-2010\"\n",
        "\n",
        "    for i, site in sites_df.iterrows():\n",
        "        site_name = site['site_name']\n",
        "        lat = site['latitude']\n",
        "        lon = site['longitude']\n",
        "\n",
        "        if not availability[site_name]['chelsa']['available']:\n",
        "            print(f\"CHELSA data not available for {site_name}, skipping...\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Fetching CHELSA data for site: {site_name} ({lat}, {lon})\")\n",
        "\n",
        "        chelsa_results[site_name] = {\n",
        "            'temperature': None,\n",
        "            'precipitation': None\n",
        "        }\n",
        "\n",
        "        # Temperature data\n",
        "        if availability[site_name]['chelsa']['variables'].get('temperature', False):\n",
        "            print(f\"  Fetching temperature data...\")\n",
        "\n",
        "            try:\n",
        "                # CHELSA temperature data for all 12 months\n",
        "                temp_data = []\n",
        "\n",
        "                for month in range(1, 13):\n",
        "                    try:\n",
        "                        # CHELSA v2.1 URL pattern for temperature\n",
        "                        url = f\"https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/tas/CHELSA_tas_V2.1_{reference_period}_mean_{month:02d}.tif\"\n",
        "\n",
        "                        # Use rasterio to read the GeoTIFF\n",
        "                        import rasterio\n",
        "\n",
        "                        # Download the file to a temporary location\n",
        "                        temp_file = f\"temp_chelsa_tas_{month:02d}.tif\"\n",
        "\n",
        "                        r = requests.get(url, stream=True)\n",
        "                        if r.status_code == 200:\n",
        "                            with open(temp_file, 'wb') as f:\n",
        "                                for chunk in r.iter_content(chunk_size=8192):\n",
        "                                    if chunk:\n",
        "                                        f.write(chunk)\n",
        "\n",
        "                            # Open the file with rasterio\n",
        "                            with rasterio.open(temp_file) as src:\n",
        "                                # Get the value at the site location\n",
        "                                val = list(src.sample([(lon, lat)]))[0][0]\n",
        "\n",
        "                                # CHELSA temperature is in °C * 10\n",
        "                                val = val / 10 if val != src.nodata else np.nan\n",
        "\n",
        "                                # Add to our data\n",
        "                                temp_data.append({\n",
        "                                    'month': month,\n",
        "                                    'temperature': val\n",
        "                                })\n",
        "\n",
        "                            # Remove temporary file\n",
        "                            os.remove(temp_file)\n",
        "                    except Exception as e:\n",
        "                        print(f\"    Error processing temperature data for month {month}: {str(e)}\")\n",
        "\n",
        "                if temp_data:\n",
        "                    # Convert to DataFrame\n",
        "                    temp_df = pd.DataFrame(temp_data)\n",
        "\n",
        "                    # Save to file\n",
        "                    temp_file = f\"{chelsa_dir}/{site_name}_chelsa_temperature.csv\"\n",
        "                    temp_df.to_csv(temp_file, index=False)\n",
        "                    print(f\"  Temperature data saved to: {temp_file}\")\n",
        "\n",
        "                    # Store in results\n",
        "                    chelsa_results[site_name]['temperature'] = temp_df\n",
        "            except Exception as e:\n",
        "                print(f\"  Error fetching temperature data: {str(e)}\")\n",
        "\n",
        "        # Precipitation data\n",
        "        if availability[site_name]['chelsa']['variables'].get('precipitation', False):\n",
        "            print(f\"  Fetching precipitation data...\")\n",
        "\n",
        "            try:\n",
        "                # CHELSA precipitation data for all 12 months\n",
        "                precip_data = []\n",
        "\n",
        "                for month in range(1, 13):\n",
        "                    try:\n",
        "                        # CHELSA v2.1 URL pattern for precipitation\n",
        "                        url = f\"https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/pr/CHELSA_pr_V2.1_{reference_period}_mean_{month:02d}.tif\"\n",
        "\n",
        "                        # Use rasterio to read the GeoTIFF\n",
        "                        import rasterio\n",
        "\n",
        "                        # Download the file to a temporary location\n",
        "                        temp_file = f\"temp_chelsa_pr_{month:02d}.tif\"\n",
        "\n",
        "                        r = requests.get(url, stream=True)\n",
        "                        if r.status_code == 200:\n",
        "                            with open(temp_file, 'wb') as f:\n",
        "                                for chunk in r.iter_content(chunk_size=8192):\n",
        "                                    if chunk:\n",
        "                                        f.write(chunk)\n",
        "\n",
        "                            # Open the file with rasterio\n",
        "                            with rasterio.open(temp_file) as src:\n",
        "                                # Get the value at the site location\n",
        "                                val = list(src.sample([(lon, lat)]))[0][0]\n",
        "\n",
        "                                # Add to our data\n",
        "                                precip_data.append({\n",
        "                                    'month': month,\n",
        "                                    'precipitation': val\n",
        "                                })\n",
        "\n",
        "                            # Remove temporary file\n",
        "                            os.remove(temp_file)\n",
        "                    except Exception as e:\n",
        "                        print(f\"    Error processing precipitation data for month {month}: {str(e)}\")\n",
        "\n",
        "                if precip_data:\n",
        "                    # Convert to DataFrame\n",
        "                    precip_df = pd.DataFrame(precip_data)\n",
        "\n",
        "                    # Save to file\n",
        "                    precip_file = f\"{chelsa_dir}/{site_name}_chelsa_precipitation.csv\"\n",
        "                    precip_df.to_csv(precip_file, index=False)\n",
        "                    print(f\"  Precipitation data saved to: {precip_file}\")\n",
        "\n",
        "                    # Store in results\n",
        "                    chelsa_results[site_name]['precipitation'] = precip_df\n",
        "            except Exception as e:\n",
        "                print(f\"  Error fetching precipitation data: {str(e)}\")\n",
        "\n",
        "    return chelsa_results"
      ],
      "metadata": {
        "id": "aFBIAxEF3gZg"
      },
      "id": "aFBIAxEF3gZg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_eobs_data(sites_df, availability, start_year=1970, end_year=None, output_dir=\"/content/climate_outputs\"):\n",
        "    \"\"\"\n",
        "    Fetch climate data from E-OBS gridded dataset.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    sites_df : pandas.DataFrame\n",
        "        DataFrame with glacier site information\n",
        "    availability : dict\n",
        "        Dictionary of availability by site and source\n",
        "    start_year : int, optional\n",
        "        Start year for data retrieval\n",
        "    end_year : int, optional\n",
        "        End year for data retrieval\n",
        "    output_dir : str, optional\n",
        "        Directory to save output files\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    dict\n",
        "        Dictionary with E-OBS climate data for each site\n",
        "    \"\"\"\n",
        "    if end_year is None:\n",
        "        end_year = datetime.now().year\n",
        "\n",
        "    eobs_results = {}\n",
        "\n",
        "    # Create output directory for raw data\n",
        "    eobs_dir = f\"{output_dir}/eobs\"\n",
        "    os.makedirs(eobs_dir, exist_ok=True)\n",
        "\n",
        "    for i, site in sites_df.iterrows():\n",
        "        site_name = site['site_name']\n",
        "        lat = site['latitude']\n",
        "        lon = site['longitude']\n",
        "\n",
        "        if not availability[site_name]['eobs']['available']:\n",
        "            print(f\"E-OBS data not available for {site_name}, skipping...\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Fetching E-OBS data for site: {site_name} ({lat}, {lon})\")\n",
        "\n",
        "        eobs_results[site_name] = {\n",
        "            'temperature': None,\n",
        "            'precipitation': None\n",
        "        }\n",
        "\n",
        "        # E-OBS data is accessible through their data server\n",
        "        # We'll download the NetCDF files and extract the data\n",
        "\n",
        "        # Temperature data\n",
        "        if availability[site_name]['eobs']['variables'].get('temperature', False):\n",
        "            print(f\"  Fetching temperature data...\")\n",
        "\n",
        "            try:\n",
        "                # E-OBS temperature dataset URL (version 25.0e)\n",
        "                url = \"https://surfobs.climate.copernicus.eu/dataaccess/access_eobs.php#datafiles\"\n",
        "\n",
        "                # For E-OBS, we need to download the full NetCDF file\n",
        "                # This can be large, so we'll just create placeholder code here\n",
        "\n",
        "                # In a real scenario, you would download the file and process it\n",
        "                # For example:\n",
        "                # r = requests.get(eobs_temp_url, stream=True)\n",
        "                # with open(\"eobs_temp.nc\", 'wb') as f:\n",
        "                #     for chunk in r.iter_content(chunk_size=8192):\n",
        "                #         if chunk:\n",
        "                #             f.write(chunk)\n",
        "\n",
        "                # Create a DataFrame with synthetic data for demonstration\n",
        "                # In a real scenario, you would extract data from the NetCDF file\n",
        "\n",
        "                # Generate synthetic data\n",
        "                dates = pd.date_range(start=f\"{start_year}-01-01\", end=f\"{end_year}-12-31\", freq='D')\n",
        "                temp_values = np.random.normal(5, 3, size=len(dates))  # Mean 5°C, SD 3°C\n",
        "\n",
        "                temp_df = pd.DataFrame({\n",
        "                    'date': dates,\n",
        "                    'temperature': temp_values\n",
        "                })\n",
        "\n",
        "                # Save to file\n",
        "                temp_file = f\"{eobs_dir}/{site_name}_eobs_temperature.csv\"\n",
        "                temp_df.to_csv(temp_file, index=False)\n",
        "                print(f\"  Temperature data saved to: {temp_file}\")\n",
        "\n",
        "                # Store in results\n",
        "                eobs_results[site_name]['temperature'] = temp_df\n",
        "\n",
        "                print(\"  Note: This is synthetic E-OBS temperature data for demonstration.\")\n",
        "                print(\"  In a real scenario, you would download and process actual E-OBS NetCDF files.\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Error fetching temperature data: {str(e)}\")\n",
        "\n",
        "        # Precipitation data\n",
        "        if availability[site_name]['eobs']['variables'].get('precipitation', False):\n",
        "            print(f\"  Fetching precipitation data...\")\n",
        "\n",
        "            try:\n",
        "                # E-OBS precipitation dataset URL (version 25.0e)\n",
        "                url = \"https://surfobs.climate.copernicus.eu/dataaccess/access_eobs.php#datafiles\"\n",
        "\n",
        "                # Similar to temperature, we'll create synthetic data for demonstration\n",
        "\n",
        "                # Generate synthetic data\n",
        "                dates = pd.date_range(start=f\"{start_year}-01-01\", end=f\"{end_year}-12-31\", freq='D')\n",
        "                precip_values = np.random.exponential(2, size=len(dates))  # Mean 2mm\n",
        "\n",
        "                precip_df = pd.DataFrame({\n",
        "                    'date': dates,\n",
        "                    'precipitation': precip_values\n",
        "                })\n",
        "\n",
        "                # Save to file\n",
        "                precip_file = f\"{eobs_dir}/{site_name}_eobs_precipitation.csv\"\n",
        "                precip_df.to_csv(precip_file, index=False)\n",
        "                print(f\"  Precipitation data saved to: {precip_file}\")\n",
        "\n",
        "                # Store in results\n",
        "                eobs_results[site_name]['precipitation'] = precip_df\n",
        "\n",
        "                print(\"  Note: This is synthetic E-OBS precipitation data for demonstration.\")\n",
        "                print(\"  In a real scenario, you would download and process actual E-OBS NetCDF files.\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Error fetching precipitation data: {str(e)}\")\n",
        "\n",
        "    return eobs_results"
      ],
      "metadata": {
        "id": "EOFtrZOU3lIh"
      },
      "id": "EOFtrZOU3lIh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_integrated_climate_data(sites_df, availability, start_year=1979, end_year=None,\n",
        "                                noaa_token=None, frost_client_id=None, cds_setup=False,\n",
        "                                output_dir=\"/content/climate_outputs\"):\n",
        "    \"\"\"\n",
        "    Fetch climate data from multiple sources based on availability checks.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    sites_df : pandas.DataFrame\n",
        "        DataFrame with glacier site information\n",
        "    availability : dict\n",
        "        Dictionary of availability by site and source\n",
        "    start_year : int, optional\n",
        "        Start year for data retrieval\n",
        "    end_year : int, optional\n",
        "        End year for data retrieval\n",
        "    noaa_token : str, optional\n",
        "        NOAA API token\n",
        "    frost_client_id : str, optional\n",
        "        MET Norway Frost API client ID\n",
        "    cds_setup : bool, optional\n",
        "        Whether CDS API is set up\n",
        "    output_dir : str, optional\n",
        "        Directory to save output files\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    dict\n",
        "        Dictionary with integrated climate data for each site\n",
        "    \"\"\"\n",
        "    if end_year is None:\n",
        "        end_year = datetime.now().year\n",
        "\n",
        "    integrated_results = {}\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for i, site in sites_df.iterrows():\n",
        "        site_name = site['site_name']\n",
        "        lat = site['latitude']\n",
        "        lon = site['longitude']\n",
        "\n",
        "        print(f\"\\nFetching data for site: {site_name} ({lat}, {lon})\")\n",
        "\n",
        "        integrated_results[site_name] = {\n",
        "            'noaa_data': None,\n",
        "            'era5_data': None,\n",
        "            'frost_data': None,\n",
        "            'senorge_data': None,\n",
        "            'nve_data': None,\n",
        "            'chelsa_data': None,\n",
        "            'eobs_data': None,\n",
        "            'integrated_data': {\n",
        "                'temperature': {},\n",
        "                'precipitation': {},\n",
        "                'wind': {},\n",
        "                'snow': {},\n",
        "                'cloudiness': {}\n",
        "            },\n",
        "            'metadata': {\n",
        "                'site_name': site_name,\n",
        "                'latitude': lat,\n",
        "                'longitude': lon,\n",
        "                'noaa_station': None,\n",
        "                'frost_station': None,\n",
        "                'sources_used': []\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Fetch Frost data first (highest priority for Norwegian sites)\n",
        "        if availability[site_name]['frost']['available'] and frost_client_id:\n",
        "            print(f\"  Fetching MET Norway Frost data for {site_name}...\")\n",
        "\n",
        "            try:\n",
        "                # Find nearby stations\n",
        "                stations_url = \"https://frost.met.no/sources/v0.jsonld\"\n",
        "                params = {\n",
        "                    'geometry': f'nearest(POINT({lon} {lat}))',\n",
        "                    'nearestmaxcount': 5,\n",
        "                    'types': 'SN',  # Standard Norwegian weather stations\n",
        "                }\n",
        "\n",
        "                r = requests.get(stations_url, params=params, auth=(frost_client_id, ''))\n",
        "\n",
        "                if r.status_code == 200:\n",
        "                    stations_data = r.json()\n",
        "\n",
        "                    if 'data' in stations_data and stations_data['data']:\n",
        "                        station = stations_data['data'][0]\n",
        "                        station_id = station['id']\n",
        "                        station_name = station['name']\n",
        "                        station_lat = station.get('geometry', {}).get('coordinates', [None, None])[1]\n",
        "                        station_lon = station.get('geometry', {}).get('coordinates', [None, None])[0]\n",
        "\n",
        "                        integrated_results[site_name]['metadata']['frost_station'] = {\n",
        "                            'id': station_id,\n",
        "                            'name': station_name,\n",
        "                            'latitude': station_lat,\n",
        "                            'longitude': station_lon\n",
        "                        }\n",
        "\n",
        "                        # Get available variables\n",
        "                        available_vars = [var for var, is_available in\n",
        "                                        availability[site_name]['frost']['variables'].items()\n",
        "                                        if is_available]\n",
        "\n",
        "                        # Map variable names to Frost element IDs\n",
        "                        element_mapping = {\n",
        "                            'temperature': 'air_temperature',\n",
        "                            'mean_temperature': 'mean(air_temperature P1D)',\n",
        "                            'min_temperature': 'min(air_temperature P1D)',\n",
        "                            'max_temperature': 'max(air_temperature P1D)',\n",
        "                            'precipitation': 'sum(precipitation_amount P1D)',\n",
        "                            'snow_depth': 'snow_depth',\n",
        "                            'wind_speed': 'wind_speed',\n",
        "                            'max_wind_speed': 'max(wind_speed P1D)'\n",
        "                        }\n",
        "\n",
        "                        # Get the corresponding Frost element IDs\n",
        "                        elements = [element_mapping[var] for var in available_vars if var in element_mapping]\n",
        "\n",
        "                        if elements:\n",
        "                            # Join elements with comma\n",
        "                            elements_str = ','.join(elements)\n",
        "\n",
        "                            # Fetch data\n",
        "                            site_data = []\n",
        "\n",
        "                            # Fetch data for each year\n",
        "                            for year in range(start_year, end_year + 1):\n",
        "                                try:\n",
        "                                    # Define the time range for this year\n",
        "                                    from_date = f\"{year}-01-01\"\n",
        "                                    to_date = f\"{year}-12-31\"\n",
        "\n",
        "                                    print(f\"    Fetching Frost data for year {year}...\")\n",
        "\n",
        "                                    # Set up the API request\n",
        "                                    url = \"https://frost.met.no/observations/v0.jsonld\"\n",
        "                                    params = {\n",
        "                                        'sources': station_id,\n",
        "                                        'elements': elements_str,\n",
        "                                        'referencetime': f\"{from_date}/{to_date}\",\n",
        "                                        'timeresolution': 'P1D',  # Daily data\n",
        "                                        'fields': 'value,elementId,unit,referenceTime'\n",
        "                                    }\n",
        "\n",
        "                                    # Make the request\n",
        "                                    r = requests.get(url, params=params, auth=(frost_client_id, ''))\n",
        "\n",
        "                                    if r.status_code == 200:\n",
        "                                        data = r.json()\n",
        "\n",
        "                                        if 'data' in data:\n",
        "                                            # Process data\n",
        "                                            for obs in data['data']:\n",
        "                                                for obs_data in obs.get('observations', []):\n",
        "                                                    record = {\n",
        "                                                        'date': obs.get('referenceTime'),\n",
        "                                                        'element': obs_data.get('elementId'),\n",
        "                                                        'value': obs_data.get('value'),\n",
        "                                                        'unit': obs_data.get('unit')\n",
        "                                                    }\n",
        "                                                    site_data.append(record)\n",
        "\n",
        "                                            print(f\"      Retrieved {len(data['data'])} records\")\n",
        "                                        else:\n",
        "                                            print(f\"      No data returned for {year}\")\n",
        "                                    else:\n",
        "                                        print(f\"      API error for {year}: {r.status_code} - {r.text}\")\n",
        "                                except Exception as e:\n",
        "                                    print(f\"      Error fetching data for {year}: {str(e)}\")\n",
        "\n",
        "                                # Add a small delay to avoid rate limiting\n",
        "                                time.sleep(0.5)\n",
        "\n",
        "                            if site_data:\n",
        "                                # Convert to DataFrame\n",
        "                                df = pd.DataFrame(site_data)\n",
        "                                integrated_results[site_name]['frost_data'] = df\n",
        "                                integrated_results[site_name]['metadata']['sources_used'].append('Frost')\n",
        "\n",
        "                                # Save raw data\n",
        "                                frost_dir = f\"{output_dir}/frost\"\n",
        "                                os.makedirs(frost_dir, exist_ok=True)\n",
        "                                raw_frost_file = f\"{frost_dir}/{site_name}_frost_raw_data.csv\"\n",
        "                                df.to_csv(raw_frost_file, index=False)\n",
        "                                print(f\"    Raw Frost data saved to: {raw_frost_file}\")\n",
        "                            else:\n",
        "                                print(f\"    No Frost data collected for {site_name}\")\n",
        "                        else:\n",
        "                            print(f\"    No available elements for {site_name}\")\n",
        "                    else:\n",
        "                        print(f\"    No Frost stations found near {site_name}\")\n",
        "                else:\n",
        "                    print(f\"    Frost API error: {r.status_code} - {r.text}\")\n",
        "            except Exception as e:\n",
        "                print(f\"    Error fetching Frost data: {str(e)}\")\n",
        "\n",
        "        # Fetch SeNorge data if available\n",
        "        if availability[site_name]['senorge']['available']:\n",
        "            print(f\"  Fetching SeNorge data for {site_name}...\")\n",
        "\n",
        "            # Initialize dictionary for SeNorge data\n",
        "            integrated_results[site_name]['senorge_data'] = {}\n",
        "\n",
        "            try:\n",
        "                # Check if site is within Norway's bounds\n",
        "                norway_bounds = {\n",
        "                    'min_lat': 57.5,\n",
        "                    'max_lat': 71.5,\n",
        "                    'min_lon': 4.0,\n",
        "                    'max_lon': 31.5\n",
        "                }\n",
        "\n",
        "                if (norway_bounds['min_lat'] <= lat <= norway_bounds['max_lat'] and\n",
        "                    norway_bounds['min_lon'] <= lon <= norway_bounds['max_lon']):\n",
        "\n",
        "                    # Create SeNorge directory\n",
        "                    senorge_dir = f\"{output_dir}/senorge\"\n",
        "                    os.makedirs(senorge_dir, exist_ok=True)\n",
        "\n",
        "                    # Temperature data\n",
        "                    if availability[site_name]['senorge']['variables'].get('temperature', False):\n",
        "                        print(f\"    Fetching SeNorge temperature data...\")\n",
        "\n",
        "                        # Create a list to store annual data\n",
        "                        temp_data = []\n",
        "\n",
        "                        # For demonstration, we'll create synthetic data\n",
        "                        # In a real scenario, you would fetch data from SeNorge's Thredds server\n",
        "                        dates = pd.date_range(start=f\"{start_year}-01-01\", end=f\"{end_year}-12-31\", freq='D')\n",
        "\n",
        "                        # Generate temperature values with seasonal cycle\n",
        "                        # Average temperature of 5°C with 10°C seasonal amplitude\n",
        "                        days = np.arange(len(dates))\n",
        "                        temp_values = 5 + 10 * np.cos(2 * np.pi * days / 365.25) + np.random.normal(0, 2, size=len(dates))\n",
        "\n",
        "                        temp_df = pd.DataFrame({\n",
        "                            'time': dates,\n",
        "                            'tm': temp_values,\n",
        "                            'longitude': lon,\n",
        "                            'latitude': lat\n",
        "                        })\n",
        "\n",
        "                        # Save temperature data\n",
        "                        temp_file = f\"{senorge_dir}/{site_name}_senorge_temperature.csv\"\n",
        "                        temp_df.to_csv(temp_file, index=False)\n",
        "                        print(f\"    Temperature data saved to: {temp_file}\")\n",
        "\n",
        "                        # Store data\n",
        "                        integrated_results[site_name]['senorge_data']['temperature'] = temp_df\n",
        "                        integrated_results[site_name]['metadata']['sources_used'].append('SeNorge')\n",
        "\n",
        "                        print(\"    Note: This is synthetic SeNorge temperature data for demonstration.\")\n",
        "                        print(\"    In a real scenario, you would fetch data from SeNorge's Thredds server.\")\n",
        "\n",
        "                    # Precipitation data\n",
        "                    if availability[site_name]['senorge']['variables'].get('precipitation', False):\n",
        "                        print(f\"    Fetching SeNorge precipitation data...\")\n",
        "\n",
        "                        # For demonstration, we'll create synthetic data\n",
        "                        dates = pd.date_range(start=f\"{start_year}-01-01\", end=f\"{end_year}-12-31\", freq='D')\n",
        "\n",
        "                        # Generate precipitation values with seasonal cycle\n",
        "                        # More precipitation in winter, less in summer\n",
        "                        days = np.arange(len(dates))\n",
        "                        # Base precipitation with seasonal variation and random component\n",
        "                        prcp_values = 2 + 2 * np.cos(2 * np.pi * days / 365.25 + np.pi)\n",
        "                        prcp_values = np.maximum(0, prcp_values + np.random.exponential(1, size=len(dates)))\n",
        "\n",
        "                        precip_df = pd.DataFrame({\n",
        "                            'time': dates,\n",
        "                            'rr': prcp_values,\n",
        "                            'longitude': lon,\n",
        "                            'latitude': lat\n",
        "                        })\n",
        "\n",
        "                        # Save precipitation data\n",
        "                        precip_file = f\"{senorge_dir}/{site_name}_senorge_precipitation.csv\"\n",
        "                        precip_df.to_csv(precip_file, index=False)\n",
        "                        print(f\"    Precipitation data saved to: {precip_file}\")\n",
        "\n",
        "                        # Store data\n",
        "                        integrated_results[site_name]['senorge_data']['precipitation'] = precip_df\n",
        "                        if 'SeNorge' not in integrated_results[site_name]['metadata']['sources_used']:\n",
        "                            integrated_results[site_name]['metadata']['sources_used'].append('SeNorge')\n",
        "\n",
        "                        print(\"    Note: This is synthetic SeNorge precipitation data for demonstration.\")\n",
        "                        print(\"    In a real scenario, you would fetch data from SeNorge's Thredds server.\")\n",
        "\n",
        "                    # Snow depth data\n",
        "                    if availability[site_name]['senorge']['variables'].get('snow_depth', False):\n",
        "                        print(f\"    Fetching SeNorge snow depth data...\")\n",
        "\n",
        "                        # For demonstration, we'll create synthetic data\n",
        "                        dates = pd.date_range(start=f\"{start_year}-01-01\", end=f\"{end_year}-12-31\", freq='D')\n",
        "\n",
        "                        # Generate snow depth values with seasonal cycle\n",
        "                        # More snow in winter, none in summer\n",
        "                        days = np.arange(len(dates))\n",
        "                        # Base snow depth with seasonal variation and random component\n",
        "                        snow_values = np.maximum(0, 20 * np.cos(2 * np.pi * days / 365.25 + np.pi) + np.random.normal(0, 5, size=len(dates)))\n",
        "\n",
        "                        snow_df = pd.DataFrame({\n",
        "                            'time': dates,\n",
        "                            'sd': snow_values,\n",
        "                            'longitude': lon,\n",
        "                            'latitude': lat\n",
        "                        })\n",
        "\n",
        "                        # Save snow depth data\n",
        "                        snow_file = f\"{senorge_dir}/{site_name}_senorge_snow_depth.csv\"\n",
        "                        snow_df.to_csv(snow_file, index=False)\n",
        "                        print(f\"    Snow depth data saved to: {snow_file}\")\n",
        "\n",
        "                        # Store data\n",
        "                        integrated_results[site_name]['senorge_data']['snow_depth'] = snow_df\n",
        "                        if 'SeNorge' not in integrated_results[site_name]['metadata']['sources_used']:\n",
        "                            integrated_results[site_name]['metadata']['sources_used'].append('SeNorge')\n",
        "\n",
        "                        print(\"    Note: This is synthetic SeNorge snow depth data for demonstration.\")\n",
        "                        print(\"    In a real scenario, you would fetch data from SeNorge's Thredds server.\")\n",
        "                else:\n",
        "                    print(f\"    SeNorge data not available for {site_name} (outside Norway)\")\n",
        "            except Exception as e:\n",
        "                print(f\"    Error fetching SeNorge data: {str(e)}\")\n",
        "\n",
        "        # Fetch NVE glacier data if available\n",
        "        if availability[site_name]['nve']['available']:\n",
        "            print(f\"  Fetching NVE glacier data for {site_name}...\")\n",
        "\n",
        "            # Initialize dictionary for NVE data\n",
        "            integrated_results[site_name]['nve_data'] = {}\n",
        "\n",
        "            try:\n",
        "                # For demonstration, we'll create synthetic data\n",
        "                # In a real scenario, you would search for the glacier by name and fetch data from NVE's API\n",
        "\n",
        "                # Create NVE directory\n",
        "                nve_dir = f\"{output_dir}/nve\"\n",
        "                os.makedirs(nve_dir, exist_ok=True)\n",
        "\n",
        "                # Mass balance data\n",
        "                if availability[site_name]['nve']['variables'].get('mass_balance', False):\n",
        "                    print(f\"    Creating synthetic NVE mass balance data...\")\n",
        "\n",
        "                    # Generate years\n",
        "                    years = np.arange(start_year, end_year + 1)\n",
        "\n",
        "                    # Generate mass balance values with trend (negative balance in recent years)\n",
        "                    # Base value around -0.5 m w.e. with decreasing trend and random component\n",
        "                    mb_values = -0.5 - 0.01 * (years - start_year) + np.random.normal(0, 0.3, size=len(years))\n",
        "\n",
        "                    mb_df = pd.DataFrame({\n",
        "                        'year': years,\n",
        "                        'winter_balance': mb_values + np.random.normal(1.5, 0.2, size=len(years)),\n",
        "                        'summer_balance': mb_values - np.random.normal(1.5, 0.2, size=len(years)),\n",
        "                        'annual_balance': mb_values\n",
        "                    })\n",
        "\n",
        "                    # Save mass balance data\n",
        "                    mb_file = f\"{nve_dir}/{site_name}_nve_mass_balance.csv\"\n",
        "                    mb_df.to_csv(mb_file, index=False)\n",
        "                    print(f\"    Mass balance data saved to: {mb_file}\")\n",
        "\n",
        "                    # Store data\n",
        "                    integrated_results[site_name]['nve_data']['mass_balance'] = mb_df\n",
        "                    integrated_results[site_name]['metadata']['sources_used'].append('NVE')\n",
        "\n",
        "                    print(\"    Note: This is synthetic NVE mass balance data for demonstration.\")\n",
        "                    print(\"    In a real scenario, you would fetch data from NVE's API.\")\n",
        "\n",
        "                # Length change data\n",
        "                if availability[site_name]['nve']['variables'].get('length_change', False):\n",
        "                    print(f\"    Creating synthetic NVE length change data...\")\n",
        "\n",
        "                    # Generate years (less frequent measurements)\n",
        "                    years = np.arange(start_year, end_year + 1, 2)  # Every 2 years\n",
        "\n",
        "                    # Generate length change values with trend (retreat in recent years)\n",
        "                    # Base retreat of -5 meters per year with increasing rate and random component\n",
        "                    lc_values = -5 - 0.2 * (years - start_year) + np.random.normal(0, 2, size=len(years))\n",
        "                    # Cumulative retreat\n",
        "                    cum_retreat = np.cumsum(lc_values)\n",
        "\n",
        "                    lc_df = pd.DataFrame({\n",
        "                        'year': years,\n",
        "                        'length_change': lc_values,\n",
        "                        'cumulative_retreat': cum_retreat\n",
        "                    })\n",
        "\n",
        "                    # Save length change data\n",
        "                    lc_file = f\"{nve_dir}/{site_name}_nve_length_change.csv\"\n",
        "                    lc_df.to_csv(lc_file, index=False)\n",
        "                    print(f\"    Length change data saved to: {lc_file}\")\n",
        "\n",
        "                    # Store data\n",
        "                    integrated_results[site_name]['nve_data']['length_change'] = lc_df\n",
        "                    if 'NVE' not in integrated_results[site_name]['metadata']['sources_used']:\n",
        "                        integrated_results[site_name]['metadata']['sources_used'].append('NVE')\n",
        "\n",
        "                    print(\"    Note: This is synthetic NVE length change data for demonstration.\")\n",
        "                    print(\"    In a real scenario, you would fetch data from NVE's API.\")\n",
        "            except Exception as e:\n",
        "                print(f\"    Error fetching NVE data: {str(e)}\")\n",
        "\n",
        "        # Fetch NOAA data if available\n",
        "        if availability[site_name]['noaa']['available'] and noaa_token:\n",
        "            print(f\"  Fetching NOAA data for {site_name}...\")\n",
        "\n",
        "            headers = {'token': noaa_token}\n",
        "            base_url = \"https://www.ncdc.noaa.gov/cdo-web/api/v2\"\n",
        "            station_id = availability[site_name]['noaa']['station_id']\n",
        "            station_name = availability[site_name]['noaa']['station_name']\n",
        "\n",
        "            integrated_results[site_name]['metadata']['noaa_station'] = {\n",
        "                'id': station_id,\n",
        "                'name': station_name,\n",
        "                'latitude': availability[site_name]['noaa']['station_lat'],\n",
        "                'longitude': availability[site_name]['noaa']['station_lon']\n",
        "            }\n",
        "\n",
        "            # Only fetch variables that are available\n",
        "            available_vars = [var for var, is_available in\n",
        "                            availability[site_name]['noaa']['variables'].items()\n",
        "                            if is_available]\n",
        "\n",
        "            if available_vars:\n",
        "                data_types = ','.join(available_vars)\n",
        "                site_data = []\n",
        "\n",
        "                # Fetch data year by year\n",
        "                for year in range(max(start_year, 1970), end_year + 1):\n",
        "                    data_url = f\"{base_url}/data\"\n",
        "                    data_params = {\n",
        "                        'datasetid': 'GHCND',\n",
        "                        'stationid': station_id,\n",
        "                        'startdate': f\"{year}-01-01\",\n",
        "                        'enddate': f\"{year}-12-31\",\n",
        "                        'datatypeid': data_types,\n",
        "                        'units': 'metric',\n",
        "                        'limit': 1000\n",
        "                    }\n",
        "\n",
        "                    try:\n",
        "                        response = requests.get(data_url, headers=headers, params=data_params, timeout=30)\n",
        "                        if response.status_code == 200:\n",
        "                            data = response.json()\n",
        "                            if 'results' in data and data['results']:\n",
        "                                site_data.extend(data['results'])\n",
        "                                print(f\"    Year {year}: {len(data['results'])} records\")\n",
        "                            else:\n",
        "                                print(f\"    Year {year}: No data found\")\n",
        "                        else:\n",
        "                            print(f\"    Year {year}: API error {response.status_code}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"    Error fetching data for year {year}: {str(e)}\")\n",
        "\n",
        "                    # Add a small delay to avoid rate limiting\n",
        "                    time.sleep(0.5)\n",
        "\n",
        "                if site_data:\n",
        "                    df = pd.DataFrame(site_data)\n",
        "                    integrated_results[site_name]['noaa_data'] = df\n",
        "                    integrated_results[site_name]['metadata']['sources_used'].append('NOAA')\n",
        "\n",
        "                    # Save raw NOAA data\n",
        "                    noaa_dir = f\"{output_dir}/noaa\"\n",
        "                    os.makedirs(noaa_dir, exist_ok=True)\n",
        "                    raw_noaa_file = f\"{noaa_dir}/{site_name}_noaa_raw_data.csv\"\n",
        "                    df.to_csv(raw_noaa_file, index=False)\n",
        "                    print(f\"  Raw NOAA data saved to: {raw_noaa_file}\")\n",
        "                else:\n",
        "                    print(f\"  No NOAA data collected for {site_name}\")\n",
        "            else:\n",
        "                print(f\"  No available variables from NOAA for {site_name}\")\n",
        "\n",
        "        # Fetch ERA5 data if available\n",
        "        if availability[site_name]['era5']['available'] and cds_setup:\n",
        "            print(f\"  Fetching ERA5 data for {site_name}...\")\n",
        "\n",
        "            try:\n",
        "                import cdsapi\n",
        "                c = cdsapi.Client()\n",
        "\n",
        "                # Create an ERA5 subdirectory\n",
        "                era5_dir = f\"{output_dir}/era5\"\n",
        "                os.makedirs(era5_dir, exist_ok=True)\n",
        "\n",
        "                output_file = f\"{era5_dir}/{site_name}_era5.nc\"\n",
        "\n",
        "                # Define years and months\n",
        "                years = [str(year) for year in range(start_year, end_year + 1)]\n",
        "                months = [f\"{month:02d}\" for month in range(1, 13)]\n",
        "\n",
        "                # Request data\n",
        "                print(f\"  Requesting ERA5 data from CDS API for {site_name}...\")\n",
        "                c.retrieve(\n",
        "                    'reanalysis-era5-single-levels-monthly-means',\n",
        "                    {\n",
        "                        'product_type': 'monthly_averaged_reanalysis',\n",
        "                        'variable': ['2m_temperature', 'total_precipitation'],\n",
        "                        'year': years,\n",
        "                        'month': months,\n",
        "                        'time': '00:00',\n",
        "                        'area': [lat+1, lon-1, lat-1, lon+1],  # N/W/S/E\n",
        "                        'format': 'netcdf',\n",
        "                    },\n",
        "                    output_file)\n",
        "\n",
        "                print(f\"  ERA5 data downloaded to: {output_file}\")\n",
        "\n",
        "                # Load data\n",
        "                ds = xr.open_dataset(output_file)\n",
        "                ds = ds.sel(latitude=lat, longitude=lon, method='nearest')\n",
        "                integrated_results[site_name]['era5_data'] = ds\n",
        "                integrated_results[site_name]['metadata']['sources_used'].append('ERA5')\n",
        "\n",
        "                # Save as CSV for easier access\n",
        "                era5_csv_dir = f\"{output_dir}/era5_csv\"\n",
        "                os.makedirs(era5_csv_dir, exist_ok=True)\n",
        "\n",
        "                if 't2m' in ds:\n",
        "                    temp_df = ds['t2m'].to_dataframe().reset_index()\n",
        "                    temp_df.to_csv(f\"{era5_csv_dir}/{site_name}_era5_temperature.csv\", index=False)\n",
        "\n",
        "                if 'tp' in ds:\n",
        "                    precip_df = ds['tp'].to_dataframe().reset_index()\n",
        "                    precip_df.to_csv(f\"{era5_csv_dir}/{site_name}_era5_precipitation.csv\", index=False)\n",
        "\n",
        "                print(f\"  ERA5 data processed for {site_name}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Error fetching ERA5 data: {str(e)}\")\n",
        "\n",
        "        # Fetch CHELSA data if available\n",
        "        if availability[site_name]['chelsa']['available']:\n",
        "            print(f\"  Fetching CHELSA climatology data for {site_name}...\")\n",
        "\n",
        "            # Initialize dictionary for CHELSA data\n",
        "            integrated_results[site_name]['chelsa_data'] = {}\n",
        "\n",
        "            try:\n",
        "                # Create CHELSA directory\n",
        "                chelsa_dir = f\"{output_dir}/chelsa\"\n",
        "                os.makedirs(chelsa_dir, exist_ok=True)\n",
        "\n",
        "                # For demonstration, we'll create synthetic data\n",
        "                # In a real scenario, you would download and process CHELSA geotiffs\n",
        "\n",
        "                # Temperature data\n",
        "                if availability[site_name]['chelsa']['variables'].get('temperature', False):\n",
        "                    print(f\"    Creating synthetic CHELSA temperature data...\")\n",
        "\n",
        "                    # Generate monthly climatology\n",
        "                    months = np.arange(1, 13)\n",
        "\n",
        "                    # Generate temperature values with seasonal cycle\n",
        "                    # Average temperature of 5°C with 10°C seasonal amplitude\n",
        "                    temp_values = 5 + 10 * np.cos(2 * np.pi * (months - 1) / 12) + np.random.normal(0, 0.5, size=12)\n",
        "\n",
        "                    temp_df = pd.DataFrame({\n",
        "                        'month': months,\n",
        "                        'temperature': temp_values\n",
        "                    })\n",
        "\n",
        "                    # Save temperature data\n",
        "                    temp_file = f\"{chelsa_dir}/{site_name}_chelsa_temperature.csv\"\n",
        "                    temp_df.to_csv(temp_file, index=False)\n",
        "                    print(f\"    Temperature climatology saved to: {temp_file}\")\n",
        "\n",
        "                    # Store data\n",
        "                    integrated_results[site_name]['chelsa_data']['temperature'] = temp_df\n",
        "                    integrated_results[site_name]['metadata']['sources_used'].append('CHELSA')\n",
        "\n",
        "                    print(\"    Note: This is synthetic CHELSA temperature data for demonstration.\")\n",
        "                    print(\"    In a real scenario, you would download and process CHELSA geotiffs.\")\n",
        "\n",
        "                # Precipitation data\n",
        "                if availability[site_name]['chelsa']['variables'].get('precipitation', False):\n",
        "                    print(f\"    Creating synthetic CHELSA precipitation data...\")\n",
        "\n",
        "                    # Generate monthly climatology\n",
        "                    months = np.arange(1, 13)\n",
        "\n",
        "                    # Generate precipitation values with seasonal cycle\n",
        "                    # More precipitation in winter, less in summer\n",
        "                    prcp_values = 80 + 40 * np.cos(2 * np.pi * (months - 1) / 12 + np.pi) + np.random.normal(0, 10, size=12)\n",
        "                    prcp_values = np.maximum(0, prcp_values)  # Ensure non-negative\n",
        "\n",
        "                    precip_df = pd.DataFrame({\n",
        "                        'month': months,\n",
        "                        'precipitation': prcp_values\n",
        "                    })\n",
        "\n",
        "                    # Save precipitation data\n",
        "                    precip_file = f\"{chelsa_dir}/{site_name}_chelsa_precipitation.csv\"\n",
        "                    precip_df.to_csv(precip_file, index=False)\n",
        "                    print(f\"    Precipitation climatology saved to: {precip_file}\")\n",
        "\n",
        "                    # Store data\n",
        "                    integrated_results[site_name]['chelsa_data']['precipitation'] = precip_df\n",
        "                    if 'CHELSA' not in integrated_results[site_name]['metadata']['sources_used']:\n",
        "                        integrated_results[site_name]['metadata']['sources_used'].append('CHELSA')\n",
        "\n",
        "                    print(\"    Note: This is synthetic CHELSA precipitation data for demonstration.\")\n",
        "                    print(\"    In a real scenario, you would download and process CHELSA geotiffs.\")\n",
        "            except Exception as e:\n",
        "                print(f\"    Error creating CHELSA data: {str(e)}\")\n",
        "\n",
        "        # Fetch E-OBS data if available\n",
        "        if availability[site_name]['eobs']['available']:\n",
        "            print(f\"  Fetching E-OBS data for {site_name}...\")\n",
        "\n",
        "            # Initialize dictionary for E-OBS data\n",
        "            integrated_results[site_name]['eobs_data'] = {}\n",
        "\n",
        "            try:\n",
        "                # Check if site is within Europe's bounds\n",
        "                europe_bounds = {\n",
        "                    'min_lat': 25.0,\n",
        "                    'max_lat': 75.0,\n",
        "                    'min_lon': -25.0,\n",
        "                    'max_lon': 45.0\n",
        "                }\n",
        "\n",
        "                if (europe_bounds['min_lat'] <= lat <= europe_bounds['max_lat'] and\n",
        "                    europe_bounds['min_lon'] <= lon <= europe_bounds['max_lon']):\n",
        "\n",
        "                    # Create E-OBS directory\n",
        "                    eobs_dir = f\"{output_dir}/eobs\"\n",
        "                    os.makedirs(eobs_dir, exist_ok=True)\n",
        "\n",
        "                    # For demonstration, we'll create synthetic data\n",
        "                    # In a real scenario, you would download and process E-OBS netCDF files\n",
        "\n",
        "                    # Temperature data\n",
        "                    if availability[site_name]['eobs']['variables'].get('temperature', False):\n",
        "                        print(f\"    Creating synthetic E-OBS temperature data...\")\n",
        "\n",
        "                        # Generate dates\n",
        "                        dates = pd.date_range(start=f\"{start_year}-01-01\", end=f\"{end_year}-12-31\", freq='D')\n",
        "\n",
        "                        # Generate temperature values with seasonal cycle and trend\n",
        "                        # Average temperature of 5°C with 10°C seasonal amplitude\n",
        "                        # and warming trend of 0.03°C per year\n",
        "                        days = np.arange(len(dates))\n",
        "                        years_since_start = (dates.year - start_year).values\n",
        "                        trend = 0.03 * years_since_start  # 0.03°C warming per year\n",
        "                        seasonal = 10 * np.cos(2 * np.pi * days / 365.25)\n",
        "                        temp_values = 5 + trend + seasonal + np.random.normal(0, 1.5, size=len(dates))\n",
        "\n",
        "                        temp_df = pd.DataFrame({\n",
        "                            'date': dates,\n",
        "                            'temperature': temp_values\n",
        "                        })\n",
        "\n",
        "                        # Save temperature data\n",
        "                        temp_file = f\"{eobs_dir}/{site_name}_eobs_temperature.csv\"\n",
        "                        temp_df.to_csv(temp_file, index=False)\n",
        "                        print(f\"    Temperature data saved to: {temp_file}\")\n",
        "\n",
        "                        # Store data\n",
        "                        integrated_results[site_name]['eobs_data']['temperature'] = temp_df\n",
        "                        integrated_results[site_name]['metadata']['sources_used'].append('E-OBS')\n",
        "\n",
        "                        print(\"    Note: This is synthetic E-OBS temperature data for demonstration.\")\n",
        "                        print(\"    In a real scenario, you would download and process E-OBS netCDF files.\")\n",
        "\n",
        "                    # Precipitation data\n",
        "                    if availability[site_name]['eobs']['variables'].get('precipitation', False):\n",
        "                        print(f\"    Creating synthetic E-OBS precipitation data...\")\n",
        "\n",
        "                        # Generate dates\n",
        "                        dates = pd.date_range(start=f\"{start_year}-01-01\", end=f\"{end_year}-12-31\", freq='D')\n",
        "\n",
        "                        # Generate precipitation values with seasonal cycle\n",
        "                        # More precipitation in winter, less in summer\n",
        "                        days = np.arange(len(dates))\n",
        "                        seasonal = 2 * np.cos(2 * np.pi * days / 365.25 + np.pi)\n",
        "                        # Base precipitation with seasonal variation and random component\n",
        "                        prcp_values = np.maximum(0, seasonal + np.random.exponential(1, size=len(dates)))\n",
        "\n",
        "                        precip_df = pd.DataFrame({\n",
        "                            'date': dates,\n",
        "                            'precipitation': prcp_values\n",
        "                        })\n",
        "\n",
        "                        # Save precipitation data\n",
        "                        precip_file = f\"{eobs_dir}/{site_name}_eobs_precipitation.csv\"\n",
        "                        precip_df.to_csv(precip_file, index=False)\n",
        "                        print(f\"    Precipitation data saved to: {precip_file}\")\n",
        "\n",
        "                        # Store data\n",
        "                        integrated_results[site_name]['eobs_data']['precipitation'] = precip_df\n",
        "                        if 'E-OBS' not in integrated_results[site_name]['metadata']['sources_used']:\n",
        "                            integrated_results[site_name]['metadata']['sources_used'].append('E-OBS')\n",
        "\n",
        "                        print(\"    Note: This is synthetic E-OBS precipitation data for demonstration.\")\n",
        "                        print(\"    In a real scenario, you would download and process E-OBS netCDF files.\")\n",
        "                else:\n",
        "                    print(f\"    E-OBS data not available for {site_name} (outside Europe)\")\n",
        "            except Exception as e:\n",
        "                print(f\"    Error creating E-OBS data: {str(e)}\")\n",
        "\n",
        "    return integrated_results\n",
        "    if end_year is None:\n",
        "        end_year = datetime.now().year\n",
        "\n",
        "    integrated_results = {}\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for i, site in sites_df.iterrows():\n",
        "        site_name = site['site_name']\n",
        "        lat = site['latitude']\n",
        "        lon = site['longitude']\n",
        "\n",
        "        print(f\"\\nFetching data for site: {site_name} ({lat}, {lon})\")\n",
        "\n",
        "        integrated_results[site_name] = {\n",
        "            'noaa_data': None,\n",
        "            'era5_data': None,\n",
        "            'integrated_data': {\n",
        "                'temperature': {},\n",
        "                'precipitation': {},\n",
        "                'wind': {},\n",
        "                'snow': {},\n",
        "                'cloudiness': {}\n",
        "            },\n",
        "            'metadata': {\n",
        "                'site_name': site_name,\n",
        "                'latitude': lat,\n",
        "                'longitude': lon,\n",
        "                'noaa_station': None,\n",
        "                'sources_used': []\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Fetch NOAA data if available\n",
        "        if availability[site_name]['noaa']['available'] and noaa_token:\n",
        "            print(f\"  Fetching NOAA data for {site_name}...\")\n",
        "\n",
        "            headers = {'token': noaa_token}\n",
        "            base_url = \"https://www.ncdc.noaa.gov/cdo-web/api/v2\"\n",
        "            station_id = availability[site_name]['noaa']['station_id']\n",
        "            station_name = availability[site_name]['noaa']['station_name']\n",
        "\n",
        "            integrated_results[site_name]['metadata']['noaa_station'] = {\n",
        "                'id': station_id,\n",
        "                'name': station_name,\n",
        "                'latitude': availability[site_name]['noaa']['station_lat'],\n",
        "                'longitude': availability[site_name]['noaa']['station_lon']\n",
        "            }\n",
        "\n",
        "            # Only fetch variables that are available\n",
        "            available_vars = [var for var, is_available in\n",
        "                            availability[site_name]['noaa']['variables'].items()\n",
        "                            if is_available]\n",
        "\n",
        "            if available_vars:\n",
        "                data_types = ','.join(available_vars)\n",
        "                site_data = []\n",
        "\n",
        "                # Fetch data year by year\n",
        "                for year in range(max(start_year, 1970), end_year + 1):\n",
        "                    data_url = f\"{base_url}/data\"\n",
        "                    data_params = {\n",
        "                        'datasetid': 'GHCND',\n",
        "                        'stationid': station_id,\n",
        "                        'startdate': f\"{year}-01-01\",\n",
        "                        'enddate': f\"{year}-12-31\",\n",
        "                        'datatypeid': data_types,\n",
        "                        'units': 'metric',\n",
        "                        'limit': 1000\n",
        "                    }\n",
        "\n",
        "                    try:\n",
        "                        response = requests.get(data_url, headers=headers, params=data_params, timeout=30)\n",
        "                        if response.status_code == 200:\n",
        "                            data = response.json()\n",
        "                            if 'results' in data and data['results']:\n",
        "                                site_data.extend(data['results'])\n",
        "                                print(f\"    Year {year}: {len(data['results'])} records\")\n",
        "                            else:\n",
        "                                print(f\"    Year {year}: No data found\")\n",
        "                        else:\n",
        "                            print(f\"    Year {year}: API error {response.status_code}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"    Error fetching data for year {year}: {str(e)}\")\n",
        "\n",
        "                    # Add a small delay to avoid rate limiting\n",
        "                    time.sleep(0.5)\n",
        "\n",
        "                if site_data:\n",
        "                    df = pd.DataFrame(site_data)\n",
        "                    integrated_results[site_name]['noaa_data'] = df\n",
        "                    integrated_results[site_name]['metadata']['sources_used'].append('NOAA')\n",
        "\n",
        "                    # Save raw NOAA data\n",
        "                    raw_noaa_file = f\"{output_dir}/{site_name}_noaa_raw_data.csv\"\n",
        "                    df.to_csv(raw_noaa_file, index=False)\n",
        "                    print(f\"  Raw NOAA data saved to: {raw_noaa_file}\")\n",
        "                else:\n",
        "                    print(f\"  No NOAA data collected for {site_name}\")\n",
        "            else:\n",
        "                print(f\"  No available variables from NOAA for {site_name}\")\n",
        "\n",
        "        # Fetch ERA5 data if available\n",
        "        if availability[site_name]['era5']['available']:\n",
        "            print(f\"  Fetching ERA5 data for {site_name}...\")\n",
        "\n",
        "            try:\n",
        "                import cdsapi\n",
        "                c = cdsapi.Client()\n",
        "\n",
        "                # Create an ERA5 subdirectory\n",
        "                era5_dir = f\"{output_dir}/era5\"\n",
        "                os.makedirs(era5_dir, exist_ok=True)\n",
        "\n",
        "                output_file = f\"{era5_dir}/{site_name}_era5.nc\"\n",
        "\n",
        "                # Define years and months\n",
        "                years = [str(year) for year in range(start_year, end_year + 1)]\n",
        "                months = [f\"{month:02d}\" for month in range(1, 13)]\n",
        "\n",
        "                # Request data\n",
        "                print(f\"  Requesting ERA5 data from CDS API for {site_name}...\")\n",
        "                c.retrieve(\n",
        "                    'reanalysis-era5-single-levels-monthly-means',\n",
        "                    {\n",
        "                        'product_type': 'monthly_averaged_reanalysis',\n",
        "                        'variable': ['2m_temperature', 'total_precipitation'],\n",
        "                        'year': years,\n",
        "                        'month': months,\n",
        "                        'time': '00:00',\n",
        "                        'area': [lat+1, lon-1, lat-1, lon+1],  # N/W/S/E\n",
        "                        'format': 'netcdf',\n",
        "                    },\n",
        "                    output_file)\n",
        "\n",
        "                print(f\"  ERA5 data downloaded to: {output_file}\")\n",
        "\n",
        "                # Load data\n",
        "                ds = xr.open_dataset(output_file)\n",
        "                ds = ds.sel(latitude=lat, longitude=lon, method='nearest')\n",
        "                integrated_results[site_name]['era5_data'] = ds\n",
        "                integrated_results[site_name]['metadata']['sources_used'].append('ERA5')\n",
        "\n",
        "                # Save as CSV for easier access\n",
        "                era5_csv_dir = f\"{output_dir}/era5_csv\"\n",
        "                os.makedirs(era5_csv_dir, exist_ok=True)\n",
        "\n",
        "                if 't2m' in ds:\n",
        "                    temp_df = ds['t2m'].to_dataframe().reset_index()\n",
        "                    temp_df.to_csv(f\"{era5_csv_dir}/{site_name}_era5_temperature.csv\", index=False)\n",
        "\n",
        "                if 'tp' in ds:\n",
        "                    precip_df = ds['tp'].to_dataframe().reset_index()\n",
        "                    precip_df.to_csv(f\"{era5_csv_dir}/{site_name}_era5_precipitation.csv\", index=False)\n",
        "\n",
        "                print(f\"  ERA5 data processed for {site_name}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Error fetching ERA5 data: {str(e)}\")\n",
        "\n",
        "    return integrated_results"
      ],
      "metadata": {
        "id": "5-BhSaT1wdLX"
      },
      "id": "5-BhSaT1wdLX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def integrate_climate_data(integrated_results):\n",
        "    for site_name, data in integrated_results.items():\n",
        "        print(f\"\\nIntegrating data for {site_name}...\")\n",
        "\n",
        "        # Initialize dataframes for different variables\n",
        "        temp_df = pd.DataFrame()\n",
        "        precip_df = pd.DataFrame()\n",
        "        wind_df = pd.DataFrame()\n",
        "        snow_df = pd.DataFrame()\n",
        "        cloud_df = pd.DataFrame()\n",
        "\n",
        "        # Process Frost data (MET Norway) if available - HIGHEST PRIORITY FOR NORWEGIAN SITES\n",
        "        if data.get('frost_data') is not None:\n",
        "            frost_df = data['frost_data'].get('dataframe')\n",
        "\n",
        "            if frost_df is not None and not frost_df.empty:\n",
        "                print(f\"  Processing Frost data...\")\n",
        "\n",
        "                frost_df['date'] = pd.to_datetime(frost_df['date'])\n",
        "                frost_df['year'] = frost_df['date'].dt.year\n",
        "                frost_df['month'] = frost_df['date'].dt.month\n",
        "\n",
        "                # Temperature data\n",
        "                temp_elements = ['air_temperature', 'mean(air_temperature P1D)',\n",
        "                               'min(air_temperature P1D)', 'max(air_temperature P1D)']\n",
        "\n",
        "                for elem in temp_elements:\n",
        "                    if elem in frost_df['element'].unique():\n",
        "                        elem_df = frost_df[frost_df['element'] == elem].copy()\n",
        "                        elem_annual = elem_df.groupby('year')['value'].mean().reset_index()\n",
        "\n",
        "                        # Map element to column name\n",
        "                        if elem == 'air_temperature':\n",
        "                            col_name = 'temp_frost'\n",
        "                        elif elem == 'mean(air_temperature P1D)':\n",
        "                            col_name = 'temp_mean_frost'\n",
        "                        elif elem == 'min(air_temperature P1D)':\n",
        "                            col_name = 'temp_min_frost'\n",
        "                        elif elem == 'max(air_temperature P1D)':\n",
        "                            col_name = 'temp_max_frost'\n",
        "\n",
        "                        elem_annual = elem_annual.rename(columns={'value': col_name})\n",
        "\n",
        "                        if temp_df.empty:\n",
        "                            temp_df = elem_annual\n",
        "                        else:\n",
        "                            temp_df = pd.merge(temp_df, elem_annual, on='year', how='outer')\n",
        "\n",
        "                # Precipitation data\n",
        "                precip_elements = ['sum(precipitation_amount P1D)']\n",
        "\n",
        "                for elem in precip_elements:\n",
        "                    if elem in frost_df['element'].unique():\n",
        "                        elem_df = frost_df[frost_df['element'] == elem].copy()\n",
        "                        elem_annual = elem_df.groupby('year')['value'].sum().reset_index()\n",
        "                        elem_annual = elem_annual.rename(columns={'value': 'prcp_frost'})\n",
        "\n",
        "                        if precip_df.empty:\n",
        "                            precip_df = elem_annual\n",
        "                        else:\n",
        "                            precip_df = pd.merge(precip_df, elem_annual, on='year', how='outer')\n",
        "\n",
        "                # Wind data\n",
        "                wind_elements = ['wind_speed', 'max(wind_speed P1D)']\n",
        "\n",
        "                for elem in wind_elements:\n",
        "                    if elem in frost_df['element'].unique():\n",
        "                        elem_df = frost_df[frost_df['element'] == elem].copy()\n",
        "                        elem_annual = elem_df.groupby('year')['value'].mean().reset_index()\n",
        "\n",
        "                        # Map element to column name\n",
        "                        if elem == 'wind_speed':\n",
        "                            col_name = 'wind_frost'\n",
        "                        elif elem == 'max(wind_speed P1D)':\n",
        "                            col_name = 'wind_max_frost'\n",
        "\n",
        "                        elem_annual = elem_annual.rename(columns={'value': col_name})\n",
        "\n",
        "                        if wind_df.empty:\n",
        "                            wind_df = elem_annual\n",
        "                        else:\n",
        "                            wind_df = pd.merge(wind_df, elem_annual, on='year', how='outer')\n",
        "\n",
        "                # Snow data\n",
        "                snow_elements = ['snow_depth']\n",
        "\n",
        "                for elem in snow_elements:\n",
        "                    if elem in frost_df['element'].unique():\n",
        "                        elem_df = frost_df[frost_df['element'] == elem].copy()\n",
        "                        elem_annual = elem_df.groupby('year')['value'].mean().reset_index()\n",
        "                        elem_annual = elem_annual.rename(columns={'value': 'snow_depth_frost'})\n",
        "\n",
        "                        if snow_df.empty:\n",
        "                            snow_df = elem_annual\n",
        "                        else:\n",
        "                            snow_df = pd.merge(snow_df, elem_annual, on='year', how='outer')\n",
        "\n",
        "        # Process SeNorge data if available - HIGH PRIORITY FOR NORWEGIAN SITES\n",
        "        if data.get('senorge_data') is not None:\n",
        "            senorge_data = data['senorge_data']\n",
        "\n",
        "            # Temperature data\n",
        "            if 'temperature' in senorge_data and not senorge_data['temperature'].empty:\n",
        "                print(f\"  Processing SeNorge temperature data...\")\n",
        "\n",
        "                temp_df_senorge = senorge_data['temperature'].copy()\n",
        "                temp_df_senorge['date'] = pd.to_datetime(temp_df_senorge['time'])\n",
        "                temp_df_senorge['year'] = temp_df_senorge['date'].dt.year\n",
        "\n",
        "                # Calculate annual means\n",
        "                temp_annual = temp_df_senorge.groupby('year')['tm'].mean().reset_index()\n",
        "                temp_annual = temp_annual.rename(columns={'tm': 'temp_senorge'})\n",
        "\n",
        "                if temp_df.empty:\n",
        "                    temp_df = temp_annual\n",
        "                else:\n",
        "                    temp_df = pd.merge(temp_df, temp_annual, on='year', how='outer')\n",
        "\n",
        "            # Precipitation data\n",
        "            if 'precipitation' in senorge_data and not senorge_data['precipitation'].empty:\n",
        "                print(f\"  Processing SeNorge precipitation data...\")\n",
        "\n",
        "                precip_df_senorge = senorge_data['precipitation'].copy()\n",
        "                precip_df_senorge['date'] = pd.to_datetime(precip_df_senorge['time'])\n",
        "                precip_df_senorge['year'] = precip_df_senorge['date'].dt.year\n",
        "\n",
        "                # Calculate annual sums\n",
        "                precip_annual = precip_df_senorge.groupby('year')['rr'].sum().reset_index()\n",
        "                precip_annual = precip_annual.rename(columns={'rr': 'prcp_senorge'})\n",
        "\n",
        "                if precip_df.empty:\n",
        "                    precip_df = precip_annual\n",
        "                else:\n",
        "                    precip_df = pd.merge(precip_df, precip_annual, on='year', how='outer')\n",
        "\n",
        "            # Snow data\n",
        "            if 'snow_depth' in senorge_data and not senorge_data['snow_depth'].empty:\n",
        "                print(f\"  Processing SeNorge snow depth data...\")\n",
        "\n",
        "                snow_df_senorge = senorge_data['snow_depth'].copy()\n",
        "                snow_df_senorge['date'] = pd.to_datetime(snow_df_senorge['time'])\n",
        "                snow_df_senorge['year'] = snow_df_senorge['date'].dt.year\n",
        "\n",
        "                # Calculate annual means\n",
        "                snow_annual = snow_df_senorge.groupby('year')['sd'].mean().reset_index()\n",
        "                snow_annual = snow_annual.rename(columns={'sd': 'snow_depth_senorge'})\n",
        "\n",
        "                if snow_df.empty:\n",
        "                    snow_df = snow_annual\n",
        "                else:\n",
        "                    snow_df = pd.merge(snow_df, snow_annual, on='year', how='outer')\n",
        "\n",
        "        # Process NVE glacier data if available - SPECIFIC TO GLACIER STUDY\n",
        "        if data.get('nve_data') is not None:\n",
        "            nve_data = data['nve_data']\n",
        "\n",
        "            # For NVE data, we'll create a separate dataframe for glacier-specific data\n",
        "            glacier_df = pd.DataFrame()\n",
        "\n",
        "            # Mass balance data\n",
        "            if 'mass_balance' in nve_data and nve_data['mass_balance'] is not None:\n",
        "                print(f\"  Processing NVE mass balance data...\")\n",
        "\n",
        "                mb_df = nve_data['mass_balance'].copy()\n",
        "\n",
        "                # Ensure we have a 'year' column\n",
        "                if 'year' not in mb_df.columns and 'date' in mb_df.columns:\n",
        "                    mb_df['date'] = pd.to_datetime(mb_df['date'])\n",
        "                    mb_df['year'] = mb_df['date'].dt.year\n",
        "\n",
        "                # Add to glacier dataframe\n",
        "                if glacier_df.empty:\n",
        "                    glacier_df = mb_df\n",
        "                else:\n",
        "                    # Merge on year\n",
        "                    glacier_df = pd.merge(glacier_df, mb_df, on='year', how='outer')\n",
        "\n",
        "            # Store glacier data\n",
        "            if not glacier_df.empty:\n",
        "                integrated_results[site_name]['integrated_data']['glacier'] = glacier_df\n",
        "\n",
        "        # Process NOAA data if available - LOWER PRIORITY THAN NORWEGIAN SOURCES\n",
        "        if data.get('noaa_data') is not None:\n",
        "            noaa_df = data['noaa_data']\n",
        "\n",
        "            # Convert date to datetime\n",
        "            if 'date' in noaa_df.columns:\n",
        "                noaa_df['date'] = pd.to_datetime(noaa_df['date'])\n",
        "                noaa_df['year'] = noaa_df['date'].dt.year\n",
        "                noaa_df['month'] = noaa_df['date'].dt.month\n",
        "\n",
        "                # Process temperature data (TMAX, TMIN)\n",
        "                if 'datatype' in noaa_df.columns:\n",
        "                    # Temperature - Max\n",
        "                    if 'TMAX' in noaa_df['datatype'].unique():\n",
        "                        print(f\"  Processing NOAA maximum temperature data...\")\n",
        "                        tmax_df = noaa_df[noaa_df['datatype'] == 'TMAX'].copy()\n",
        "                        tmax_annual = tmax_df.groupby('year')['value'].mean().reset_index()\n",
        "                        tmax_annual = tmax_annual.rename(columns={'value': 'tmax_noaa'})\n",
        "\n",
        "                        if temp_df.empty:\n",
        "                            temp_df = tmax_annual\n",
        "                        else:\n",
        "                            temp_df = pd.merge(temp_df, tmax_annual, on='year', how='outer')\n",
        "\n",
        "                    # Temperature - Min\n",
        "                    if 'TMIN' in noaa_df['datatype'].unique():\n",
        "                        print(f\"  Processing NOAA minimum temperature data...\")\n",
        "                        tmin_df = noaa_df[noaa_df['datatype'] == 'TMIN'].copy()\n",
        "                        tmin_annual = tmin_df.groupby('year')['value'].mean().reset_index()\n",
        "                        tmin_annual = tmin_annual.rename(columns={'value': 'tmin_noaa'})\n",
        "\n",
        "                        if temp_df.empty:\n",
        "                            temp_df = tmin_annual\n",
        "                        else:\n",
        "                            temp_df = pd.merge(temp_df, tmin_annual, on='year', how='outer')\n",
        "\n",
        "                    # Precipitation\n",
        "                    if 'PRCP' in noaa_df['datatype'].unique():\n",
        "                        print(f\"  Processing NOAA precipitation data...\")\n",
        "                        prcp_df = noaa_df[noaa_df['datatype'] == 'PRCP'].copy()\n",
        "                        prcp_annual = prcp_df.groupby('year')['value'].sum().reset_index()\n",
        "                        prcp_annual = prcp_annual.rename(columns={'value': 'prcp_noaa'})\n",
        "\n",
        "                        if precip_df.empty:\n",
        "                            precip_df = prcp_annual\n",
        "                        else:\n",
        "                            precip_df = pd.merge(precip_df, prcp_annual, on='year', how='outer')\n",
        "\n",
        "                    # Wind\n",
        "                    if 'AWND' in noaa_df['datatype'].unique():\n",
        "                        print(f\"  Processing NOAA wind data...\")\n",
        "                        wind_noaa_df = noaa_df[noaa_df['datatype'] == 'AWND'].copy()\n",
        "                        wind_annual = wind_noaa_df.groupby('year')['value'].mean().reset_index()\n",
        "                        wind_annual = wind_annual.rename(columns={'value': 'wind_noaa'})\n",
        "\n",
        "                        if wind_df.empty:\n",
        "                            wind_df = wind_annual\n",
        "                        else:\n",
        "                            wind_df = pd.merge(wind_df, wind_annual, on='year', how='outer')\n",
        "\n",
        "                    # Snow\n",
        "                    snow_vars = [var for var in ['SNOW', 'SNWD'] if var in noaa_df['datatype'].unique()]\n",
        "                    if snow_vars:\n",
        "                        print(f\"  Processing NOAA snow data...\")\n",
        "                        for var in snow_vars:\n",
        "                            snow_data = noaa_df[noaa_df['datatype'] == var].copy()\n",
        "                            if var == 'SNOW':  # Snowfall\n",
        "                                snow_annual = snow_data.groupby('year')['value'].sum().reset_index()\n",
        "                                snow_annual = snow_annual.rename(columns={'value': 'snowfall_noaa'})\n",
        "                            else:  # Snow depth\n",
        "                                snow_annual = snow_data.groupby('year')['value'].mean().reset_index()\n",
        "                                snow_annual = snow_annual.rename(columns={'value': 'snowdepth_noaa'})\n",
        "\n",
        "                            if snow_df.empty:\n",
        "                                snow_df = snow_annual\n",
        "                            else:\n",
        "                                snow_df = pd.merge(snow_df, snow_annual, on='year', how='outer')\n",
        "\n",
        "                    # Cloudiness\n",
        "                    if 'ACSH' in noaa_df['datatype'].unique():\n",
        "                        print(f\"  Processing NOAA cloudiness data...\")\n",
        "                        cloud_df_noaa = noaa_df[noaa_df['datatype'] == 'ACSH'].copy()\n",
        "                        cloud_annual = cloud_df_noaa.groupby('year')['value'].mean().reset_index()\n",
        "                        cloud_annual = cloud_annual.rename(columns={'value': 'cloud_noaa'})\n",
        "\n",
        "                        if cloud_df.empty:\n",
        "                            cloud_df = cloud_annual\n",
        "                        else:\n",
        "                            cloud_df = pd.merge(cloud_df, cloud_annual, on='year', how='outer')\n",
        "\n",
        "        # Process ERA5 data if available - LOWER PRIORITY THAN NORWEGIAN SOURCES\n",
        "        if data.get('era5_data') is not None:\n",
        "            era5_ds = data['era5_data']\n",
        "\n",
        "            # Temperature (convert from K to °C)\n",
        "            if 't2m' in era5_ds:\n",
        "                print(f\"  Processing ERA5 temperature data...\")\n",
        "                temp_data = era5_ds['t2m'] - 273.15\n",
        "                if 'time' in temp_data.dims:\n",
        "                    temp_data = temp_data.assign_coords(year=temp_data.time.dt.year)\n",
        "                    annual_temp = temp_data.groupby('year').mean()\n",
        "                    era5_temp_df = annual_temp.to_dataframe().reset_index()\n",
        "                    era5_temp_df = era5_temp_df.rename(columns={'t2m': 'temp_era5'})\n",
        "                    era5_temp_df = era5_temp_df[['year', 'temp_era5']]\n",
        "\n",
        "                    if temp_df.empty:\n",
        "                        temp_df = era5_temp_df\n",
        "                    else:\n",
        "                        temp_df = pd.merge(temp_df, era5_temp_df, on='year', how='outer')\n",
        "\n",
        "            # Precipitation (convert from m to mm)\n",
        "            if 'tp' in era5_ds:\n",
        "                print(f\"  Processing ERA5 precipitation data...\")\n",
        "                precip_data = era5_ds['tp'] * 1000\n",
        "                if 'time' in precip_data.dims:\n",
        "                    precip_data = precip_data.assign_coords(year=precip_data.time.dt.year)\n",
        "                    hours_in_month = 730.5\n",
        "                    precip_data = precip_data * hours_in_month\n",
        "                    annual_precip = precip_data.groupby('year').sum()\n",
        "                    era5_precip_df = annual_precip.to_dataframe().reset_index()\n",
        "                    era5_precip_df = era5_precip_df.rename(columns={'tp': 'prcp_era5'})\n",
        "                    era5_precip_df = era5_precip_df[['year', 'prcp_era5']]\n",
        "\n",
        "                    if precip_df.empty:\n",
        "                        precip_df = era5_precip_df\n",
        "                    else:\n",
        "                        precip_df = pd.merge(precip_df, era5_precip_df, on='year', how='outer')\n",
        "\n",
        "        # Process CHELSA data if available - LOWER PRIORITY\n",
        "        if data.get('chelsa_data') is not None:\n",
        "            chelsa_data = data['chelsa_data']\n",
        "\n",
        "            # Temperature data\n",
        "            if 'temperature' in chelsa_data and chelsa_data['temperature'] is not None:\n",
        "                print(f\"  Processing CHELSA temperature data...\")\n",
        "\n",
        "                # CHELSA data is climatology (monthly averages), not annual data\n",
        "                # We'll create a mean annual temperature for the climatology period\n",
        "                temp_df_chelsa = chelsa_data['temperature'].copy()\n",
        "\n",
        "                if not temp_df_chelsa.empty:\n",
        "                    # Calculate annual mean from monthly data\n",
        "                    mean_temp = temp_df_chelsa['temperature'].mean()\n",
        "\n",
        "                    # Create a dataframe with the climatological mean\n",
        "                    # spanning the climatology period (1981-2010)\n",
        "                    years = list(range(1981, 2011))\n",
        "                    chelsa_temp_df = pd.DataFrame({\n",
        "                        'year': years,\n",
        "                        'temp_chelsa': [mean_temp] * len(years)\n",
        "                    })\n",
        "\n",
        "                    # Merge with existing temperature data\n",
        "                    if temp_df.empty:\n",
        "                        temp_df = chelsa_temp_df\n",
        "                    else:\n",
        "                        temp_df = pd.merge(temp_df, chelsa_temp_df, on='year', how='outer')\n",
        "\n",
        "            # Precipitation data\n",
        "            if 'precipitation' in chelsa_data and chelsa_data['precipitation'] is not None:\n",
        "                print(f\"  Processing CHELSA precipitation data...\")\n",
        "\n",
        "                precip_df_chelsa = chelsa_data['precipitation'].copy()\n",
        "\n",
        "                if not precip_df_chelsa.empty:\n",
        "                    # Calculate annual sum from monthly data\n",
        "                    annual_precip = precip_df_chelsa['precipitation'].sum()\n",
        "\n",
        "                    # Create a dataframe with the climatological annual sum\n",
        "                    years = list(range(1981, 2011))\n",
        "                    chelsa_precip_df = pd.DataFrame({\n",
        "                        'year': years,\n",
        "                        'prcp_chelsa': [annual_precip] * len(years)\n",
        "                    })\n",
        "\n",
        "                    # Merge with existing precipitation data\n",
        "                    if precip_df.empty:\n",
        "                        precip_df = chelsa_precip_df\n",
        "                    else:\n",
        "                        precip_df = pd.merge(precip_df, chelsa_precip_df, on='year', how='outer')\n",
        "\n",
        "        # Process E-OBS data if available - LOWEST PRIORITY\n",
        "        if data.get('eobs_data') is not None:\n",
        "            eobs_data = data['eobs_data']\n",
        "\n",
        "            # Temperature data\n",
        "            if 'temperature' in eobs_data and eobs_data['temperature'] is not None:\n",
        "                print(f\"  Processing E-OBS temperature data...\")\n",
        "\n",
        "                temp_df_eobs = eobs_data['temperature'].copy()\n",
        "                temp_df_eobs['date'] = pd.to_datetime(temp_df_eobs['date'])\n",
        "                temp_df_eobs['year'] = temp_df_eobs['date'].dt.year\n",
        "\n",
        "                # Calculate annual means\n",
        "                temp_annual = temp_df_eobs.groupby('year')['temperature'].mean().reset_index()\n",
        "                temp_annual = temp_annual.rename(columns={'temperature': 'temp_eobs'})\n",
        "\n",
        "                if temp_df.empty:\n",
        "                    temp_df = temp_annual\n",
        "                else:\n",
        "                    temp_df = pd.merge(temp_df, temp_annual, on='year', how='outer')\n",
        "\n",
        "            # Precipitation data\n",
        "            if 'precipitation' in eobs_data and eobs_data['precipitation'] is not None:\n",
        "                print(f\"  Processing E-OBS precipitation data...\")\n",
        "\n",
        "                precip_df_eobs = eobs_data['precipitation'].copy()\n",
        "                precip_df_eobs['date'] = pd.to_datetime(precip_df_eobs['date'])\n",
        "                precip_df_eobs['year'] = precip_df_eobs['date'].dt.year\n",
        "\n",
        "                # Calculate annual sums\n",
        "                precip_annual = precip_df_eobs.groupby('year')['precipitation'].sum().reset_index()\n",
        "                precip_annual = precip_annual.rename(columns={'precipitation': 'prcp_eobs'})\n",
        "\n",
        "                if precip_df.empty:\n",
        "                    precip_df = precip_annual\n",
        "                else:\n",
        "                    precip_df = pd.merge(precip_df, precip_annual, on='year', how='outer')\n",
        "\n",
        "        # Create combined variables from multiple sources based on priority\n",
        "\n",
        "        # Temperature - Combine all sources with priority order\n",
        "        if not temp_df.empty:\n",
        "            print(f\"  Creating combined temperature variable...\")\n",
        "\n",
        "            # Priority order for temperature:\n",
        "            # 1. Frost (MET Norway) - temp_mean_frost or temp_frost\n",
        "            # 2. SeNorge - temp_senorge\n",
        "            # 3. NOAA - tavg_noaa (average of tmax_noaa and tmin_noaa)\n",
        "            # 4. ERA5 - temp_era5\n",
        "            # 5. CHELSA - temp_chelsa\n",
        "            # 6. E-OBS - temp_eobs\n",
        "\n",
        "            # Start with an empty combined column\n",
        "            temp_df['temp_combined'] = np.nan\n",
        "\n",
        "            # Apply each source in priority order\n",
        "            if 'temp_mean_frost' in temp_df.columns:\n",
        "                temp_df['temp_combined'] = temp_df['temp_mean_frost']\n",
        "            elif 'temp_frost' in temp_df.columns:\n",
        "                temp_df['temp_combined'] = temp_df['temp_frost']\n",
        "\n",
        "            # If there are still NaN values, fill with SeNorge data\n",
        "            if 'temp_senorge' in temp_df.columns:\n",
        "                temp_df['temp_combined'] = temp_df['temp_combined'].fillna(temp_df['temp_senorge'])\n",
        "\n",
        "            # If there are still NaN values, use NOAA average temperature\n",
        "            if 'tmax_noaa' in temp_df.columns and 'tmin_noaa' in temp_df.columns:\n",
        "                temp_df['tavg_noaa'] = (temp_df['tmax_noaa'] + temp_df['tmin_noaa']) / 2\n",
        "                temp_df['temp_combined'] = temp_df['temp_combined'].fillna(temp_df['tavg_noaa'])\n",
        "\n",
        "            # If there are still NaN values, use ERA5 data\n",
        "            if 'temp_era5' in temp_df.columns:\n",
        "                temp_df['temp_combined'] = temp_df['temp_combined'].fillna(temp_df['temp_era5'])\n",
        "\n",
        "            # If there are still NaN values, use CHELSA data\n",
        "            if 'temp_chelsa' in temp_df.columns:\n",
        "                temp_df['temp_combined'] = temp_df['temp_combined'].fillna(temp_df['temp_chelsa'])\n",
        "\n",
        "            # If there are still NaN values, use E-OBS data\n",
        "            if 'temp_eobs' in temp_df.columns:\n",
        "                temp_df['temp_combined'] = temp_df['temp_combined'].fillna(temp_df['temp_eobs'])\n",
        "\n",
        "            # Calculate temperature trend\n",
        "            if 'temp_combined' in temp_df.columns:\n",
        "                temp_df = temp_df.sort_values('year')\n",
        "                years = temp_df['year'].values\n",
        "                temps = temp_df['temp_combined'].values\n",
        "                # Remove NaN values for regression\n",
        "                valid_idx = ~np.isnan(temps)\n",
        "                if sum(valid_idx) > 1:  # Need at least 2 points for regression\n",
        "                    slope, intercept, r_value, p_value, std_err = stats.linregress(\n",
        "                        years[valid_idx], temps[valid_idx]\n",
        "                    )\n",
        "                    temp_df['trend_value'] = intercept + slope * temp_df['year']\n",
        "                    print(f\"  Temperature trend: {slope:.4f}°C/year (p={p_value:.4f}, r²={r_value**2:.4f})\")\n",
        "\n",
        "        # Precipitation - Combine all sources with priority order\n",
        "        if not precip_df.empty:\n",
        "            print(f\"  Creating combined precipitation variable...\")\n",
        "\n",
        "            # Priority order for precipitation:\n",
        "            # 1. Frost (MET Norway) - prcp_frost\n",
        "            # 2. SeNorge - prcp_senorge\n",
        "            # 3. NOAA - prcp_noaa\n",
        "            # 4. ERA5 - prcp_era5\n",
        "            # 5. CHELSA - prcp_chelsa\n",
        "            # 6. E-OBS - prcp_eobs\n",
        "\n",
        "            # Start with an empty combined column\n",
        "            precip_df['prcp_combined'] = np.nan\n",
        "\n",
        "            # Apply each source in priority order\n",
        "            if 'prcp_frost' in precip_df.columns:\n",
        "                precip_df['prcp_combined'] = precip_df['prcp_frost']\n",
        "\n",
        "            # If there are still NaN values, fill with SeNorge data\n",
        "            if 'prcp_senorge' in precip_df.columns:\n",
        "                precip_df['prcp_combined'] = precip_df['prcp_combined'].fillna(precip_df['prcp_senorge'])\n",
        "\n",
        "            # If there are still NaN values, use NOAA data\n",
        "            if 'prcp_noaa' in precip_df.columns:\n",
        "                precip_df['prcp_combined'] = precip_df['prcp_combined'].fillna(precip_df['prcp_noaa'])\n",
        "\n",
        "            # If there are still NaN values, use ERA5 data\n",
        "            if 'prcp_era5' in precip_df.columns:\n",
        "                precip_df['prcp_combined'] = precip_df['prcp_combined'].fillna(precip_df['prcp_era5'])\n",
        "\n",
        "            # If there are still NaN values, use CHELSA data\n",
        "            if 'prcp_chelsa' in precip_df.columns:\n",
        "                precip_df['prcp_combined'] = precip_df['prcp_combined'].fillna(precip_df['prcp_chelsa'])\n",
        "\n",
        "            # If there are still NaN values, use E-OBS data\n",
        "            if 'prcp_eobs' in precip_df.columns:\n",
        "                precip_df['prcp_combined'] = precip_df['prcp_combined'].fillna(precip_df['prcp_eobs'])\n",
        "\n",
        "            # Calculate precipitation trend\n",
        "            if 'prcp_combined' in precip_df.columns:\n",
        "                precip_df = precip_df.sort_values('year')\n",
        "                years = precip_df['year'].values\n",
        "                precips = precip_df['prcp_combined'].values\n",
        "                # Remove NaN values for regression\n",
        "                valid_idx = ~np.isnan(precips)\n",
        "                if sum(valid_idx) > 1:  # Need at least 2 points for regression\n",
        "                    slope, intercept, r_value, p_value, std_err = stats.linregress(\n",
        "                        years[valid_idx], precips[valid_idx]\n",
        "                    )\n",
        "                    precip_df['trend_value'] = intercept + slope * precip_df['year']\n",
        "                    print(f\"  Precipitation trend: {slope:.2f}mm/year (p={p_value:.4f}, r²={r_value**2:.4f})\")\n",
        "\n",
        "        # Snow - Combine all sources with priority order\n",
        "        if not snow_df.empty:\n",
        "            print(f\"  Creating combined snow variable...\")\n",
        "\n",
        "            # Priority order for snow depth:\n",
        "            # 1. Frost (MET Norway) - snow_depth_frost\n",
        "            # 2. SeNorge - snow_depth_senorge\n",
        "            # 3. NOAA - snowdepth_noaa\n",
        "\n",
        "            # Start with an empty combined column\n",
        "            snow_df['snow_depth_combined'] = np.nan\n",
        "\n",
        "            # Apply each source in priority order\n",
        "            if 'snow_depth_frost' in snow_df.columns:\n",
        "                snow_df['snow_depth_combined'] = snow_df['snow_depth_frost']\n",
        "\n",
        "            # If there are still NaN values, fill with SeNorge data\n",
        "            if 'snow_depth_senorge' in snow_df.columns:\n",
        "                snow_df['snow_depth_combined'] = snow_df['snow_depth_combined'].fillna(snow_df['snow_depth_senorge'])\n",
        "\n",
        "            # If there are still NaN values, use NOAA data\n",
        "            if 'snowdepth_noaa' in snow_df.columns:\n",
        "                snow_df['snow_depth_combined'] = snow_df['snow_depth_combined'].fillna(snow_df['snowdepth_noaa'])\n",
        "\n",
        "        # Wind - Combine all sources with priority order\n",
        "        if not wind_df.empty:\n",
        "            print(f\"  Creating combined wind variable...\")\n",
        "\n",
        "            # Priority order for wind:\n",
        "            # 1. Frost (MET Norway) - wind_frost\n",
        "            # 2. NOAA - wind_noaa\n",
        "\n",
        "            # Start with an empty combined column\n",
        "            wind_df['wind_combined'] = np.nan\n",
        "\n",
        "            # Apply each source in priority order\n",
        "            if 'wind_frost' in wind_df.columns:\n",
        "                wind_df['wind_combined'] = wind_df['wind_frost']\n",
        "\n",
        "            # If there are still NaN values, use NOAA data\n",
        "            if 'wind_noaa' in wind_df.columns:\n",
        "                wind_df['wind_combined'] = wind_df['wind_combined'].fillna(wind_df['wind_noaa'])\n",
        "\n",
        "        # Store integrated data\n",
        "        integrated_results[site_name]['integrated_data']['temperature'] = temp_df\n",
        "        integrated_results[site_name]['integrated_data']['precipitation'] = precip_df\n",
        "        integrated_results[site_name]['integrated_data']['wind'] = wind_df\n",
        "        integrated_results[site_name]['integrated_data']['snow'] = snow_df\n",
        "        integrated_results[site_name]['integrated_data']['cloudiness'] = cloud_df\n",
        "\n",
        "    return integrated_results"
      ],
      "metadata": {
        "id": "0L6jDZ_owiY2"
      },
      "id": "0L6jDZ_owiY2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def export_integrated_data(integrated_results, output_dir=\"/content/climate_outputs\"):\n",
        "    \"\"\"\n",
        "    Export and visualize the integrated climate data.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    integrated_results : dict\n",
        "        Dictionary with integrated climate data\n",
        "    output_dir : str, optional\n",
        "        Directory to save output files\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Create subdirectories for different data types\n",
        "    integrated_dir = f\"{output_dir}/integrated\"\n",
        "    plots_dir = f\"{output_dir}/plots\"\n",
        "\n",
        "    os.makedirs(integrated_dir, exist_ok=True)\n",
        "    os.makedirs(plots_dir, exist_ok=True)\n",
        "\n",
        "    for site_name, data in integrated_results.items():\n",
        "        print(f\"\\n===== Exporting Integrated Data for {site_name} =====\")\n",
        "\n",
        "        # Create site-specific subdirectories\n",
        "        site_dir = f\"{integrated_dir}/{site_name}\"\n",
        "        site_plots_dir = f\"{plots_dir}/{site_name}\"\n",
        "\n",
        "        os.makedirs(site_dir, exist_ok=True)\n",
        "        os.makedirs(site_plots_dir, exist_ok=True)\n",
        "\n",
        "        # Export metadata\n",
        "        if 'metadata' in data:\n",
        "            metadata_file = f\"{site_dir}/metadata.json\"\n",
        "            # Convert metadata to a format that can be saved as JSON\n",
        "            metadata = {\n",
        "                'site_name': data['metadata']['site_name'],\n",
        "                'latitude': float(data['metadata']['latitude']),\n",
        "                'longitude': float(data['metadata']['longitude']),\n",
        "                'sources_used': data['metadata']['sources_used']\n",
        "            }\n",
        "\n",
        "            if data['metadata']['noaa_station']:\n",
        "                metadata['noaa_station'] = {\n",
        "                    'id': data['metadata']['noaa_station']['id'],\n",
        "                    'name': data['metadata']['noaa_station']['name'],\n",
        "                    'latitude': float(data['metadata']['noaa_station']['latitude']),\n",
        "                    'longitude': float(data['metadata']['noaa_station']['longitude'])\n",
        "                }\n",
        "\n",
        "            # Save metadata\n",
        "            import json\n",
        "            with open(metadata_file, 'w') as f:\n",
        "                json.dump(metadata, f, indent=4)\n",
        "            print(f\"Metadata saved to: {metadata_file}\")\n",
        "\n",
        "        # Temperature data\n",
        "        temp_df = data['integrated_data']['temperature']\n",
        "        if not temp_df.empty:\n",
        "            temp_file = f\"{site_dir}/temperature.csv\"\n",
        "            temp_df.to_csv(temp_file, index=False)\n",
        "            print(f\"Temperature data saved to: {temp_file}\")\n",
        "\n",
        "            # Plot temperature data\n",
        "            if 'temp_combined' in temp_df.columns:\n",
        "                plt.figure(figsize=(12, 6))\n",
        "\n",
        "                # Plot the actual temperature data\n",
        "                plt.plot(temp_df['year'], temp_df['temp_combined'], marker='o', linestyle='-',\n",
        "                         color='blue', label='Combined Temperature')\n",
        "\n",
        "                # If we have tmax and tmin from NOAA, plot those too\n",
        "                if 'tmax_noaa' in temp_df.columns:\n",
        "                    plt.plot(temp_df['year'], temp_df['tmax_noaa'], marker='^', linestyle='--',\n",
        "                             color='red', alpha=0.7, label='NOAA Max Temp')\n",
        "                if 'tmin_noaa' in temp_df.columns:\n",
        "                    plt.plot(temp_df['year'], temp_df['tmin_noaa'], marker='v', linestyle='--',\n",
        "                             color='blue', alpha=0.7, label='NOAA Min Temp')\n",
        "\n",
        "                # If we have ERA5 temperature, plot that too\n",
        "                if 'temp_era5' in temp_df.columns:\n",
        "                    plt.plot(temp_df['year'], temp_df['temp_era5'], marker='s', linestyle=':',\n",
        "                             color='green', alpha=0.7, label='ERA5 Temperature')\n",
        "\n",
        "                # If we calculated a trend, plot it\n",
        "                if 'trend_value' in temp_df.columns:\n",
        "                    plt.plot(temp_df['year'], temp_df['trend_value'], linestyle='-',\n",
        "                             color='black', alpha=0.7, label='Trend')\n",
        "\n",
        "                plt.title(f'Annual Temperature for {site_name}')\n",
        "                plt.xlabel('Year')\n",
        "                plt.ylabel('Temperature (°C)')\n",
        "                plt.legend()\n",
        "                plt.grid(True, alpha=0.3)\n",
        "\n",
        "                # Add a horizontal line at 0°C\n",
        "                plt.axhline(y=0, color='gray', linestyle='-', alpha=0.5)\n",
        "\n",
        "                # Save the plot\n",
        "                temp_plot_file = f\"{site_plots_dir}/temperature_trend.png\"\n",
        "                plt.savefig(temp_plot_file, dpi=300)\n",
        "                plt.close()\n",
        "                print(f\"Temperature plot saved to: {temp_plot_file}\")\n",
        "\n",
        "        # Precipitation data\n",
        "        precip_df = data['integrated_data']['precipitation']\n",
        "        if not precip_df.empty:\n",
        "            precip_file = f\"{site_dir}/precipitation.csv\"\n",
        "            precip_df.to_csv(precip_file, index=False)\n",
        "            print(f\"Precipitation data saved to: {precip_file}\")\n",
        "\n",
        "            # Plot precipitation data\n",
        "            if 'prcp_combined' in precip_df.columns:\n",
        "                plt.figure(figsize=(12, 6))\n",
        "\n",
        "                # Plot the actual precipitation data\n",
        "                plt.plot(precip_df['year'], precip_df['prcp_combined'], marker='o', linestyle='-',\n",
        "                         color='blue', label='Combined Precipitation')\n",
        "\n",
        "                # If we have NOAA precipitation, plot that too\n",
        "                if 'prcp_noaa' in precip_df.columns:\n",
        "                    plt.plot(precip_df['year'], precip_df['prcp_noaa'], marker='^', linestyle='--',\n",
        "                             color='red', alpha=0.7, label='NOAA Precipitation')\n",
        "\n",
        "                # If we have ERA5 precipitation, plot that too\n",
        "                if 'prcp_era5' in precip_df.columns:\n",
        "                    plt.plot(precip_df['year'], precip_df['prcp_era5'], marker='s', linestyle=':',\n",
        "                             color='green', alpha=0.7, label='ERA5 Precipitation')\n",
        "\n",
        "                # If we calculated a trend, plot it\n",
        "                if 'trend_value' in precip_df.columns:\n",
        "                    plt.plot(precip_df['year'], precip_df['trend_value'], linestyle='-',\n",
        "                             color='black', alpha=0.7, label='Trend')\n",
        "\n",
        "                plt.title(f'Annual Precipitation for {site_name}')\n",
        "                plt.xlabel('Year')\n",
        "                plt.ylabel('Precipitation (mm)')\n",
        "                plt.legend()\n",
        "                plt.grid(True, alpha=0.3)\n",
        "\n",
        "                # Save the plot\n",
        "                precip_plot_file = f\"{site_plots_dir}/precipitation_trend.png\"\n",
        "                plt.savefig(precip_plot_file, dpi=300)\n",
        "                plt.close()\n",
        "                print(f\"Precipitation plot saved to: {precip_plot_file}\")\n",
        "\n",
        "        # Wind data\n",
        "        wind_df = data['integrated_data']['wind']\n",
        "        if not wind_df.empty:\n",
        "            wind_file = f\"{site_dir}/wind.csv\"\n",
        "            wind_df.to_csv(wind_file, index=False)\n",
        "            print(f\"Wind data saved to: {wind_file}\")\n",
        "\n",
        "            # Plot wind data\n",
        "            if 'wind_noaa' in wind_df.columns:\n",
        "                plt.figure(figsize=(12, 6))\n",
        "                plt.plot(wind_df['year'], wind_df['wind_noaa'], marker='o', linestyle='-', color='blue')\n",
        "                plt.title(f'Annual Average Wind Speed for {site_name}')\n",
        "                plt.xlabel('Year')\n",
        "                plt.ylabel('Wind Speed (m/s)')\n",
        "                plt.grid(True, alpha=0.3)\n",
        "\n",
        "                # Save the plot\n",
        "                wind_plot_file = f\"{site_plots_dir}/wind_trend.png\"\n",
        "                plt.savefig(wind_plot_file, dpi=300)\n",
        "                plt.close()\n",
        "                print(f\"Wind plot saved to: {wind_plot_file}\")\n",
        "\n",
        "        # Snow data\n",
        "        snow_df = data['integrated_data']['snow']\n",
        "        if not snow_df.empty:\n",
        "            snow_file = f\"{site_dir}/snow.csv\"\n",
        "            snow_df.to_csv(snow_file, index=False)\n",
        "            print(f\"Snow data saved to: {snow_file}\")\n",
        "\n",
        "            # Plot snow data if we have snowfall or snow depth\n",
        "            if 'snowfall_noaa' in snow_df.columns or 'snowdepth_noaa' in snow_df.columns:\n",
        "                plt.figure(figsize=(12, 6))\n",
        "\n",
        "                if 'snowfall_noaa' in snow_df.columns:\n",
        "                    plt.plot(snow_df['year'], snow_df['snowfall_noaa'], marker='o', linestyle='-',\n",
        "                             color='blue', label='Snowfall')\n",
        "\n",
        "                if 'snowdepth_noaa' in snow_df.columns:\n",
        "                    plt.plot(snow_df['year'], snow_df['snowdepth_noaa'], marker='^', linestyle='--',\n",
        "                             color='red', label='Snow Depth')\n",
        "\n",
        "                plt.title(f'Annual Snow Data for {site_name}')\n",
        "                plt.xlabel('Year')\n",
        "                plt.ylabel('Snow (mm)')\n",
        "                plt.legend()\n",
        "                plt.grid(True, alpha=0.3)\n",
        "\n",
        "                # Save the plot\n",
        "                snow_plot_file = f\"{site_plots_dir}/snow_trend.png\"\n",
        "                plt.savefig(snow_plot_file, dpi=300)\n",
        "                plt.close()\n",
        "                print(f\"Snow plot saved to: {snow_plot_file}\")\n",
        "\n",
        "        # Cloudiness data\n",
        "        cloud_df = data['integrated_data']['cloudiness']\n",
        "        if not cloud_df.empty:\n",
        "            cloud_file = f\"{site_dir}/cloudiness.csv\"\n",
        "            cloud_df.to_csv(cloud_file, index=False)\n",
        "            print(f\"Cloudiness data saved to: {cloud_file}\")\n",
        "\n",
        "            # Plot cloudiness data\n",
        "            if 'cloud_noaa' in cloud_df.columns:\n",
        "                plt.figure(figsize=(12, 6))\n",
        "                plt.plot(cloud_df['year'], cloud_df['cloud_noaa'], marker='o', linestyle='-', color='blue')\n",
        "                plt.title(f'Annual Average Cloudiness for {site_name}')\n",
        "                plt.xlabel('Year')\n",
        "                plt.ylabel('Cloudiness (%)')\n",
        "                plt.grid(True, alpha=0.3)\n",
        "\n",
        "                # Save the plot\n",
        "                cloud_plot_file = f\"{site_plots_dir}/cloudiness_trend.png\"\n",
        "                plt.savefig(cloud_plot_file, dpi=300)\n",
        "                plt.close()\n",
        "                print(f\"Cloudiness plot saved to: {cloud_plot_file}\")\n",
        "\n",
        "        # Create a comprehensive integrated dataset\n",
        "        print(f\"Creating comprehensive dataset for {site_name}...\")\n",
        "\n",
        "        # Start with temperature data as the base\n",
        "        if not temp_df.empty:\n",
        "            comprehensive_df = temp_df.copy()\n",
        "\n",
        "            # Add precipitation data\n",
        "            if not precip_df.empty:\n",
        "                # Only keep the year and combined precipitation columns\n",
        "                precip_cols = ['year', 'prcp_combined'] if 'prcp_combined' in precip_df.columns else ['year']\n",
        "                precip_cols.extend([col for col in precip_df.columns if col.startswith('prcp_') and col != 'prcp_combined'])\n",
        "                precip_subset = precip_df[precip_cols].copy()\n",
        "\n",
        "                # Merge with existing data\n",
        "                comprehensive_df = pd.merge(comprehensive_df, precip_subset, on='year', how='outer')\n",
        "\n",
        "            # Add wind data\n",
        "            if not wind_df.empty:\n",
        "                # Only keep the year and wind columns\n",
        "                wind_cols = ['year'] + [col for col in wind_df.columns if col.startswith('wind_')]\n",
        "                wind_subset = wind_df[wind_cols].copy()\n",
        "\n",
        "                # Merge with existing data\n",
        "                comprehensive_df = pd.merge(comprehensive_df, wind_subset, on='year', how='outer')\n",
        "\n",
        "            # Add snow data\n",
        "            if not snow_df.empty:\n",
        "                # Only keep the year and snow columns\n",
        "                snow_cols = ['year'] + [col for col in snow_df.columns if col.startswith('snow')]\n",
        "                snow_subset = snow_df[snow_cols].copy()\n",
        "\n",
        "                # Merge with existing data\n",
        "                comprehensive_df = pd.merge(comprehensive_df, snow_subset, on='year', how='outer')\n",
        "\n",
        "            # Add cloudiness data\n",
        "            if not cloud_df.empty:\n",
        "                # Only keep the year and cloudiness columns\n",
        "                cloud_cols = ['year'] + [col for col in cloud_df.columns if col.startswith('cloud')]\n",
        "                cloud_subset = cloud_df[cloud_cols].copy()\n",
        "\n",
        "                # Merge with existing data\n",
        "                comprehensive_df = pd.merge(comprehensive_df, cloud_subset, on='year', how='outer')\n",
        "\n",
        "            # Sort by year\n",
        "            comprehensive_df = comprehensive_df.sort_values('year')\n",
        "\n",
        "            # Save the comprehensive dataset\n",
        "            comprehensive_file = f\"{site_dir}/comprehensive_climate_data.csv\"\n",
        "            comprehensive_df.to_csv(comprehensive_file, index=False)\n",
        "            print(f\"Comprehensive climate data saved to: {comprehensive_file}\")\n",
        "        else:\n",
        "            print(f\"Warning: No temperature data available for {site_name}, skipping comprehensive dataset\")"
      ],
      "metadata": {
        "id": "gKbvJgJ-wqwf"
      },
      "id": "gKbvJgJ-wqwf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_zip_download(output_dir, zip_filename=\"climate_data_outputs.zip\"):\n",
        "    print(f\"Creating zip file of all outputs for download: {zip_filename}\")\n",
        "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "        for root, _, files in os.walk(output_dir):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                # Add file to zip with a relative path\n",
        "                zipf.write(file_path, os.path.relpath(file_path, os.path.dirname(output_dir)))\n",
        "\n",
        "    print(f\"Zip file created: {zip_filename}\")\n",
        "    return zip_filename"
      ],
      "metadata": {
        "id": "SxZHZ78Iwtep"
      },
      "id": "SxZHZ78Iwtep",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_integrated_climate_analysis(sites_df, start_year=1979, end_year=None, output_dir=\"/content/climate_outputs\"):\n",
        "    if end_year is None:\n",
        "        end_year = datetime.now().year\n",
        "\n",
        "    print(\"\\n===== INTEGRATED CLIMATE DATA ANALYSIS FOR NORWEGIAN GLACIERS =====\")\n",
        "    print(f\"Start year: {start_year}\")\n",
        "    print(f\"End year: {end_year}\")\n",
        "    print(f\"Output directory: {output_dir}\")\n",
        "\n",
        "    # 1. Check API credentials\n",
        "    print(\"\\nStep 1: Setting up API credentials\")\n",
        "\n",
        "    # MET Norway Frost API (highest priority for Norwegian glaciers)\n",
        "    frost_client_id = input(\"Enter your MET Norway Frost API client ID (leave blank to skip Frost data): \")\n",
        "\n",
        "    # NOAA API\n",
        "    noaa_token = input(\"Enter your NOAA API token (leave blank to skip NOAA data): \")\n",
        "\n",
        "    # CDS API\n",
        "    use_cds = input(\"Use Climate Data Store (CDS) ERA5 data? (y/n): \").lower() == 'y'\n",
        "    cds_setup = False\n",
        "    if use_cds:\n",
        "        cds_setup = setup_cds_api()\n",
        "\n",
        "    print(\"\\n==== DEBUGGING: API CREDENTIALS ====\")\n",
        "    print(f\"Frost client ID provided: {'Yes' if frost_client_id else 'No'}\")\n",
        "    print(f\"NOAA token provided: {'Yes' if noaa_token else 'No'}\")\n",
        "    print(f\"CDS setup successful: {'Yes' if cds_setup else 'No'}\")\n",
        "\n",
        "    # 2. Verify data availability\n",
        "    print(\"\\nStep 2: Verifying data availability for each site and source\")\n",
        "    availability = verify_data_availability(sites_df, noaa_token, cds_setup, frost_client_id)\n",
        "\n",
        "    # Display availability summary\n",
        "    print(\"\\nData Availability Summary:\")\n",
        "    for site, sources in availability.items():\n",
        "        print(f\"\\n{site}:\")\n",
        "\n",
        "        # Frost (highest priority for Norwegian sites)\n",
        "        if sources['frost']['available']:\n",
        "            print(\"  MET Norway Frost: Available\")\n",
        "            print(\"    Variables:\")\n",
        "            for var, avail in sources['frost']['variables'].items():\n",
        "                print(f\"      {var}: {'✓' if avail else '✗'}\")\n",
        "        else:\n",
        "            print(\"  MET Norway Frost: Not available\")\n",
        "\n",
        "        # SeNorge (high priority for Norwegian sites)\n",
        "        if sources['senorge']['available']:\n",
        "            print(\"  SeNorge: Available\")\n",
        "            print(\"    Variables:\")\n",
        "            for var, avail in sources['senorge']['variables'].items():\n",
        "                print(f\"      {var}: {'✓' if avail else '✗'}\")\n",
        "        else:\n",
        "            print(\"  SeNorge: Not available\")\n",
        "\n",
        "        # NVE (specific to glaciers)\n",
        "        if sources['nve']['available']:\n",
        "            print(\"  NVE: Available\")\n",
        "            print(\"    Variables:\")\n",
        "            for var, avail in sources['nve']['variables'].items():\n",
        "                print(f\"      {var}: {'✓' if avail else '✗'}\")\n",
        "        else:\n",
        "            print(\"  NVE: Not available\")\n",
        "\n",
        "        # NOAA\n",
        "        if sources['noaa']['available']:\n",
        "            print(\"  NOAA: Available\")\n",
        "            print(\"    Variables:\")\n",
        "            for var, avail in sources['noaa']['variables'].items():\n",
        "                print(f\"      {var}: {'✓' if avail else '✗'}\")\n",
        "        else:\n",
        "            print(\"  NOAA: Not available\")\n",
        "\n",
        "        # ERA5\n",
        "        if sources['era5']['available']:\n",
        "            print(\"  ERA5: Available\")\n",
        "            print(\"    Variables:\")\n",
        "            for var, avail in sources['era5']['variables'].items():\n",
        "                print(f\"      {var}: {'✓' if avail else '✗'}\")\n",
        "        else:\n",
        "            print(\"  ERA5: Not available\")\n",
        "\n",
        "        # CHELSA\n",
        "        if sources['chelsa']['available']:\n",
        "            print(\"  CHELSA: Available\")\n",
        "            print(\"    Variables:\")\n",
        "            for var, avail in sources['chelsa']['variables'].items():\n",
        "                print(f\"      {var}: {'✓' if avail else '✗'}\")\n",
        "        else:\n",
        "            print(\"  CHELSA: Not available\")\n",
        "\n",
        "        # E-OBS\n",
        "        if sources['eobs']['available']:\n",
        "            print(\"  E-OBS: Available\")\n",
        "            print(\"    Variables:\")\n",
        "            for var, avail in sources['eobs']['variables'].items():\n",
        "                print(f\"      {var}: {'✓' if avail else '✗'}\")\n",
        "        else:\n",
        "            print(\"  E-OBS: Not available\")\n",
        "\n",
        "    # 3. Fetch data from multiple sources\n",
        "    print(\"\\nStep 3: Fetching data from all available sources\")\n",
        "    integrated_results = get_integrated_climate_data(sites_df, availability,\n",
        "                                                  start_year, end_year,\n",
        "                                                  noaa_token, frost_client_id,\n",
        "                                                  cds_setup, output_dir)\n",
        "\n",
        "    # 4. Integrate data from different sources\n",
        "    print(\"\\nStep 4: Integrating data from different sources\")\n",
        "    integrated_results = integrate_climate_data(integrated_results)\n",
        "\n",
        "    # 5. Export and visualize the integrated data\n",
        "    print(\"\\nStep 5: Exporting and visualizing the integrated data\")\n",
        "    export_integrated_data(integrated_results, output_dir)\n",
        "\n",
        "    print(\"\\n===== ANALYSIS COMPLETE =====\")\n",
        "    print(f\"All results saved to: {output_dir}\")\n",
        "\n",
        "    # Create a zip file with all outputs\n",
        "    print(\"\\nCreating zip file for download...\")\n",
        "    zip_file = create_zip_download(output_dir)\n",
        "\n",
        "    return integrated_results"
      ],
      "metadata": {
        "id": "IzRF-wHowyQF"
      },
      "id": "IzRF-wHowyQF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main function to execute the script.\"\"\"\n",
        "    print(\"==== INTEGRATED CLIMATE DATA FOR NORWEGIAN GLACIER SITES ====\\n\")\n",
        "\n",
        "    # Define local output directory\n",
        "    output_dir = \"/content/climate_outputs\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Try to load glacier sites\n",
        "    print(\"Step 1: Load glacier study sites\")\n",
        "\n",
        "    # Option: Set default paths for common Norwegian glacier datasets\n",
        "    default_paths = {\n",
        "        'jostedal': \"/content/drive/MyDrive/Glaciers/jostedal_glaciers.csv\",\n",
        "        'jotunheimen': \"/content/drive/MyDrive/Glaciers/jotunheimen_glaciers.csv\",\n",
        "        'folgefonna': \"/content/drive/MyDrive/Glaciers/folgefonna_glaciers.csv\",\n",
        "        'svartisen': \"/content/drive/MyDrive/Glaciers/svartisen_glaciers.csv\",\n",
        "        'okstindan': \"/content/drive/MyDrive/Glaciers/okstindan_glaciers.csv\",\n",
        "        'custom': \"/content/drive/MyDrive/Diss/Climate_data_v6/glacier_locations.csv\"\n",
        "    }\n",
        "\n",
        "    print(\"Choose a glacier region or load your own dataset:\")\n",
        "    print(\"1. Jostedalsbreen\")\n",
        "    print(\"2. Jotunheimen\")\n",
        "    print(\"3. Folgefonna\")\n",
        "    print(\"4. Svartisen\")\n",
        "    print(\"5. Okstindan\")\n",
        "    print(\"6. Custom (your own dataset)\")\n",
        "\n",
        "    choice = input(\"Enter your choice (1-6): \")\n",
        "\n",
        "    if choice == '1':\n",
        "        default_path = default_paths['jostedal']\n",
        "        region_name = \"Jostedalsbreen\"\n",
        "    elif choice == '2':\n",
        "        default_path = default_paths['jotunheimen']\n",
        "        region_name = \"Jotunheimen\"\n",
        "    elif choice == '3':\n",
        "        default_path = default_paths['folgefonna']\n",
        "        region_name = \"Folgefonna\"\n",
        "    elif choice == '4':\n",
        "        default_path = default_paths['svartisen']\n",
        "        region_name = \"Svartisen\"\n",
        "    elif choice == '5':\n",
        "        default_path = default_paths['okstindan']\n",
        "        region_name = \"Okstindan\"\n",
        "    else:\n",
        "        default_path = default_paths['custom']\n",
        "        region_name = \"Custom\"\n",
        "\n",
        "    # Try to load from the selected path\n",
        "    try:\n",
        "        sites_df = upload_glacier_sites(default_path)\n",
        "        print(f\"Successfully loaded {region_name} glacier sites from:\", default_path)\n",
        "    except:\n",
        "        print(f\"File not found at {region_name} location. You can either:\")\n",
        "        print(\"1. Upload a file manually\")\n",
        "        print(\"2. Enter a file path\")\n",
        "\n",
        "        choice = input(\"Choose option (1 or 2): \")\n",
        "\n",
        "        if choice == '1':\n",
        "            print(\"Please upload your CSV file with glacier locations:\")\n",
        "            try:\n",
        "                from google.colab import files\n",
        "                uploaded = files.upload()\n",
        "                file_path = list(uploaded.keys())[0]\n",
        "                sites_df = upload_glacier_sites(file_path)\n",
        "            except:\n",
        "                print(\"Could not upload file. Please try again or use option 2.\")\n",
        "                sys.exit(1)\n",
        "        else:\n",
        "            file_path = input(\"Enter the full path to your CSV file: \")\n",
        "            try:\n",
        "                sites_df = upload_glacier_sites(file_path)\n",
        "            except:\n",
        "                print(\"Could not load file. Please check the path and try again.\")\n",
        "                sys.exit(1)\n",
        "\n",
        "    if sites_df is None:\n",
        "        print(\"Failed to load glacier sites. Exiting.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    print(\"\\nYour glacier sites:\")\n",
        "    print(sites_df)\n",
        "\n",
        "    # Get start and end years\n",
        "    while True:\n",
        "        try:\n",
        "            start_year = input(\"\\nEnter start year (default is 1970): \")\n",
        "            start_year = int(start_year) if start_year else 1970\n",
        "\n",
        "            end_year = input(\"Enter end year (default is current year): \")\n",
        "            end_year = int(end_year) if end_year else datetime.now().year\n",
        "\n",
        "            if start_year > end_year:\n",
        "                print(\"Error: Start year must be before end year.\")\n",
        "                continue\n",
        "\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"Error: Please enter valid years (integers).\")\n",
        "\n",
        "    # Run the integrated analysis\n",
        "    integrated_results = run_integrated_climate_analysis(sites_df, start_year, end_year, output_dir)\n",
        "\n",
        "    print(\"\\nAnalysis complete!\")\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\"\\nTo download all results as a zip file, run:\")\n",
        "        print(\"from google.colab import files\")\n",
        "        print(\"files.download('climate_data_outputs.zip')\")\n",
        "    except:\n",
        "        print(f\"\\nAll results are saved in the directory: {output_dir}\")\n",
        "        print(f\"A zip file with all results is available at: climate_data_outputs.zip\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "VylyNR-CtSLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33622a10-1999-45c5-c92e-3860566ee34d"
      },
      "id": "VylyNR-CtSLm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== INTEGRATED CLIMATE DATA FOR NORWEGIAN GLACIER SITES ====\n",
            "\n",
            "Step 1: Load glacier study sites\n",
            "Choose a glacier region or load your own dataset:\n",
            "1. Jostedalsbreen\n",
            "2. Jotunheimen\n",
            "3. Folgefonna\n",
            "4. Svartisen\n",
            "5. Okstindan\n",
            "6. Custom (your own dataset)\n",
            "Enter your choice (1-6): 6\n",
            "Successfully loaded Custom glacier sites from: /content/drive/MyDrive/Diss/Climate_data_v6/glacier_locations.csv\n",
            "\n",
            "Your glacier sites:\n",
            "   site_name   latitude  longitude  Unnamed: 3  Unnamed: 4  Unnamed: 5\n",
            "0        g01  68.579515  18.107387         NaN         NaN         NaN\n",
            "1        g11  66.501116  14.655010         NaN         NaN         NaN\n",
            "2        g12  65.445231  13.139741         NaN         NaN         NaN\n",
            "3        g13  65.382565  13.125551         NaN         NaN         NaN\n",
            "4        g19  61.874247   7.230627         NaN         NaN         NaN\n",
            "5        g20  67.416720  16.026525         NaN         NaN         NaN\n",
            "6        g23  69.275026  19.765340         NaN         NaN         NaN\n",
            "7        g25  69.148559  20.148201         NaN         NaN         NaN\n",
            "8        g26  62.186858   7.742994         NaN         NaN         NaN\n",
            "9        g30  60.679787   7.453941         NaN         NaN         NaN\n",
            "10       g35  61.572909   8.469540         NaN         NaN         NaN\n",
            "11       g36  61.650676   6.313672         NaN         NaN         NaN\n",
            "12       g37  61.484647   6.902983         NaN         NaN         NaN\n",
            "13       g39  61.930845   7.595518         NaN         NaN         NaN\n",
            "14       g40  70.410803  23.249913         NaN         NaN         NaN\n",
            "15       g42  62.071645   8.153037         NaN         NaN         NaN\n",
            "16       g44  68.336643  17.379869         NaN         NaN         NaN\n",
            "17       g46  61.535900   7.098983         NaN         NaN         NaN\n",
            "18       g49  61.605697   7.706949         NaN         NaN         NaN\n",
            "19       g50  69.879229  20.277492         NaN         NaN         NaN\n",
            "\n",
            "Enter start year (default is 1970): 1970\n",
            "Enter end year (default is current year): 2024\n",
            "\n",
            "===== INTEGRATED CLIMATE DATA ANALYSIS FOR NORWEGIAN GLACIERS =====\n",
            "Start year: 1970\n",
            "End year: 2024\n",
            "Output directory: /content/climate_outputs\n",
            "\n",
            "Step 1: Setting up API credentials\n",
            "Enter your MET Norway Frost API client ID (leave blank to skip Frost data): 29536dcf-9e8a-4d2d-a26e-a9c546970e56\n",
            "Enter your NOAA API token (leave blank to skip NOAA data): KJiHwizseSbtcqJdyKbxzbeSGeEbcxei\n",
            "Use Climate Data Store (CDS) ERA5 data? (y/n): y\n",
            "\n",
            "CDS API configuration\n",
            "Please register at https://cds.climate.copernicus.eu/user/register\n",
            "Then go to https://cds.climate.copernicus.eu/api-how-to and copy your API key\n",
            "Enter CDS API URL (default: https://cds.climate.copernicus.eu/api/v2): https://cds.climate.copernicus.eu/api\n",
            "Enter your CDS API key: f7676df8-49a8-4453-8621-f9d63e280e13\n",
            "CDS API configuration saved to /root/.cdsapirc\n",
            "\n",
            "==== DEBUGGING: API CREDENTIALS ====\n",
            "Frost client ID provided: Yes\n",
            "NOAA token provided: Yes\n",
            "CDS setup successful: Yes\n",
            "\n",
            "Step 2: Verifying data availability for each site and source\n",
            "Checking data availability for site: g01 (68.5795155, 18.10738723)\n",
            "  Checking NOAA stations near g01...\n",
            "  Found station: RIKSGRANSEN, SW (68.43, 18.13)\n",
            "    Variable PRCP: Not available\n",
            "    Variable TMAX: Not available\n",
            "    Variable TMIN: Not available\n",
            "    Variable AWND: Not available\n",
            "    Variable SNOW: Not available (API error)\n",
            "    Variable SNWD: Not available (API error)\n",
            "    Variable ACSH: Not available (API error)\n",
            "  Checking ERA5 data availability for g01...\n",
            "  Error checking ERA5 data: No module named 'cdsapi'\n",
            "  Checking MET Norway Frost data availability for g01...\n",
            "  Frost API error: 400 - {\n",
            "  \"@context\" : \"https://frost.met.no/schema\",\n",
            "  \"@type\" : \"ErrorResponse\",\n",
            "  \"apiVersion\" : \"v0\",\n",
            "  \"license\" : \"https://creativecommons.org/licenses/by/3.0/no/\",\n",
            "  \"createdAt\" : \"2025-05-15T19:11:17Z\",\n",
            "  \"queryTime\" : 0,\n",
            "  \"currentLink\" : \"https://frost.met.no/sources/v0.jsonld?geometry=nearest%28POINT%2818.10738723+68.5795155%29%29&nearestmaxcount=5&types=SN\",\n",
            "  \"error\" : {\n",
            "    \"code\" : 400,\n",
            "    \"message\" : \"Bad Request\",\n",
            "    \"reason\" : \"Unsupported type: sn\",\n",
            "    \"help\" : \"Supported types: SensorSystem, InterpolatedDataset, RegionDataset\"\n",
            "  }\n",
            "}\n",
            "  Checking SeNorge data availability for g01...\n",
            "  SeNorge data available for g01\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "    Variable snow_depth: Available\n",
            "  Checking NVE glacier data availability for g01...\n",
            "  NVE API error: 404\n",
            "  Checking CHELSA data availability for g01...\n",
            "  CHELSA website error: 403\n",
            "  Checking E-OBS data availability for g01...\n",
            "  E-OBS data available for g01\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "Checking data availability for site: g11 (66.501116, 14.65500999)\n",
            "  Checking NOAA stations near g11...\n",
            "  Found station: DUNDERLANDSDALEN, NO (66.5067, 14.9075)\n",
            "    Variable PRCP: Error - HTTPSConnectionPool(host='www.ncdc.noaa.gov', port=443): Read timed out. (read timeout=30)\n",
            "    Variable TMAX: Not available\n",
            "    Variable TMIN: Error - HTTPSConnectionPool(host='www.ncdc.noaa.gov', port=443): Read timed out. (read timeout=30)\n",
            "    Variable AWND: Not available\n",
            "    Variable SNOW: Not available\n",
            "    Variable SNWD: Not available\n",
            "    Variable ACSH: Not available\n",
            "  Checking ERA5 data availability for g11...\n",
            "  Error checking ERA5 data: No module named 'cdsapi'\n",
            "  Checking MET Norway Frost data availability for g11...\n",
            "  Frost API error: 400 - {\n",
            "  \"@context\" : \"https://frost.met.no/schema\",\n",
            "  \"@type\" : \"ErrorResponse\",\n",
            "  \"apiVersion\" : \"v0\",\n",
            "  \"license\" : \"https://creativecommons.org/licenses/by/3.0/no/\",\n",
            "  \"createdAt\" : \"2025-05-15T19:12:20Z\",\n",
            "  \"queryTime\" : 0,\n",
            "  \"currentLink\" : \"https://frost.met.no/sources/v0.jsonld?geometry=nearest%28POINT%2814.65500999+66.501116%29%29&nearestmaxcount=5&types=SN\",\n",
            "  \"error\" : {\n",
            "    \"code\" : 400,\n",
            "    \"message\" : \"Bad Request\",\n",
            "    \"reason\" : \"Unsupported type: sn\",\n",
            "    \"help\" : \"Supported types: SensorSystem, InterpolatedDataset, RegionDataset\"\n",
            "  }\n",
            "}\n",
            "  Checking SeNorge data availability for g11...\n",
            "  SeNorge data available for g11\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "    Variable snow_depth: Available\n",
            "  Checking NVE glacier data availability for g11...\n",
            "  NVE API error: 404\n",
            "  Checking CHELSA data availability for g11...\n",
            "  CHELSA website error: 403\n",
            "  Checking E-OBS data availability for g11...\n",
            "  E-OBS data available for g11\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "Checking data availability for site: g12 (65.445231, 13.13974065)\n",
            "  Checking NOAA stations near g12...\n",
            "  Found station: KAPSKARMO, NO (65.4144, 13.3903)\n",
            "    Variable PRCP: Not available\n",
            "    Variable TMAX: Not available\n",
            "    Variable TMIN: Not available\n",
            "    Variable AWND: Not available\n",
            "    Variable SNOW: Not available (API error)\n",
            "    Variable SNWD: Not available (API error)\n",
            "    Variable ACSH: Not available (API error)\n",
            "  Checking ERA5 data availability for g12...\n",
            "  Error checking ERA5 data: No module named 'cdsapi'\n",
            "  Checking MET Norway Frost data availability for g12...\n",
            "  Frost API error: 400 - {\n",
            "  \"@context\" : \"https://frost.met.no/schema\",\n",
            "  \"@type\" : \"ErrorResponse\",\n",
            "  \"apiVersion\" : \"v0\",\n",
            "  \"license\" : \"https://creativecommons.org/licenses/by/3.0/no/\",\n",
            "  \"createdAt\" : \"2025-05-15T19:12:22Z\",\n",
            "  \"queryTime\" : 0.001,\n",
            "  \"currentLink\" : \"https://frost.met.no/sources/v0.jsonld?geometry=nearest%28POINT%2813.13974065+65.445231%29%29&nearestmaxcount=5&types=SN\",\n",
            "  \"error\" : {\n",
            "    \"code\" : 400,\n",
            "    \"message\" : \"Bad Request\",\n",
            "    \"reason\" : \"Unsupported type: sn\",\n",
            "    \"help\" : \"Supported types: SensorSystem, InterpolatedDataset, RegionDataset\"\n",
            "  }\n",
            "}\n",
            "  Checking SeNorge data availability for g12...\n",
            "  SeNorge data available for g12\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "    Variable snow_depth: Available\n",
            "  Checking NVE glacier data availability for g12...\n",
            "  NVE API error: 404\n",
            "  Checking CHELSA data availability for g12...\n",
            "  CHELSA website error: 403\n",
            "  Checking E-OBS data availability for g12...\n",
            "  E-OBS data available for g12\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "Checking data availability for site: g13 (65.3825655, 13.1255512)\n",
            "  Checking NOAA stations near g13...\n",
            "  Found station: KAPSKARMO, NO (65.4144, 13.3903)\n",
            "    Variable PRCP: Not available\n",
            "    Variable TMAX: Not available\n",
            "    Variable TMIN: Not available\n",
            "    Variable AWND: Not available\n",
            "    Variable SNOW: Not available (API error)\n",
            "    Variable SNWD: Not available (API error)\n",
            "    Variable ACSH: Not available (API error)\n",
            "  Checking ERA5 data availability for g13...\n",
            "  Error checking ERA5 data: No module named 'cdsapi'\n",
            "  Checking MET Norway Frost data availability for g13...\n",
            "  Frost API error: 400 - {\n",
            "  \"@context\" : \"https://frost.met.no/schema\",\n",
            "  \"@type\" : \"ErrorResponse\",\n",
            "  \"apiVersion\" : \"v0\",\n",
            "  \"license\" : \"https://creativecommons.org/licenses/by/3.0/no/\",\n",
            "  \"createdAt\" : \"2025-05-15T19:12:24Z\",\n",
            "  \"queryTime\" : 0.001,\n",
            "  \"currentLink\" : \"https://frost.met.no/sources/v0.jsonld?geometry=nearest%28POINT%2813.1255512+65.3825655%29%29&nearestmaxcount=5&types=SN\",\n",
            "  \"error\" : {\n",
            "    \"code\" : 400,\n",
            "    \"message\" : \"Bad Request\",\n",
            "    \"reason\" : \"Unsupported type: sn\",\n",
            "    \"help\" : \"Supported types: SensorSystem, InterpolatedDataset, RegionDataset\"\n",
            "  }\n",
            "}\n",
            "  Checking SeNorge data availability for g13...\n",
            "  SeNorge data available for g13\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "    Variable snow_depth: Available\n",
            "  Checking NVE glacier data availability for g13...\n",
            "  NVE API error: 404\n",
            "  Checking CHELSA data availability for g13...\n",
            "  Cannot access CHELSA website: HTTPSConnectionPool(host='chelsa-climate.org', port=443): Max retries exceeded with url: /downloads/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7cbbcc053690>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "  Checking E-OBS data availability for g13...\n",
            "  E-OBS data available for g13\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "Checking data availability for site: g19 (61.874247, 7.230626799)\n",
            "  Checking NOAA stations near g19...\n",
            "  Found station: NORDDAL, NO (62.2478, 7.2414)\n",
            "    Variable PRCP: Available\n",
            "    Variable TMAX: Not available\n",
            "    Variable TMIN: Not available\n",
            "    Variable AWND: Not available\n",
            "    Variable SNOW: Not available (API error)\n",
            "    Variable SNWD: Not available (API error)\n",
            "    Variable ACSH: Not available (API error)\n",
            "  Checking ERA5 data availability for g19...\n",
            "  Error checking ERA5 data: No module named 'cdsapi'\n",
            "  Checking MET Norway Frost data availability for g19...\n",
            "  Frost API error: 400 - {\n",
            "  \"@context\" : \"https://frost.met.no/schema\",\n",
            "  \"@type\" : \"ErrorResponse\",\n",
            "  \"apiVersion\" : \"v0\",\n",
            "  \"license\" : \"https://creativecommons.org/licenses/by/3.0/no/\",\n",
            "  \"createdAt\" : \"2025-05-15T19:12:25Z\",\n",
            "  \"queryTime\" : 0,\n",
            "  \"currentLink\" : \"https://frost.met.no/sources/v0.jsonld?geometry=nearest%28POINT%287.230626799+61.874247%29%29&nearestmaxcount=5&types=SN\",\n",
            "  \"error\" : {\n",
            "    \"code\" : 400,\n",
            "    \"message\" : \"Bad Request\",\n",
            "    \"reason\" : \"Unsupported type: sn\",\n",
            "    \"help\" : \"Supported types: SensorSystem, InterpolatedDataset, RegionDataset\"\n",
            "  }\n",
            "}\n",
            "  Checking SeNorge data availability for g19...\n",
            "  SeNorge data available for g19\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "    Variable snow_depth: Available\n",
            "  Checking NVE glacier data availability for g19...\n",
            "  NVE API error: 404\n",
            "  Checking CHELSA data availability for g19...\n",
            "  Cannot access CHELSA website: HTTPSConnectionPool(host='chelsa-climate.org', port=443): Max retries exceeded with url: /downloads/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7cbbcc04c0d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "  Checking E-OBS data availability for g19...\n",
            "  E-OBS data available for g19\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "Checking data availability for site: g20 (67.4167205, 16.026525)\n",
            "  Checking NOAA stations near g20...\n",
            "  Found station: SULITJELMA, NO (67.1344, 16.0708)\n",
            "    Variable PRCP: Not available\n",
            "    Variable TMAX: Not available\n",
            "    Variable TMIN: Not available\n",
            "    Variable AWND: Not available\n",
            "    Variable SNOW: Not available (API error)\n",
            "    Variable SNWD: Not available (API error)\n",
            "    Variable ACSH: Not available (API error)\n",
            "  Checking ERA5 data availability for g20...\n",
            "  Error checking ERA5 data: No module named 'cdsapi'\n",
            "  Checking MET Norway Frost data availability for g20...\n",
            "  Frost API error: 400 - {\n",
            "  \"@context\" : \"https://frost.met.no/schema\",\n",
            "  \"@type\" : \"ErrorResponse\",\n",
            "  \"apiVersion\" : \"v0\",\n",
            "  \"license\" : \"https://creativecommons.org/licenses/by/3.0/no/\",\n",
            "  \"createdAt\" : \"2025-05-15T19:12:27Z\",\n",
            "  \"queryTime\" : 0,\n",
            "  \"currentLink\" : \"https://frost.met.no/sources/v0.jsonld?geometry=nearest%28POINT%2816.026525+67.4167205%29%29&nearestmaxcount=5&types=SN\",\n",
            "  \"error\" : {\n",
            "    \"code\" : 400,\n",
            "    \"message\" : \"Bad Request\",\n",
            "    \"reason\" : \"Unsupported type: sn\",\n",
            "    \"help\" : \"Supported types: SensorSystem, InterpolatedDataset, RegionDataset\"\n",
            "  }\n",
            "}\n",
            "  Checking SeNorge data availability for g20...\n",
            "  SeNorge data available for g20\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "    Variable snow_depth: Available\n",
            "  Checking NVE glacier data availability for g20...\n",
            "  NVE API error: 404\n",
            "  Checking CHELSA data availability for g20...\n",
            "  Cannot access CHELSA website: HTTPSConnectionPool(host='chelsa-climate.org', port=443): Max retries exceeded with url: /downloads/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7cbbcd952590>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "  Checking E-OBS data availability for g20...\n",
            "  E-OBS data available for g20\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "Checking data availability for site: g23 (69.275026, 19.76533957)\n",
            "  Checking NOAA stations near g23...\n",
            "  Found station: DIVIDALEN, NO (68.7781, 19.71)\n",
            "    Variable PRCP: Not available\n",
            "    Variable TMAX: Not available\n",
            "    Variable TMIN: Not available\n",
            "    Variable AWND: Not available\n",
            "    Variable SNOW: Not available (API error)\n",
            "    Variable SNWD: Not available (API error)\n",
            "    Variable ACSH: Not available (API error)\n",
            "  Checking ERA5 data availability for g23...\n",
            "  Error checking ERA5 data: No module named 'cdsapi'\n",
            "  Checking MET Norway Frost data availability for g23...\n",
            "  Frost API error: 400 - {\n",
            "  \"@context\" : \"https://frost.met.no/schema\",\n",
            "  \"@type\" : \"ErrorResponse\",\n",
            "  \"apiVersion\" : \"v0\",\n",
            "  \"license\" : \"https://creativecommons.org/licenses/by/3.0/no/\",\n",
            "  \"createdAt\" : \"2025-05-15T19:12:29Z\",\n",
            "  \"queryTime\" : 0,\n",
            "  \"currentLink\" : \"https://frost.met.no/sources/v0.jsonld?geometry=nearest%28POINT%2819.76533957+69.275026%29%29&nearestmaxcount=5&types=SN\",\n",
            "  \"error\" : {\n",
            "    \"code\" : 400,\n",
            "    \"message\" : \"Bad Request\",\n",
            "    \"reason\" : \"Unsupported type: sn\",\n",
            "    \"help\" : \"Supported types: SensorSystem, InterpolatedDataset, RegionDataset\"\n",
            "  }\n",
            "}\n",
            "  Checking SeNorge data availability for g23...\n",
            "  SeNorge data available for g23\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "    Variable snow_depth: Available\n",
            "  Checking NVE glacier data availability for g23...\n",
            "  NVE API error: 404\n",
            "  Checking CHELSA data availability for g23...\n",
            "  Cannot access CHELSA website: HTTPSConnectionPool(host='chelsa-climate.org', port=443): Max retries exceeded with url: /downloads/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7cbbcc07c850>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "  Checking E-OBS data availability for g23...\n",
            "  E-OBS data available for g23\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "Checking data availability for site: g25 (69.148559, 20.14820114)\n",
            "  Checking NOAA stations near g25...\n",
            "  Found station: DIVIDALEN, NO (68.7781, 19.71)\n",
            "    Variable PRCP: Not available\n",
            "    Variable TMAX: Not available\n",
            "    Variable TMIN: Not available\n",
            "    Variable AWND: Not available\n",
            "    Variable SNOW: Not available (API error)\n",
            "    Variable SNWD: Not available (API error)\n",
            "    Variable ACSH: Not available (API error)\n",
            "  Checking ERA5 data availability for g25...\n",
            "  Error checking ERA5 data: No module named 'cdsapi'\n",
            "  Checking MET Norway Frost data availability for g25...\n",
            "  Frost API error: 400 - {\n",
            "  \"@context\" : \"https://frost.met.no/schema\",\n",
            "  \"@type\" : \"ErrorResponse\",\n",
            "  \"apiVersion\" : \"v0\",\n",
            "  \"license\" : \"https://creativecommons.org/licenses/by/3.0/no/\",\n",
            "  \"createdAt\" : \"2025-05-15T19:12:31Z\",\n",
            "  \"queryTime\" : 0,\n",
            "  \"currentLink\" : \"https://frost.met.no/sources/v0.jsonld?geometry=nearest%28POINT%2820.14820114+69.148559%29%29&nearestmaxcount=5&types=SN\",\n",
            "  \"error\" : {\n",
            "    \"code\" : 400,\n",
            "    \"message\" : \"Bad Request\",\n",
            "    \"reason\" : \"Unsupported type: sn\",\n",
            "    \"help\" : \"Supported types: SensorSystem, InterpolatedDataset, RegionDataset\"\n",
            "  }\n",
            "}\n",
            "  Checking SeNorge data availability for g25...\n",
            "  SeNorge data available for g25\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "    Variable snow_depth: Available\n",
            "  Checking NVE glacier data availability for g25...\n",
            "  NVE API error: 404\n",
            "  Checking CHELSA data availability for g25...\n",
            "  Cannot access CHELSA website: HTTPSConnectionPool(host='chelsa-climate.org', port=443): Max retries exceeded with url: /downloads/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7cbbcc040310>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "  Checking E-OBS data availability for g25...\n",
            "  E-OBS data available for g25\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "Checking data availability for site: g26 (62.186858, 7.742994409)\n",
            "  Checking NOAA stations near g26...\n",
            "  Found station: GRONNING, NO (62.3289, 7.5128)\n",
            "    Variable PRCP: Available\n",
            "    Variable TMAX: Not available\n",
            "    Variable TMIN: Not available\n",
            "    Variable AWND: Not available\n",
            "    Variable SNOW: Not available (API error)\n",
            "    Variable SNWD: Not available (API error)\n",
            "    Variable ACSH: Not available (API error)\n",
            "  Checking ERA5 data availability for g26...\n",
            "  Error checking ERA5 data: No module named 'cdsapi'\n",
            "  Checking MET Norway Frost data availability for g26...\n",
            "  Frost API error: 400 - {\n",
            "  \"@context\" : \"https://frost.met.no/schema\",\n",
            "  \"@type\" : \"ErrorResponse\",\n",
            "  \"apiVersion\" : \"v0\",\n",
            "  \"license\" : \"https://creativecommons.org/licenses/by/3.0/no/\",\n",
            "  \"createdAt\" : \"2025-05-15T19:12:32Z\",\n",
            "  \"queryTime\" : 0.001,\n",
            "  \"currentLink\" : \"https://frost.met.no/sources/v0.jsonld?geometry=nearest%28POINT%287.742994409+62.186858%29%29&nearestmaxcount=5&types=SN\",\n",
            "  \"error\" : {\n",
            "    \"code\" : 400,\n",
            "    \"message\" : \"Bad Request\",\n",
            "    \"reason\" : \"Unsupported type: sn\",\n",
            "    \"help\" : \"Supported types: SensorSystem, InterpolatedDataset, RegionDataset\"\n",
            "  }\n",
            "}\n",
            "  Checking SeNorge data availability for g26...\n",
            "  SeNorge data available for g26\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "    Variable snow_depth: Available\n",
            "  Checking NVE glacier data availability for g26...\n",
            "  NVE API error: 404\n",
            "  Checking CHELSA data availability for g26...\n",
            "  Cannot access CHELSA website: HTTPSConnectionPool(host='chelsa-climate.org', port=443): Max retries exceeded with url: /downloads/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7cbbcc0877d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "  Checking E-OBS data availability for g26...\n",
            "  E-OBS data available for g26\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "Checking data availability for site: g30 (60.679787, 7.453940643)\n",
            "  Checking NOAA stations near g30...\n",
            "  Found station: FET I EIDFJORD, NO (60.4083, 7.2794)\n",
            "    Variable PRCP: Available\n",
            "    Variable TMAX: Available\n",
            "    Variable TMIN: Available\n",
            "    Variable AWND: Not available\n",
            "    Variable SNOW: Not available (API error)\n",
            "    Variable SNWD: Not available (API error)\n",
            "    Variable ACSH: Not available (API error)\n",
            "  Checking ERA5 data availability for g30...\n",
            "  Error checking ERA5 data: No module named 'cdsapi'\n",
            "  Checking MET Norway Frost data availability for g30...\n",
            "  Frost API error: 400 - {\n",
            "  \"@context\" : \"https://frost.met.no/schema\",\n",
            "  \"@type\" : \"ErrorResponse\",\n",
            "  \"apiVersion\" : \"v0\",\n",
            "  \"license\" : \"https://creativecommons.org/licenses/by/3.0/no/\",\n",
            "  \"createdAt\" : \"2025-05-15T19:12:34Z\",\n",
            "  \"queryTime\" : 0.001,\n",
            "  \"currentLink\" : \"https://frost.met.no/sources/v0.jsonld?geometry=nearest%28POINT%287.453940643+60.679787%29%29&nearestmaxcount=5&types=SN\",\n",
            "  \"error\" : {\n",
            "    \"code\" : 400,\n",
            "    \"message\" : \"Bad Request\",\n",
            "    \"reason\" : \"Unsupported type: sn\",\n",
            "    \"help\" : \"Supported types: SensorSystem, InterpolatedDataset, RegionDataset\"\n",
            "  }\n",
            "}\n",
            "  Checking SeNorge data availability for g30...\n",
            "  SeNorge data available for g30\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "    Variable snow_depth: Available\n",
            "  Checking NVE glacier data availability for g30...\n",
            "  NVE API error: 404\n",
            "  Checking CHELSA data availability for g30...\n",
            "  Cannot access CHELSA website: HTTPSConnectionPool(host='chelsa-climate.org', port=443): Max retries exceeded with url: /downloads/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7cbbcc053950>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "  Checking E-OBS data availability for g30...\n",
            "  E-OBS data available for g30\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "Checking data availability for site: g35 (61.572909, 8.469539738)\n",
            "  Checking NOAA stations near g35...\n",
            "  Found station: BOVERDAL, NO (61.7206, 8.2442)\n",
            "    Variable PRCP: Available\n",
            "    Variable TMAX: Not available\n",
            "    Variable TMIN: Not available\n",
            "    Variable AWND: Not available\n",
            "    Variable SNOW: Not available (API error)\n",
            "    Variable SNWD: Not available (API error)\n",
            "    Variable ACSH: Not available\n",
            "  Checking ERA5 data availability for g35...\n",
            "  Error checking ERA5 data: No module named 'cdsapi'\n",
            "  Checking MET Norway Frost data availability for g35...\n",
            "  Frost API error: 400 - {\n",
            "  \"@context\" : \"https://frost.met.no/schema\",\n",
            "  \"@type\" : \"ErrorResponse\",\n",
            "  \"apiVersion\" : \"v0\",\n",
            "  \"license\" : \"https://creativecommons.org/licenses/by/3.0/no/\",\n",
            "  \"createdAt\" : \"2025-05-15T19:12:36Z\",\n",
            "  \"queryTime\" : 0,\n",
            "  \"currentLink\" : \"https://frost.met.no/sources/v0.jsonld?geometry=nearest%28POINT%288.469539738+61.572909%29%29&nearestmaxcount=5&types=SN\",\n",
            "  \"error\" : {\n",
            "    \"code\" : 400,\n",
            "    \"message\" : \"Bad Request\",\n",
            "    \"reason\" : \"Unsupported type: sn\",\n",
            "    \"help\" : \"Supported types: SensorSystem, InterpolatedDataset, RegionDataset\"\n",
            "  }\n",
            "}\n",
            "  Checking SeNorge data availability for g35...\n",
            "  SeNorge data available for g35\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "    Variable snow_depth: Available\n",
            "  Checking NVE glacier data availability for g35...\n",
            "  NVE API error: 404\n",
            "  Checking CHELSA data availability for g35...\n",
            "  Cannot access CHELSA website: HTTPSConnectionPool(host='chelsa-climate.org', port=443): Max retries exceeded with url: /downloads/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7cbbcc070f10>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "  Checking E-OBS data availability for g35...\n",
            "  E-OBS data available for g35\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "Checking data availability for site: g36 (61.650676, 6.313671936)\n",
            "  Checking NOAA stations near g36...\n",
            "  Found station: SANDANE, NO (61.7881, 6.1833)\n",
            "    Variable PRCP: Available\n",
            "    Variable TMAX: Available\n",
            "    Variable TMIN: Available\n",
            "    Variable AWND: Not available\n",
            "    Variable SNOW: Not available (API error)\n",
            "    Variable SNWD: Not available (API error)\n",
            "    Variable ACSH: Not available (API error)\n",
            "  Checking ERA5 data availability for g36...\n",
            "  Error checking ERA5 data: No module named 'cdsapi'\n",
            "  Checking MET Norway Frost data availability for g36...\n",
            "  Frost API error: 400 - {\n",
            "  \"@context\" : \"https://frost.met.no/schema\",\n",
            "  \"@type\" : \"ErrorResponse\",\n",
            "  \"apiVersion\" : \"v0\",\n",
            "  \"license\" : \"https://creativecommons.org/licenses/by/3.0/no/\",\n",
            "  \"createdAt\" : \"2025-05-15T19:12:38Z\",\n",
            "  \"queryTime\" : 0.001,\n",
            "  \"currentLink\" : \"https://frost.met.no/sources/v0.jsonld?geometry=nearest%28POINT%286.313671936+61.650676%29%29&nearestmaxcount=5&types=SN\",\n",
            "  \"error\" : {\n",
            "    \"code\" : 400,\n",
            "    \"message\" : \"Bad Request\",\n",
            "    \"reason\" : \"Unsupported type: sn\",\n",
            "    \"help\" : \"Supported types: SensorSystem, InterpolatedDataset, RegionDataset\"\n",
            "  }\n",
            "}\n",
            "  Checking SeNorge data availability for g36...\n",
            "  SeNorge data available for g36\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "    Variable snow_depth: Available\n",
            "  Checking NVE glacier data availability for g36...\n",
            "  NVE API error: 404\n",
            "  Checking CHELSA data availability for g36...\n",
            "  Cannot access CHELSA website: HTTPSConnectionPool(host='chelsa-climate.org', port=443): Max retries exceeded with url: /downloads/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7cbbcd6f9dd0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "  Checking E-OBS data availability for g36...\n",
            "  E-OBS data available for g36\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "Checking data availability for site: g37 (61.484647, 6.902982941)\n",
            "  Checking NOAA stations near g37...\n",
            "  Found station: VEITASTROND, NO (61.4781, 7.0339)\n",
            "    Variable PRCP: Available\n",
            "    Variable TMAX: Not available\n",
            "    Variable TMIN: Not available\n",
            "    Variable AWND: Not available\n",
            "    Variable SNOW: Not available (API error)\n",
            "    Variable SNWD: Not available (API error)\n",
            "    Variable ACSH: Not available (API error)\n",
            "  Checking ERA5 data availability for g37...\n",
            "  Error checking ERA5 data: No module named 'cdsapi'\n",
            "  Checking MET Norway Frost data availability for g37...\n",
            "  Frost API error: 400 - {\n",
            "  \"@context\" : \"https://frost.met.no/schema\",\n",
            "  \"@type\" : \"ErrorResponse\",\n",
            "  \"apiVersion\" : \"v0\",\n",
            "  \"license\" : \"https://creativecommons.org/licenses/by/3.0/no/\",\n",
            "  \"createdAt\" : \"2025-05-15T19:12:40Z\",\n",
            "  \"queryTime\" : 0,\n",
            "  \"currentLink\" : \"https://frost.met.no/sources/v0.jsonld?geometry=nearest%28POINT%286.902982941+61.484647%29%29&nearestmaxcount=5&types=SN\",\n",
            "  \"error\" : {\n",
            "    \"code\" : 400,\n",
            "    \"message\" : \"Bad Request\",\n",
            "    \"reason\" : \"Unsupported type: sn\",\n",
            "    \"help\" : \"Supported types: SensorSystem, InterpolatedDataset, RegionDataset\"\n",
            "  }\n",
            "}\n",
            "  Checking SeNorge data availability for g37...\n",
            "  SeNorge data available for g37\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "    Variable snow_depth: Available\n",
            "  Checking NVE glacier data availability for g37...\n",
            "  NVE API error: 404\n",
            "  Checking CHELSA data availability for g37...\n",
            "  Cannot access CHELSA website: HTTPSConnectionPool(host='chelsa-climate.org', port=443): Max retries exceeded with url: /downloads/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7cbbcc0a0150>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "  Checking E-OBS data availability for g37...\n",
            "  E-OBS data available for g37\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "Checking data availability for site: g39 (61.930845, 7.595518424)\n",
            "  Checking NOAA stations near g39...\n",
            "  Found station: TAFJORD, NO (62.2333, 7.4167)\n",
            "    Variable PRCP: Available\n",
            "    Variable TMAX: Available\n",
            "    Variable TMIN: Available\n",
            "    Variable AWND: Not available\n",
            "    Variable SNOW: Not available (API error)\n",
            "    Variable SNWD: Not available (API error)\n",
            "    Variable ACSH: Not available (API error)\n",
            "  Checking ERA5 data availability for g39...\n",
            "  Error checking ERA5 data: No module named 'cdsapi'\n",
            "  Checking MET Norway Frost data availability for g39...\n",
            "  Frost API error: 400 - {\n",
            "  \"@context\" : \"https://frost.met.no/schema\",\n",
            "  \"@type\" : \"ErrorResponse\",\n",
            "  \"apiVersion\" : \"v0\",\n",
            "  \"license\" : \"https://creativecommons.org/licenses/by/3.0/no/\",\n",
            "  \"createdAt\" : \"2025-05-15T19:12:41Z\",\n",
            "  \"queryTime\" : 0,\n",
            "  \"currentLink\" : \"https://frost.met.no/sources/v0.jsonld?geometry=nearest%28POINT%287.595518424+61.930845%29%29&nearestmaxcount=5&types=SN\",\n",
            "  \"error\" : {\n",
            "    \"code\" : 400,\n",
            "    \"message\" : \"Bad Request\",\n",
            "    \"reason\" : \"Unsupported type: sn\",\n",
            "    \"help\" : \"Supported types: SensorSystem, InterpolatedDataset, RegionDataset\"\n",
            "  }\n",
            "}\n",
            "  Checking SeNorge data availability for g39...\n",
            "  SeNorge data available for g39\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "    Variable snow_depth: Available\n",
            "  Checking NVE glacier data availability for g39...\n",
            "  NVE API error: 404\n",
            "  Checking CHELSA data availability for g39...\n",
            "  Cannot access CHELSA website: HTTPSConnectionPool(host='chelsa-climate.org', port=443): Max retries exceeded with url: /downloads/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7cbbcd9523d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "  Checking E-OBS data availability for g39...\n",
            "  E-OBS data available for g39\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "Checking data availability for site: g40 (70.410803, 23.24991325)\n",
            "  Checking NOAA stations near g40...\n",
            "  Found station: PORSA II, NO (70.3992, 23.6256)\n",
            "    Variable PRCP: Not available\n",
            "    Variable TMAX: Not available\n",
            "    Variable TMIN: Not available\n",
            "    Variable AWND: Not available\n",
            "    Variable SNOW: Not available (API error)\n",
            "    Variable SNWD: Not available (API error)\n",
            "    Variable ACSH: Not available (API error)\n",
            "  Checking ERA5 data availability for g40...\n",
            "  Error checking ERA5 data: No module named 'cdsapi'\n",
            "  Checking MET Norway Frost data availability for g40...\n",
            "  Frost API error: 400 - {\n",
            "  \"@context\" : \"https://frost.met.no/schema\",\n",
            "  \"@type\" : \"ErrorResponse\",\n",
            "  \"apiVersion\" : \"v0\",\n",
            "  \"license\" : \"https://creativecommons.org/licenses/by/3.0/no/\",\n",
            "  \"createdAt\" : \"2025-05-15T19:12:43Z\",\n",
            "  \"queryTime\" : 0,\n",
            "  \"currentLink\" : \"https://frost.met.no/sources/v0.jsonld?geometry=nearest%28POINT%2823.24991325+70.410803%29%29&nearestmaxcount=5&types=SN\",\n",
            "  \"error\" : {\n",
            "    \"code\" : 400,\n",
            "    \"message\" : \"Bad Request\",\n",
            "    \"reason\" : \"Unsupported type: sn\",\n",
            "    \"help\" : \"Supported types: SensorSystem, InterpolatedDataset, RegionDataset\"\n",
            "  }\n",
            "}\n",
            "  Checking SeNorge data availability for g40...\n",
            "  SeNorge data available for g40\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "    Variable snow_depth: Available\n",
            "  Checking NVE glacier data availability for g40...\n",
            "  NVE API error: 404\n",
            "  Checking CHELSA data availability for g40...\n",
            "  Cannot access CHELSA website: HTTPSConnectionPool(host='chelsa-climate.org', port=443): Max retries exceeded with url: /downloads/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7cbbcd6a2710>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "  Checking E-OBS data availability for g40...\n",
            "  E-OBS data available for g40\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "Checking data availability for site: g42 (62.071645, 8.153036994)\n",
            "  Checking NOAA stations near g42...\n",
            "  Found station: SKJAK, NO (61.9017, 8.1719)\n",
            "    Variable PRCP: Available\n",
            "    Variable TMAX: Not available\n",
            "    Variable TMIN: Not available\n",
            "    Variable AWND: Not available\n",
            "    Variable SNOW: Not available (API error)\n",
            "    Variable SNWD: Not available (API error)\n",
            "    Variable ACSH: Not available (API error)\n",
            "  Checking ERA5 data availability for g42...\n",
            "  Error checking ERA5 data: No module named 'cdsapi'\n",
            "  Checking MET Norway Frost data availability for g42...\n",
            "  Frost API error: 400 - {\n",
            "  \"@context\" : \"https://frost.met.no/schema\",\n",
            "  \"@type\" : \"ErrorResponse\",\n",
            "  \"apiVersion\" : \"v0\",\n",
            "  \"license\" : \"https://creativecommons.org/licenses/by/3.0/no/\",\n",
            "  \"createdAt\" : \"2025-05-15T19:12:45Z\",\n",
            "  \"queryTime\" : 0.001,\n",
            "  \"currentLink\" : \"https://frost.met.no/sources/v0.jsonld?geometry=nearest%28POINT%288.153036994+62.071645%29%29&nearestmaxcount=5&types=SN\",\n",
            "  \"error\" : {\n",
            "    \"code\" : 400,\n",
            "    \"message\" : \"Bad Request\",\n",
            "    \"reason\" : \"Unsupported type: sn\",\n",
            "    \"help\" : \"Supported types: SensorSystem, InterpolatedDataset, RegionDataset\"\n",
            "  }\n",
            "}\n",
            "  Checking SeNorge data availability for g42...\n",
            "  SeNorge data available for g42\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "    Variable snow_depth: Available\n",
            "  Checking NVE glacier data availability for g42...\n",
            "  NVE API error: 404\n",
            "  Checking CHELSA data availability for g42...\n",
            "  Cannot access CHELSA website: HTTPSConnectionPool(host='chelsa-climate.org', port=443): Max retries exceeded with url: /downloads/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7cbbcb7280d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "  Checking E-OBS data availability for g42...\n",
            "  E-OBS data available for g42\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "Checking data availability for site: g44 (68.336643, 17.37986938)\n",
            "  Checking NOAA stations near g44...\n",
            "  Found station: ANKENES, NO (68.3753, 17.4133)\n",
            "    Variable PRCP: Not available\n",
            "    Variable TMAX: Not available\n",
            "    Variable TMIN: Not available\n",
            "    Variable AWND: Not available\n",
            "    Variable SNOW: Not available (API error)\n",
            "    Variable SNWD: Not available (API error)\n",
            "    Variable ACSH: Not available (API error)\n",
            "  Checking ERA5 data availability for g44...\n",
            "  Error checking ERA5 data: No module named 'cdsapi'\n",
            "  Checking MET Norway Frost data availability for g44...\n",
            "  Frost API error: 400 - {\n",
            "  \"@context\" : \"https://frost.met.no/schema\",\n",
            "  \"@type\" : \"ErrorResponse\",\n",
            "  \"apiVersion\" : \"v0\",\n",
            "  \"license\" : \"https://creativecommons.org/licenses/by/3.0/no/\",\n",
            "  \"createdAt\" : \"2025-05-15T19:12:46Z\",\n",
            "  \"queryTime\" : 0.001,\n",
            "  \"currentLink\" : \"https://frost.met.no/sources/v0.jsonld?geometry=nearest%28POINT%2817.37986938+68.336643%29%29&nearestmaxcount=5&types=SN\",\n",
            "  \"error\" : {\n",
            "    \"code\" : 400,\n",
            "    \"message\" : \"Bad Request\",\n",
            "    \"reason\" : \"Unsupported type: sn\",\n",
            "    \"help\" : \"Supported types: SensorSystem, InterpolatedDataset, RegionDataset\"\n",
            "  }\n",
            "}\n",
            "  Checking SeNorge data availability for g44...\n",
            "  SeNorge data available for g44\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "    Variable snow_depth: Available\n",
            "  Checking NVE glacier data availability for g44...\n",
            "  NVE API error: 404\n",
            "  Checking CHELSA data availability for g44...\n",
            "  Cannot access CHELSA website: HTTPSConnectionPool(host='chelsa-climate.org', port=443): Max retries exceeded with url: /downloads/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7cbbcc051090>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "  Checking E-OBS data availability for g44...\n",
            "  E-OBS data available for g44\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "Checking data availability for site: g46 (61.5359, 7.098983188)\n",
            "  Checking NOAA stations near g46...\n",
            "  Found station: VEITASTROND, NO (61.4781, 7.0339)\n",
            "    Variable PRCP: Available\n",
            "    Variable TMAX: Not available\n",
            "    Variable TMIN: Not available\n",
            "    Variable AWND: Not available\n",
            "    Variable SNOW: Not available (API error)\n",
            "    Variable SNWD: Not available (API error)\n",
            "    Variable ACSH: Not available (API error)\n",
            "  Checking ERA5 data availability for g46...\n",
            "  Error checking ERA5 data: No module named 'cdsapi'\n",
            "  Checking MET Norway Frost data availability for g46...\n",
            "  Frost API error: 400 - {\n",
            "  \"@context\" : \"https://frost.met.no/schema\",\n",
            "  \"@type\" : \"ErrorResponse\",\n",
            "  \"apiVersion\" : \"v0\",\n",
            "  \"license\" : \"https://creativecommons.org/licenses/by/3.0/no/\",\n",
            "  \"createdAt\" : \"2025-05-15T19:12:48Z\",\n",
            "  \"queryTime\" : 0,\n",
            "  \"currentLink\" : \"https://frost.met.no/sources/v0.jsonld?geometry=nearest%28POINT%287.098983188+61.5359%29%29&nearestmaxcount=5&types=SN\",\n",
            "  \"error\" : {\n",
            "    \"code\" : 400,\n",
            "    \"message\" : \"Bad Request\",\n",
            "    \"reason\" : \"Unsupported type: sn\",\n",
            "    \"help\" : \"Supported types: SensorSystem, InterpolatedDataset, RegionDataset\"\n",
            "  }\n",
            "}\n",
            "  Checking SeNorge data availability for g46...\n",
            "  SeNorge data available for g46\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "    Variable snow_depth: Available\n",
            "  Checking NVE glacier data availability for g46...\n",
            "  NVE API error: 404\n",
            "  Checking CHELSA data availability for g46...\n",
            "  Cannot access CHELSA website: HTTPSConnectionPool(host='chelsa-climate.org', port=443): Max retries exceeded with url: /downloads/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7cbbcf90a610>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "  Checking E-OBS data availability for g46...\n",
            "  E-OBS data available for g46\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "Checking data availability for site: g49 (61.6056965, 7.706948551)\n",
            "  Checking NOAA stations near g49...\n",
            "  Found station: SOGNEFJELLHYTTA, NO (61.5644, 7.9978)\n",
            "    Variable PRCP: Available\n",
            "    Variable TMAX: Available\n",
            "    Variable TMIN: Available\n",
            "    Variable AWND: Not available\n",
            "    Variable SNOW: Not available (API error)\n",
            "    Variable SNWD: Not available (API error)\n",
            "    Variable ACSH: Not available (API error)\n",
            "  Checking ERA5 data availability for g49...\n",
            "  Error checking ERA5 data: No module named 'cdsapi'\n",
            "  Checking MET Norway Frost data availability for g49...\n",
            "  Frost API error: 400 - {\n",
            "  \"@context\" : \"https://frost.met.no/schema\",\n",
            "  \"@type\" : \"ErrorResponse\",\n",
            "  \"apiVersion\" : \"v0\",\n",
            "  \"license\" : \"https://creativecommons.org/licenses/by/3.0/no/\",\n",
            "  \"createdAt\" : \"2025-05-15T19:12:50Z\",\n",
            "  \"queryTime\" : 0,\n",
            "  \"currentLink\" : \"https://frost.met.no/sources/v0.jsonld?geometry=nearest%28POINT%287.706948551+61.6056965%29%29&nearestmaxcount=5&types=SN\",\n",
            "  \"error\" : {\n",
            "    \"code\" : 400,\n",
            "    \"message\" : \"Bad Request\",\n",
            "    \"reason\" : \"Unsupported type: sn\",\n",
            "    \"help\" : \"Supported types: SensorSystem, InterpolatedDataset, RegionDataset\"\n",
            "  }\n",
            "}\n",
            "  Checking SeNorge data availability for g49...\n",
            "  SeNorge data available for g49\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "    Variable snow_depth: Available\n",
            "  Checking NVE glacier data availability for g49...\n",
            "  NVE API error: 404\n",
            "  Checking CHELSA data availability for g49...\n",
            "  Cannot access CHELSA website: HTTPSConnectionPool(host='chelsa-climate.org', port=443): Max retries exceeded with url: /downloads/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7cbbcd70b290>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "  Checking E-OBS data availability for g49...\n",
            "  E-OBS data available for g49\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "Checking data availability for site: g50 (69.879229, 20.27749204)\n",
            "  Checking NOAA stations near g50...\n",
            "  Found station: SORKJOSEN LUFTHAVN, NO (69.7889, 20.9553)\n",
            "    Variable PRCP: Not available\n",
            "    Variable TMAX: Available\n",
            "    Variable TMIN: Available\n",
            "    Variable AWND: Not available\n",
            "    Variable SNOW: Not available (API error)\n",
            "    Variable SNWD: Not available (API error)\n",
            "    Variable ACSH: Not available (API error)\n",
            "  Checking ERA5 data availability for g50...\n",
            "  Error checking ERA5 data: No module named 'cdsapi'\n",
            "  Checking MET Norway Frost data availability for g50...\n",
            "  Frost API error: 400 - {\n",
            "  \"@context\" : \"https://frost.met.no/schema\",\n",
            "  \"@type\" : \"ErrorResponse\",\n",
            "  \"apiVersion\" : \"v0\",\n",
            "  \"license\" : \"https://creativecommons.org/licenses/by/3.0/no/\",\n",
            "  \"createdAt\" : \"2025-05-15T19:12:52Z\",\n",
            "  \"queryTime\" : 0.001,\n",
            "  \"currentLink\" : \"https://frost.met.no/sources/v0.jsonld?geometry=nearest%28POINT%2820.27749204+69.879229%29%29&nearestmaxcount=5&types=SN\",\n",
            "  \"error\" : {\n",
            "    \"code\" : 400,\n",
            "    \"message\" : \"Bad Request\",\n",
            "    \"reason\" : \"Unsupported type: sn\",\n",
            "    \"help\" : \"Supported types: SensorSystem, InterpolatedDataset, RegionDataset\"\n",
            "  }\n",
            "}\n",
            "  Checking SeNorge data availability for g50...\n",
            "  SeNorge data available for g50\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "    Variable snow_depth: Available\n",
            "  Checking NVE glacier data availability for g50...\n",
            "  NVE API error: 404\n",
            "  Checking CHELSA data availability for g50...\n",
            "  Cannot access CHELSA website: HTTPSConnectionPool(host='chelsa-climate.org', port=443): Max retries exceeded with url: /downloads/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7cbbcb71ca10>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "  Checking E-OBS data availability for g50...\n",
            "  E-OBS data available for g50\n",
            "    Variable temperature: Available\n",
            "    Variable precipitation: Available\n",
            "\n",
            "Data Availability Summary:\n",
            "\n",
            "g01:\n",
            "  MET Norway Frost: Not available\n",
            "  SeNorge: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "      snow_depth: ✓\n",
            "  NVE: Not available\n",
            "  NOAA: Available\n",
            "    Variables:\n",
            "      PRCP: ✗\n",
            "      TMAX: ✗\n",
            "      TMIN: ✗\n",
            "      AWND: ✗\n",
            "      SNOW: ✗\n",
            "      SNWD: ✗\n",
            "      ACSH: ✗\n",
            "  ERA5: Not available\n",
            "  CHELSA: Not available\n",
            "  E-OBS: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "\n",
            "g11:\n",
            "  MET Norway Frost: Not available\n",
            "  SeNorge: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "      snow_depth: ✓\n",
            "  NVE: Not available\n",
            "  NOAA: Available\n",
            "    Variables:\n",
            "      PRCP: ✗\n",
            "      TMAX: ✗\n",
            "      TMIN: ✗\n",
            "      AWND: ✗\n",
            "      SNOW: ✗\n",
            "      SNWD: ✗\n",
            "      ACSH: ✗\n",
            "  ERA5: Not available\n",
            "  CHELSA: Not available\n",
            "  E-OBS: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "\n",
            "g12:\n",
            "  MET Norway Frost: Not available\n",
            "  SeNorge: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "      snow_depth: ✓\n",
            "  NVE: Not available\n",
            "  NOAA: Available\n",
            "    Variables:\n",
            "      PRCP: ✗\n",
            "      TMAX: ✗\n",
            "      TMIN: ✗\n",
            "      AWND: ✗\n",
            "      SNOW: ✗\n",
            "      SNWD: ✗\n",
            "      ACSH: ✗\n",
            "  ERA5: Not available\n",
            "  CHELSA: Not available\n",
            "  E-OBS: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "\n",
            "g13:\n",
            "  MET Norway Frost: Not available\n",
            "  SeNorge: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "      snow_depth: ✓\n",
            "  NVE: Not available\n",
            "  NOAA: Available\n",
            "    Variables:\n",
            "      PRCP: ✗\n",
            "      TMAX: ✗\n",
            "      TMIN: ✗\n",
            "      AWND: ✗\n",
            "      SNOW: ✗\n",
            "      SNWD: ✗\n",
            "      ACSH: ✗\n",
            "  ERA5: Not available\n",
            "  CHELSA: Not available\n",
            "  E-OBS: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "\n",
            "g19:\n",
            "  MET Norway Frost: Not available\n",
            "  SeNorge: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "      snow_depth: ✓\n",
            "  NVE: Not available\n",
            "  NOAA: Available\n",
            "    Variables:\n",
            "      PRCP: ✓\n",
            "      TMAX: ✗\n",
            "      TMIN: ✗\n",
            "      AWND: ✗\n",
            "      SNOW: ✗\n",
            "      SNWD: ✗\n",
            "      ACSH: ✗\n",
            "  ERA5: Not available\n",
            "  CHELSA: Not available\n",
            "  E-OBS: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "\n",
            "g20:\n",
            "  MET Norway Frost: Not available\n",
            "  SeNorge: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "      snow_depth: ✓\n",
            "  NVE: Not available\n",
            "  NOAA: Available\n",
            "    Variables:\n",
            "      PRCP: ✗\n",
            "      TMAX: ✗\n",
            "      TMIN: ✗\n",
            "      AWND: ✗\n",
            "      SNOW: ✗\n",
            "      SNWD: ✗\n",
            "      ACSH: ✗\n",
            "  ERA5: Not available\n",
            "  CHELSA: Not available\n",
            "  E-OBS: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "\n",
            "g23:\n",
            "  MET Norway Frost: Not available\n",
            "  SeNorge: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "      snow_depth: ✓\n",
            "  NVE: Not available\n",
            "  NOAA: Available\n",
            "    Variables:\n",
            "      PRCP: ✗\n",
            "      TMAX: ✗\n",
            "      TMIN: ✗\n",
            "      AWND: ✗\n",
            "      SNOW: ✗\n",
            "      SNWD: ✗\n",
            "      ACSH: ✗\n",
            "  ERA5: Not available\n",
            "  CHELSA: Not available\n",
            "  E-OBS: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "\n",
            "g25:\n",
            "  MET Norway Frost: Not available\n",
            "  SeNorge: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "      snow_depth: ✓\n",
            "  NVE: Not available\n",
            "  NOAA: Available\n",
            "    Variables:\n",
            "      PRCP: ✗\n",
            "      TMAX: ✗\n",
            "      TMIN: ✗\n",
            "      AWND: ✗\n",
            "      SNOW: ✗\n",
            "      SNWD: ✗\n",
            "      ACSH: ✗\n",
            "  ERA5: Not available\n",
            "  CHELSA: Not available\n",
            "  E-OBS: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "\n",
            "g26:\n",
            "  MET Norway Frost: Not available\n",
            "  SeNorge: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "      snow_depth: ✓\n",
            "  NVE: Not available\n",
            "  NOAA: Available\n",
            "    Variables:\n",
            "      PRCP: ✓\n",
            "      TMAX: ✗\n",
            "      TMIN: ✗\n",
            "      AWND: ✗\n",
            "      SNOW: ✗\n",
            "      SNWD: ✗\n",
            "      ACSH: ✗\n",
            "  ERA5: Not available\n",
            "  CHELSA: Not available\n",
            "  E-OBS: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "\n",
            "g30:\n",
            "  MET Norway Frost: Not available\n",
            "  SeNorge: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "      snow_depth: ✓\n",
            "  NVE: Not available\n",
            "  NOAA: Available\n",
            "    Variables:\n",
            "      PRCP: ✓\n",
            "      TMAX: ✓\n",
            "      TMIN: ✓\n",
            "      AWND: ✗\n",
            "      SNOW: ✗\n",
            "      SNWD: ✗\n",
            "      ACSH: ✗\n",
            "  ERA5: Not available\n",
            "  CHELSA: Not available\n",
            "  E-OBS: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "\n",
            "g35:\n",
            "  MET Norway Frost: Not available\n",
            "  SeNorge: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "      snow_depth: ✓\n",
            "  NVE: Not available\n",
            "  NOAA: Available\n",
            "    Variables:\n",
            "      PRCP: ✓\n",
            "      TMAX: ✗\n",
            "      TMIN: ✗\n",
            "      AWND: ✗\n",
            "      SNOW: ✗\n",
            "      SNWD: ✗\n",
            "      ACSH: ✗\n",
            "  ERA5: Not available\n",
            "  CHELSA: Not available\n",
            "  E-OBS: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "\n",
            "g36:\n",
            "  MET Norway Frost: Not available\n",
            "  SeNorge: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "      snow_depth: ✓\n",
            "  NVE: Not available\n",
            "  NOAA: Available\n",
            "    Variables:\n",
            "      PRCP: ✓\n",
            "      TMAX: ✓\n",
            "      TMIN: ✓\n",
            "      AWND: ✗\n",
            "      SNOW: ✗\n",
            "      SNWD: ✗\n",
            "      ACSH: ✗\n",
            "  ERA5: Not available\n",
            "  CHELSA: Not available\n",
            "  E-OBS: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "\n",
            "g37:\n",
            "  MET Norway Frost: Not available\n",
            "  SeNorge: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "      snow_depth: ✓\n",
            "  NVE: Not available\n",
            "  NOAA: Available\n",
            "    Variables:\n",
            "      PRCP: ✓\n",
            "      TMAX: ✗\n",
            "      TMIN: ✗\n",
            "      AWND: ✗\n",
            "      SNOW: ✗\n",
            "      SNWD: ✗\n",
            "      ACSH: ✗\n",
            "  ERA5: Not available\n",
            "  CHELSA: Not available\n",
            "  E-OBS: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "\n",
            "g39:\n",
            "  MET Norway Frost: Not available\n",
            "  SeNorge: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "      snow_depth: ✓\n",
            "  NVE: Not available\n",
            "  NOAA: Available\n",
            "    Variables:\n",
            "      PRCP: ✓\n",
            "      TMAX: ✓\n",
            "      TMIN: ✓\n",
            "      AWND: ✗\n",
            "      SNOW: ✗\n",
            "      SNWD: ✗\n",
            "      ACSH: ✗\n",
            "  ERA5: Not available\n",
            "  CHELSA: Not available\n",
            "  E-OBS: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "\n",
            "g40:\n",
            "  MET Norway Frost: Not available\n",
            "  SeNorge: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "      snow_depth: ✓\n",
            "  NVE: Not available\n",
            "  NOAA: Available\n",
            "    Variables:\n",
            "      PRCP: ✗\n",
            "      TMAX: ✗\n",
            "      TMIN: ✗\n",
            "      AWND: ✗\n",
            "      SNOW: ✗\n",
            "      SNWD: ✗\n",
            "      ACSH: ✗\n",
            "  ERA5: Not available\n",
            "  CHELSA: Not available\n",
            "  E-OBS: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "\n",
            "g42:\n",
            "  MET Norway Frost: Not available\n",
            "  SeNorge: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "      snow_depth: ✓\n",
            "  NVE: Not available\n",
            "  NOAA: Available\n",
            "    Variables:\n",
            "      PRCP: ✓\n",
            "      TMAX: ✗\n",
            "      TMIN: ✗\n",
            "      AWND: ✗\n",
            "      SNOW: ✗\n",
            "      SNWD: ✗\n",
            "      ACSH: ✗\n",
            "  ERA5: Not available\n",
            "  CHELSA: Not available\n",
            "  E-OBS: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "\n",
            "g44:\n",
            "  MET Norway Frost: Not available\n",
            "  SeNorge: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "      snow_depth: ✓\n",
            "  NVE: Not available\n",
            "  NOAA: Available\n",
            "    Variables:\n",
            "      PRCP: ✗\n",
            "      TMAX: ✗\n",
            "      TMIN: ✗\n",
            "      AWND: ✗\n",
            "      SNOW: ✗\n",
            "      SNWD: ✗\n",
            "      ACSH: ✗\n",
            "  ERA5: Not available\n",
            "  CHELSA: Not available\n",
            "  E-OBS: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "\n",
            "g46:\n",
            "  MET Norway Frost: Not available\n",
            "  SeNorge: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "      snow_depth: ✓\n",
            "  NVE: Not available\n",
            "  NOAA: Available\n",
            "    Variables:\n",
            "      PRCP: ✓\n",
            "      TMAX: ✗\n",
            "      TMIN: ✗\n",
            "      AWND: ✗\n",
            "      SNOW: ✗\n",
            "      SNWD: ✗\n",
            "      ACSH: ✗\n",
            "  ERA5: Not available\n",
            "  CHELSA: Not available\n",
            "  E-OBS: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "\n",
            "g49:\n",
            "  MET Norway Frost: Not available\n",
            "  SeNorge: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "      snow_depth: ✓\n",
            "  NVE: Not available\n",
            "  NOAA: Available\n",
            "    Variables:\n",
            "      PRCP: ✓\n",
            "      TMAX: ✓\n",
            "      TMIN: ✓\n",
            "      AWND: ✗\n",
            "      SNOW: ✗\n",
            "      SNWD: ✗\n",
            "      ACSH: ✗\n",
            "  ERA5: Not available\n",
            "  CHELSA: Not available\n",
            "  E-OBS: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "\n",
            "g50:\n",
            "  MET Norway Frost: Not available\n",
            "  SeNorge: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "      snow_depth: ✓\n",
            "  NVE: Not available\n",
            "  NOAA: Available\n",
            "    Variables:\n",
            "      PRCP: ✗\n",
            "      TMAX: ✓\n",
            "      TMIN: ✓\n",
            "      AWND: ✗\n",
            "      SNOW: ✗\n",
            "      SNWD: ✗\n",
            "      ACSH: ✗\n",
            "  ERA5: Not available\n",
            "  CHELSA: Not available\n",
            "  E-OBS: Available\n",
            "    Variables:\n",
            "      temperature: ✓\n",
            "      precipitation: ✓\n",
            "\n",
            "Step 3: Fetching data from all available sources\n",
            "\n",
            "Fetching data for site: g01 (68.5795155, 18.10738723)\n",
            "  Fetching SeNorge data for g01...\n",
            "    Fetching SeNorge temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/senorge/g01_senorge_temperature.csv\n",
            "    Note: This is synthetic SeNorge temperature data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/senorge/g01_senorge_precipitation.csv\n",
            "    Note: This is synthetic SeNorge precipitation data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge snow depth data...\n",
            "    Snow depth data saved to: /content/climate_outputs/senorge/g01_senorge_snow_depth.csv\n",
            "    Note: This is synthetic SeNorge snow depth data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "  Fetching NOAA data for g01...\n",
            "  No available variables from NOAA for g01\n",
            "  Fetching E-OBS data for g01...\n",
            "    Creating synthetic E-OBS temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/eobs/g01_eobs_temperature.csv\n",
            "    Note: This is synthetic E-OBS temperature data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "    Creating synthetic E-OBS precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/eobs/g01_eobs_precipitation.csv\n",
            "    Note: This is synthetic E-OBS precipitation data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "\n",
            "Fetching data for site: g11 (66.501116, 14.65500999)\n",
            "  Fetching SeNorge data for g11...\n",
            "    Fetching SeNorge temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/senorge/g11_senorge_temperature.csv\n",
            "    Note: This is synthetic SeNorge temperature data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/senorge/g11_senorge_precipitation.csv\n",
            "    Note: This is synthetic SeNorge precipitation data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge snow depth data...\n",
            "    Snow depth data saved to: /content/climate_outputs/senorge/g11_senorge_snow_depth.csv\n",
            "    Note: This is synthetic SeNorge snow depth data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "  Fetching NOAA data for g11...\n",
            "  No available variables from NOAA for g11\n",
            "  Fetching E-OBS data for g11...\n",
            "    Creating synthetic E-OBS temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/eobs/g11_eobs_temperature.csv\n",
            "    Note: This is synthetic E-OBS temperature data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "    Creating synthetic E-OBS precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/eobs/g11_eobs_precipitation.csv\n",
            "    Note: This is synthetic E-OBS precipitation data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "\n",
            "Fetching data for site: g12 (65.445231, 13.13974065)\n",
            "  Fetching SeNorge data for g12...\n",
            "    Fetching SeNorge temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/senorge/g12_senorge_temperature.csv\n",
            "    Note: This is synthetic SeNorge temperature data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/senorge/g12_senorge_precipitation.csv\n",
            "    Note: This is synthetic SeNorge precipitation data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge snow depth data...\n",
            "    Snow depth data saved to: /content/climate_outputs/senorge/g12_senorge_snow_depth.csv\n",
            "    Note: This is synthetic SeNorge snow depth data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "  Fetching NOAA data for g12...\n",
            "  No available variables from NOAA for g12\n",
            "  Fetching E-OBS data for g12...\n",
            "    Creating synthetic E-OBS temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/eobs/g12_eobs_temperature.csv\n",
            "    Note: This is synthetic E-OBS temperature data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "    Creating synthetic E-OBS precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/eobs/g12_eobs_precipitation.csv\n",
            "    Note: This is synthetic E-OBS precipitation data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "\n",
            "Fetching data for site: g13 (65.3825655, 13.1255512)\n",
            "  Fetching SeNorge data for g13...\n",
            "    Fetching SeNorge temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/senorge/g13_senorge_temperature.csv\n",
            "    Note: This is synthetic SeNorge temperature data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/senorge/g13_senorge_precipitation.csv\n",
            "    Note: This is synthetic SeNorge precipitation data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge snow depth data...\n",
            "    Snow depth data saved to: /content/climate_outputs/senorge/g13_senorge_snow_depth.csv\n",
            "    Note: This is synthetic SeNorge snow depth data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "  Fetching NOAA data for g13...\n",
            "  No available variables from NOAA for g13\n",
            "  Fetching E-OBS data for g13...\n",
            "    Creating synthetic E-OBS temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/eobs/g13_eobs_temperature.csv\n",
            "    Note: This is synthetic E-OBS temperature data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "    Creating synthetic E-OBS precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/eobs/g13_eobs_precipitation.csv\n",
            "    Note: This is synthetic E-OBS precipitation data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "\n",
            "Fetching data for site: g19 (61.874247, 7.230626799)\n",
            "  Fetching SeNorge data for g19...\n",
            "    Fetching SeNorge temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/senorge/g19_senorge_temperature.csv\n",
            "    Note: This is synthetic SeNorge temperature data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/senorge/g19_senorge_precipitation.csv\n",
            "    Note: This is synthetic SeNorge precipitation data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge snow depth data...\n",
            "    Snow depth data saved to: /content/climate_outputs/senorge/g19_senorge_snow_depth.csv\n",
            "    Note: This is synthetic SeNorge snow depth data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "  Fetching NOAA data for g19...\n",
            "    Year 1970: 365 records\n",
            "    Year 1971: 365 records\n",
            "    Year 1972: 366 records\n",
            "    Year 1973: 365 records\n",
            "    Year 1974: 365 records\n",
            "    Year 1975: 365 records\n",
            "    Year 1976: 366 records\n",
            "    Year 1977: 365 records\n",
            "    Year 1978: 365 records\n",
            "    Year 1979: 365 records\n",
            "    Year 1980: 366 records\n",
            "    Year 1981: 365 records\n",
            "    Year 1982: 365 records\n",
            "    Year 1983: 365 records\n",
            "    Year 1984: 366 records\n",
            "    Year 1985: 365 records\n",
            "    Year 1986: 365 records\n",
            "    Year 1987: 365 records\n",
            "    Year 1988: 366 records\n",
            "    Year 1989: 365 records\n",
            "    Year 1990: 365 records\n",
            "    Year 1991: 365 records\n",
            "    Year 1992: 366 records\n",
            "    Year 1993: 365 records\n",
            "    Year 1994: 365 records\n",
            "    Year 1995: 365 records\n",
            "    Year 1996: 366 records\n",
            "    Year 1997: 365 records\n",
            "    Year 1998: 365 records\n",
            "    Year 1999: 365 records\n",
            "    Year 2000: 366 records\n",
            "    Year 2001: 365 records\n",
            "    Error fetching data for year 2002: HTTPSConnectionPool(host='www.ncdc.noaa.gov', port=443): Read timed out. (read timeout=30)\n",
            "    Year 2003: 365 records\n",
            "    Year 2004: 366 records\n",
            "    Year 2005: 365 records\n",
            "    Year 2006: 365 records\n",
            "    Year 2007: 365 records\n",
            "    Year 2008: 366 records\n",
            "    Year 2009: 365 records\n",
            "    Year 2010: 365 records\n",
            "    Year 2011: 365 records\n",
            "    Year 2012: 366 records\n",
            "    Year 2013: 365 records\n",
            "    Year 2014: 365 records\n",
            "    Year 2015: 365 records\n",
            "    Year 2016: 366 records\n",
            "    Year 2017: 365 records\n",
            "    Year 2018: 365 records\n",
            "    Year 2019: 365 records\n",
            "    Year 2020: 366 records\n",
            "    Year 2021: 365 records\n",
            "    Year 2022: 365 records\n",
            "    Year 2023: 365 records\n",
            "    Year 2024: 366 records\n",
            "  Raw NOAA data saved to: /content/climate_outputs/noaa/g19_noaa_raw_data.csv\n",
            "  Fetching E-OBS data for g19...\n",
            "    Creating synthetic E-OBS temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/eobs/g19_eobs_temperature.csv\n",
            "    Note: This is synthetic E-OBS temperature data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "    Creating synthetic E-OBS precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/eobs/g19_eobs_precipitation.csv\n",
            "    Note: This is synthetic E-OBS precipitation data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "\n",
            "Fetching data for site: g20 (67.4167205, 16.026525)\n",
            "  Fetching SeNorge data for g20...\n",
            "    Fetching SeNorge temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/senorge/g20_senorge_temperature.csv\n",
            "    Note: This is synthetic SeNorge temperature data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/senorge/g20_senorge_precipitation.csv\n",
            "    Note: This is synthetic SeNorge precipitation data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge snow depth data...\n",
            "    Snow depth data saved to: /content/climate_outputs/senorge/g20_senorge_snow_depth.csv\n",
            "    Note: This is synthetic SeNorge snow depth data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "  Fetching NOAA data for g20...\n",
            "  No available variables from NOAA for g20\n",
            "  Fetching E-OBS data for g20...\n",
            "    Creating synthetic E-OBS temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/eobs/g20_eobs_temperature.csv\n",
            "    Note: This is synthetic E-OBS temperature data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "    Creating synthetic E-OBS precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/eobs/g20_eobs_precipitation.csv\n",
            "    Note: This is synthetic E-OBS precipitation data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "\n",
            "Fetching data for site: g23 (69.275026, 19.76533957)\n",
            "  Fetching SeNorge data for g23...\n",
            "    Fetching SeNorge temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/senorge/g23_senorge_temperature.csv\n",
            "    Note: This is synthetic SeNorge temperature data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/senorge/g23_senorge_precipitation.csv\n",
            "    Note: This is synthetic SeNorge precipitation data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge snow depth data...\n",
            "    Snow depth data saved to: /content/climate_outputs/senorge/g23_senorge_snow_depth.csv\n",
            "    Note: This is synthetic SeNorge snow depth data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "  Fetching NOAA data for g23...\n",
            "  No available variables from NOAA for g23\n",
            "  Fetching E-OBS data for g23...\n",
            "    Creating synthetic E-OBS temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/eobs/g23_eobs_temperature.csv\n",
            "    Note: This is synthetic E-OBS temperature data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "    Creating synthetic E-OBS precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/eobs/g23_eobs_precipitation.csv\n",
            "    Note: This is synthetic E-OBS precipitation data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "\n",
            "Fetching data for site: g25 (69.148559, 20.14820114)\n",
            "  Fetching SeNorge data for g25...\n",
            "    Fetching SeNorge temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/senorge/g25_senorge_temperature.csv\n",
            "    Note: This is synthetic SeNorge temperature data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/senorge/g25_senorge_precipitation.csv\n",
            "    Note: This is synthetic SeNorge precipitation data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge snow depth data...\n",
            "    Snow depth data saved to: /content/climate_outputs/senorge/g25_senorge_snow_depth.csv\n",
            "    Note: This is synthetic SeNorge snow depth data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "  Fetching NOAA data for g25...\n",
            "  No available variables from NOAA for g25\n",
            "  Fetching E-OBS data for g25...\n",
            "    Creating synthetic E-OBS temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/eobs/g25_eobs_temperature.csv\n",
            "    Note: This is synthetic E-OBS temperature data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "    Creating synthetic E-OBS precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/eobs/g25_eobs_precipitation.csv\n",
            "    Note: This is synthetic E-OBS precipitation data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "\n",
            "Fetching data for site: g26 (62.186858, 7.742994409)\n",
            "  Fetching SeNorge data for g26...\n",
            "    Fetching SeNorge temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/senorge/g26_senorge_temperature.csv\n",
            "    Note: This is synthetic SeNorge temperature data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/senorge/g26_senorge_precipitation.csv\n",
            "    Note: This is synthetic SeNorge precipitation data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge snow depth data...\n",
            "    Snow depth data saved to: /content/climate_outputs/senorge/g26_senorge_snow_depth.csv\n",
            "    Note: This is synthetic SeNorge snow depth data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "  Fetching NOAA data for g26...\n",
            "    Year 1970: No data found\n",
            "    Year 1971: No data found\n",
            "    Year 1972: 63 records\n",
            "    Year 1973: 365 records\n",
            "    Year 1974: 365 records\n",
            "    Year 1975: 365 records\n",
            "    Year 1976: 366 records\n",
            "    Year 1977: 365 records\n",
            "    Year 1978: 365 records\n",
            "    Year 1979: 365 records\n",
            "    Year 1980: 366 records\n",
            "    Year 1981: 365 records\n",
            "    Year 1982: 365 records\n",
            "    Year 1983: 365 records\n",
            "    Year 1984: 366 records\n",
            "    Year 1985: 365 records\n",
            "    Year 1986: 365 records\n",
            "    Year 1987: 365 records\n",
            "    Year 1988: 366 records\n",
            "    Year 1989: 365 records\n",
            "    Year 1990: 365 records\n",
            "    Year 1991: 365 records\n",
            "    Year 1992: 366 records\n",
            "    Year 1993: 365 records\n",
            "    Year 1994: 365 records\n",
            "    Year 1995: 365 records\n",
            "    Year 1996: 366 records\n",
            "    Year 1997: 365 records\n",
            "    Year 1998: 365 records\n",
            "    Year 1999: 365 records\n",
            "    Year 2000: 366 records\n",
            "    Year 2001: 365 records\n",
            "    Year 2002: 365 records\n",
            "    Year 2003: 365 records\n",
            "    Year 2004: 366 records\n",
            "    Year 2005: 365 records\n",
            "    Year 2006: 365 records\n",
            "    Year 2007: 365 records\n",
            "    Year 2008: 366 records\n",
            "    Year 2009: 365 records\n",
            "    Year 2010: 365 records\n",
            "    Year 2011: 365 records\n",
            "    Year 2012: 366 records\n",
            "    Year 2013: 355 records\n",
            "    Year 2014: 365 records\n",
            "    Year 2015: 365 records\n",
            "    Year 2016: 366 records\n",
            "    Year 2017: 365 records\n",
            "    Year 2018: 365 records\n",
            "    Year 2019: 365 records\n",
            "    Year 2020: 366 records\n",
            "    Year 2021: 365 records\n",
            "    Year 2022: 365 records\n",
            "    Year 2023: 365 records\n",
            "    Year 2024: 366 records\n",
            "  Raw NOAA data saved to: /content/climate_outputs/noaa/g26_noaa_raw_data.csv\n",
            "  Fetching E-OBS data for g26...\n",
            "    Creating synthetic E-OBS temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/eobs/g26_eobs_temperature.csv\n",
            "    Note: This is synthetic E-OBS temperature data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "    Creating synthetic E-OBS precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/eobs/g26_eobs_precipitation.csv\n",
            "    Note: This is synthetic E-OBS precipitation data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "\n",
            "Fetching data for site: g30 (60.679787, 7.453940643)\n",
            "  Fetching SeNorge data for g30...\n",
            "    Fetching SeNorge temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/senorge/g30_senorge_temperature.csv\n",
            "    Note: This is synthetic SeNorge temperature data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/senorge/g30_senorge_precipitation.csv\n",
            "    Note: This is synthetic SeNorge precipitation data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge snow depth data...\n",
            "    Snow depth data saved to: /content/climate_outputs/senorge/g30_senorge_snow_depth.csv\n",
            "    Note: This is synthetic SeNorge snow depth data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "  Fetching NOAA data for g30...\n",
            "    Year 1970: 211 records\n",
            "    Year 1971: No data found\n",
            "    Year 1972: No data found\n",
            "    Year 1973: No data found\n",
            "    Year 1974: No data found\n",
            "    Year 1975: No data found\n",
            "    Year 1976: No data found\n",
            "    Year 1977: No data found\n",
            "    Year 1978: No data found\n",
            "    Year 1979: No data found\n",
            "    Year 1980: No data found\n",
            "    Year 1981: No data found\n",
            "    Year 1982: No data found\n",
            "    Year 1983: No data found\n",
            "    Year 1984: No data found\n",
            "    Year 1985: No data found\n",
            "    Year 1986: No data found\n",
            "    Year 1987: No data found\n",
            "    Error fetching data for year 1988: HTTPSConnectionPool(host='www.ncdc.noaa.gov', port=443): Read timed out. (read timeout=30)\n",
            "    Year 1989: No data found\n",
            "    Year 1990: No data found\n",
            "    Year 1991: No data found\n",
            "    Year 1992: No data found\n",
            "    Year 1993: No data found\n",
            "    Year 1994: No data found\n",
            "    Year 1995: No data found\n",
            "    Year 1996: No data found\n",
            "    Year 1997: No data found\n",
            "    Year 1998: No data found\n",
            "    Year 1999: No data found\n",
            "    Year 2000: No data found\n",
            "    Year 2001: No data found\n",
            "    Year 2002: No data found\n",
            "    Year 2003: No data found\n",
            "    Year 2004: No data found\n",
            "    Year 2005: 387 records\n",
            "    Year 2006: 1000 records\n",
            "    Year 2007: 1000 records\n",
            "    Year 2008: 1000 records\n",
            "    Year 2009: 1000 records\n",
            "    Year 2010: 1000 records\n",
            "    Year 2011: 1000 records\n",
            "    Year 2012: 1000 records\n",
            "    Year 2013: 1000 records\n",
            "    Year 2014: 1000 records\n",
            "    Year 2015: 1000 records\n",
            "    Year 2016: 1000 records\n",
            "    Year 2017: 991 records\n",
            "    Year 2018: 721 records\n",
            "    Year 2019: 827 records\n",
            "    Year 2020: 920 records\n",
            "    Year 2021: 1000 records\n",
            "    Year 2022: 1000 records\n",
            "    Year 2023: 1000 records\n",
            "    Year 2024: 1000 records\n",
            "  Raw NOAA data saved to: /content/climate_outputs/noaa/g30_noaa_raw_data.csv\n",
            "  Fetching E-OBS data for g30...\n",
            "    Creating synthetic E-OBS temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/eobs/g30_eobs_temperature.csv\n",
            "    Note: This is synthetic E-OBS temperature data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "    Creating synthetic E-OBS precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/eobs/g30_eobs_precipitation.csv\n",
            "    Note: This is synthetic E-OBS precipitation data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "\n",
            "Fetching data for site: g35 (61.572909, 8.469539738)\n",
            "  Fetching SeNorge data for g35...\n",
            "    Fetching SeNorge temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/senorge/g35_senorge_temperature.csv\n",
            "    Note: This is synthetic SeNorge temperature data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/senorge/g35_senorge_precipitation.csv\n",
            "    Note: This is synthetic SeNorge precipitation data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge snow depth data...\n",
            "    Snow depth data saved to: /content/climate_outputs/senorge/g35_senorge_snow_depth.csv\n",
            "    Note: This is synthetic SeNorge snow depth data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "  Fetching NOAA data for g35...\n",
            "    Year 1970: 365 records\n",
            "    Year 1971: 365 records\n",
            "    Year 1972: 366 records\n",
            "    Year 1973: 365 records\n",
            "    Year 1974: 365 records\n",
            "    Year 1975: 365 records\n",
            "    Year 1976: 366 records\n",
            "    Year 1977: 365 records\n",
            "    Year 1978: 365 records\n",
            "    Year 1979: 365 records\n",
            "    Year 1980: 366 records\n",
            "    Year 1981: 365 records\n",
            "    Year 1982: 365 records\n",
            "    Year 1983: 365 records\n",
            "    Error fetching data for year 1984: HTTPSConnectionPool(host='www.ncdc.noaa.gov', port=443): Read timed out. (read timeout=30)\n",
            "    Year 1985: 365 records\n",
            "    Year 1986: 365 records\n",
            "    Year 1987: 365 records\n",
            "    Year 1988: 366 records\n",
            "    Year 1989: 365 records\n",
            "    Year 1990: 365 records\n",
            "    Year 1991: 365 records\n",
            "    Year 1992: 366 records\n",
            "    Year 1993: 365 records\n",
            "    Year 1994: 365 records\n",
            "    Year 1995: 365 records\n",
            "    Year 1996: 366 records\n",
            "    Year 1997: 365 records\n",
            "    Year 1998: 365 records\n",
            "    Year 1999: 365 records\n",
            "    Year 2000: 366 records\n",
            "    Year 2001: 365 records\n",
            "    Year 2002: 365 records\n",
            "    Year 2003: 365 records\n",
            "    Year 2004: 366 records\n",
            "    Year 2005: 365 records\n",
            "    Year 2006: 365 records\n",
            "    Year 2007: 365 records\n",
            "    Year 2008: 366 records\n",
            "    Year 2009: 365 records\n",
            "    Year 2010: 365 records\n",
            "    Year 2011: 365 records\n",
            "    Year 2012: 366 records\n",
            "    Year 2013: 365 records\n",
            "    Year 2014: 359 records\n",
            "    Year 2015: 359 records\n",
            "    Year 2016: 366 records\n",
            "    Year 2017: 359 records\n",
            "    Year 2018: 330 records\n",
            "    Year 2019: 365 records\n",
            "    Year 2020: 366 records\n",
            "    Year 2021: 365 records\n",
            "    Year 2022: 365 records\n",
            "    Year 2023: 365 records\n",
            "    Year 2024: 366 records\n",
            "  Raw NOAA data saved to: /content/climate_outputs/noaa/g35_noaa_raw_data.csv\n",
            "  Fetching E-OBS data for g35...\n",
            "    Creating synthetic E-OBS temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/eobs/g35_eobs_temperature.csv\n",
            "    Note: This is synthetic E-OBS temperature data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "    Creating synthetic E-OBS precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/eobs/g35_eobs_precipitation.csv\n",
            "    Note: This is synthetic E-OBS precipitation data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "\n",
            "Fetching data for site: g36 (61.650676, 6.313671936)\n",
            "  Fetching SeNorge data for g36...\n",
            "    Fetching SeNorge temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/senorge/g36_senorge_temperature.csv\n",
            "    Note: This is synthetic SeNorge temperature data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/senorge/g36_senorge_precipitation.csv\n",
            "    Note: This is synthetic SeNorge precipitation data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge snow depth data...\n",
            "    Snow depth data saved to: /content/climate_outputs/senorge/g36_senorge_snow_depth.csv\n",
            "    Note: This is synthetic SeNorge snow depth data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "  Fetching NOAA data for g36...\n",
            "    Year 1970: 1000 records\n",
            "    Year 1971: 1000 records\n",
            "    Year 1972: 1000 records\n",
            "    Year 1973: 1000 records\n",
            "    Year 1974: 1000 records\n",
            "    Year 1975: 1000 records\n",
            "    Year 1976: 1000 records\n",
            "    Year 1977: 1000 records\n",
            "    Year 1978: 1000 records\n",
            "    Year 1979: 1000 records\n",
            "    Year 1980: 1000 records\n",
            "    Year 1981: 1000 records\n",
            "    Year 1982: 1000 records\n",
            "    Year 1983: 1000 records\n",
            "    Year 1984: 1000 records\n",
            "    Year 1985: 1000 records\n",
            "    Year 1986: 1000 records\n",
            "    Year 1987: 1000 records\n",
            "    Year 1988: 1000 records\n",
            "    Year 1989: 1000 records\n",
            "    Year 1990: 1000 records\n",
            "    Year 1991: 1000 records\n",
            "    Year 1992: 1000 records\n",
            "    Year 1993: 1000 records\n",
            "    Year 1994: 1000 records\n",
            "    Year 1995: 1000 records\n",
            "    Year 1996: 1000 records\n",
            "    Year 1997: 1000 records\n",
            "    Year 1998: 1000 records\n",
            "    Year 1999: 1000 records\n",
            "    Year 2000: 1000 records\n",
            "    Year 2001: 1000 records\n",
            "    Error fetching data for year 2002: HTTPSConnectionPool(host='www.ncdc.noaa.gov', port=443): Read timed out. (read timeout=30)\n",
            "    Year 2003: 1000 records\n",
            "    Year 2004: 1000 records\n",
            "    Year 2005: 979 records\n",
            "    Year 2006: 1000 records\n",
            "    Year 2007: 1000 records\n",
            "    Year 2008: 1000 records\n",
            "    Year 2009: 1000 records\n",
            "    Year 2010: 1000 records\n",
            "    Year 2011: 1000 records\n",
            "    Year 2012: 1000 records\n",
            "    Year 2013: 1000 records\n",
            "    Year 2014: 1000 records\n",
            "    Year 2015: 1000 records\n",
            "    Year 2016: 1000 records\n",
            "    Year 2017: 1000 records\n",
            "    Year 2018: 365 records\n",
            "    Year 2019: 365 records\n",
            "    Year 2020: 816 records\n",
            "    Year 2021: 1000 records\n",
            "    Year 2022: 1000 records\n",
            "    Year 2023: 1000 records\n",
            "    Year 2024: 1000 records\n",
            "  Raw NOAA data saved to: /content/climate_outputs/noaa/g36_noaa_raw_data.csv\n",
            "  Fetching E-OBS data for g36...\n",
            "    Creating synthetic E-OBS temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/eobs/g36_eobs_temperature.csv\n",
            "    Note: This is synthetic E-OBS temperature data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "    Creating synthetic E-OBS precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/eobs/g36_eobs_precipitation.csv\n",
            "    Note: This is synthetic E-OBS precipitation data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "\n",
            "Fetching data for site: g37 (61.484647, 6.902982941)\n",
            "  Fetching SeNorge data for g37...\n",
            "    Fetching SeNorge temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/senorge/g37_senorge_temperature.csv\n",
            "    Note: This is synthetic SeNorge temperature data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/senorge/g37_senorge_precipitation.csv\n",
            "    Note: This is synthetic SeNorge precipitation data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge snow depth data...\n",
            "    Snow depth data saved to: /content/climate_outputs/senorge/g37_senorge_snow_depth.csv\n",
            "    Note: This is synthetic SeNorge snow depth data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "  Fetching NOAA data for g37...\n",
            "    Year 1970: No data found\n",
            "    Year 1971: No data found\n",
            "    Year 1972: 124 records\n",
            "    Year 1973: 365 records\n",
            "    Year 1974: 365 records\n",
            "    Year 1975: 365 records\n",
            "    Year 1976: 366 records\n",
            "    Year 1977: 365 records\n",
            "    Year 1978: 365 records\n",
            "    Year 1979: 365 records\n",
            "    Year 1980: 366 records\n",
            "    Year 1981: 365 records\n",
            "    Year 1982: 365 records\n",
            "    Year 1983: 365 records\n",
            "    Year 1984: 366 records\n",
            "    Year 1985: 365 records\n",
            "    Year 1986: 365 records\n",
            "    Year 1987: 365 records\n",
            "    Year 1988: 366 records\n",
            "    Year 1989: 365 records\n",
            "    Year 1990: 365 records\n",
            "    Year 1991: 365 records\n",
            "    Year 1992: 366 records\n",
            "    Year 1993: 365 records\n",
            "    Year 1994: 365 records\n",
            "    Year 1995: 365 records\n",
            "    Year 1996: 366 records\n",
            "    Year 1997: 365 records\n",
            "    Year 1998: 365 records\n",
            "    Year 1999: 365 records\n",
            "    Year 2000: 366 records\n",
            "    Year 2001: 365 records\n",
            "    Year 2002: 365 records\n",
            "    Year 2003: 365 records\n",
            "    Year 2004: 366 records\n",
            "    Year 2005: 365 records\n",
            "    Year 2006: 365 records\n",
            "    Year 2007: 365 records\n",
            "    Year 2008: 366 records\n",
            "    Year 2009: 365 records\n",
            "    Year 2010: 365 records\n",
            "    Year 2011: 365 records\n",
            "    Year 2012: 366 records\n",
            "    Year 2013: 365 records\n",
            "    Year 2014: 365 records\n",
            "    Year 2015: 365 records\n",
            "    Year 2016: 366 records\n",
            "    Year 2017: 365 records\n",
            "    Year 2018: 365 records\n",
            "    Year 2019: 365 records\n",
            "    Year 2020: 366 records\n",
            "    Year 2021: 365 records\n",
            "    Year 2022: 365 records\n",
            "    Year 2023: 365 records\n",
            "    Year 2024: 366 records\n",
            "  Raw NOAA data saved to: /content/climate_outputs/noaa/g37_noaa_raw_data.csv\n",
            "  Fetching E-OBS data for g37...\n",
            "    Creating synthetic E-OBS temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/eobs/g37_eobs_temperature.csv\n",
            "    Note: This is synthetic E-OBS temperature data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "    Creating synthetic E-OBS precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/eobs/g37_eobs_precipitation.csv\n",
            "    Note: This is synthetic E-OBS precipitation data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "\n",
            "Fetching data for site: g39 (61.930845, 7.595518424)\n",
            "  Fetching SeNorge data for g39...\n",
            "    Fetching SeNorge temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/senorge/g39_senorge_temperature.csv\n",
            "    Note: This is synthetic SeNorge temperature data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/senorge/g39_senorge_precipitation.csv\n",
            "    Note: This is synthetic SeNorge precipitation data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge snow depth data...\n",
            "    Snow depth data saved to: /content/climate_outputs/senorge/g39_senorge_snow_depth.csv\n",
            "    Note: This is synthetic SeNorge snow depth data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "  Fetching NOAA data for g39...\n",
            "    Year 1970: 1000 records\n",
            "    Year 1971: 1000 records\n",
            "    Year 1972: 1000 records\n",
            "    Year 1973: 1000 records\n",
            "    Year 1974: 1000 records\n",
            "    Year 1975: 1000 records\n",
            "    Year 1976: 1000 records\n",
            "    Year 1977: 1000 records\n",
            "    Year 1978: 1000 records\n",
            "    Year 1979: 1000 records\n",
            "    Year 1980: 1000 records\n",
            "    Error fetching data for year 1981: HTTPSConnectionPool(host='www.ncdc.noaa.gov', port=443): Read timed out. (read timeout=30)\n",
            "    Year 1982: 1000 records\n",
            "    Year 1983: 1000 records\n",
            "    Year 1984: 976 records\n",
            "    Year 1985: 1000 records\n",
            "    Year 1986: 1000 records\n",
            "    Year 1987: 1000 records\n",
            "    Year 1988: 1000 records\n",
            "    Year 1989: 1000 records\n",
            "    Year 1990: 1000 records\n",
            "    Year 1991: 1000 records\n",
            "    Year 1992: 1000 records\n",
            "    Year 1993: 1000 records\n",
            "    Year 1994: 1000 records\n",
            "    Year 1995: 1000 records\n",
            "    Year 1996: 1000 records\n",
            "    Year 1997: 1000 records\n",
            "    Year 1998: 1000 records\n",
            "    Error fetching data for year 1999: HTTPSConnectionPool(host='www.ncdc.noaa.gov', port=443): Read timed out. (read timeout=30)\n",
            "    Year 2000: 1000 records\n",
            "    Year 2001: 1000 records\n",
            "    Year 2002: 1000 records\n",
            "    Year 2003: 1000 records\n",
            "    Year 2004: 1000 records\n",
            "    Year 2005: 1000 records\n",
            "    Year 2006: 1000 records\n",
            "    Year 2007: 1000 records\n",
            "    Year 2008: 1000 records\n",
            "    Year 2009: 1000 records\n",
            "    Year 2010: 1000 records\n",
            "    Year 2011: 1000 records\n",
            "    Year 2012: 1000 records\n",
            "    Year 2013: 1000 records\n",
            "    Year 2014: 1000 records\n",
            "    Year 2015: 1000 records\n",
            "    Year 2016: 1000 records\n",
            "    Year 2017: 1000 records\n",
            "    Year 2018: 1000 records\n",
            "    Year 2019: 1000 records\n",
            "    Year 2020: 1000 records\n",
            "    Year 2021: 1000 records\n",
            "    Year 2022: 1000 records\n",
            "    Year 2023: 1000 records\n",
            "    Year 2024: 1000 records\n",
            "  Raw NOAA data saved to: /content/climate_outputs/noaa/g39_noaa_raw_data.csv\n",
            "  Fetching E-OBS data for g39...\n",
            "    Creating synthetic E-OBS temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/eobs/g39_eobs_temperature.csv\n",
            "    Note: This is synthetic E-OBS temperature data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "    Creating synthetic E-OBS precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/eobs/g39_eobs_precipitation.csv\n",
            "    Note: This is synthetic E-OBS precipitation data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "\n",
            "Fetching data for site: g40 (70.410803, 23.24991325)\n",
            "  Fetching SeNorge data for g40...\n",
            "    Fetching SeNorge temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/senorge/g40_senorge_temperature.csv\n",
            "    Note: This is synthetic SeNorge temperature data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/senorge/g40_senorge_precipitation.csv\n",
            "    Note: This is synthetic SeNorge precipitation data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge snow depth data...\n",
            "    Snow depth data saved to: /content/climate_outputs/senorge/g40_senorge_snow_depth.csv\n",
            "    Note: This is synthetic SeNorge snow depth data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "  Fetching NOAA data for g40...\n",
            "  No available variables from NOAA for g40\n",
            "  Fetching E-OBS data for g40...\n",
            "    Creating synthetic E-OBS temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/eobs/g40_eobs_temperature.csv\n",
            "    Note: This is synthetic E-OBS temperature data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "    Creating synthetic E-OBS precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/eobs/g40_eobs_precipitation.csv\n",
            "    Note: This is synthetic E-OBS precipitation data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "\n",
            "Fetching data for site: g42 (62.071645, 8.153036994)\n",
            "  Fetching SeNorge data for g42...\n",
            "    Fetching SeNorge temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/senorge/g42_senorge_temperature.csv\n",
            "    Note: This is synthetic SeNorge temperature data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/senorge/g42_senorge_precipitation.csv\n",
            "    Note: This is synthetic SeNorge precipitation data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge snow depth data...\n",
            "    Snow depth data saved to: /content/climate_outputs/senorge/g42_senorge_snow_depth.csv\n",
            "    Note: This is synthetic SeNorge snow depth data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "  Fetching NOAA data for g42...\n",
            "    Year 1970: 365 records\n",
            "    Year 1971: 365 records\n",
            "    Year 1972: 366 records\n",
            "    Year 1973: 365 records\n",
            "    Year 1974: 365 records\n",
            "    Year 1975: 365 records\n",
            "    Year 1976: 366 records\n",
            "    Year 1977: 365 records\n",
            "    Year 1978: 365 records\n",
            "    Year 1979: 365 records\n",
            "    Year 1980: 366 records\n",
            "    Year 1981: 365 records\n",
            "    Year 1982: 365 records\n",
            "    Year 1983: 365 records\n",
            "    Year 1984: 366 records\n",
            "    Year 1985: 365 records\n",
            "    Year 1986: 365 records\n",
            "    Year 1987: 365 records\n",
            "    Year 1988: 366 records\n",
            "    Year 1989: 365 records\n",
            "    Year 1990: 365 records\n",
            "    Year 1991: 365 records\n",
            "    Year 1992: 366 records\n",
            "    Year 1993: 365 records\n",
            "    Year 1994: 365 records\n",
            "    Year 1995: 365 records\n",
            "    Year 1996: 366 records\n",
            "    Year 1997: 365 records\n",
            "    Year 1998: 365 records\n",
            "    Year 1999: 365 records\n",
            "    Year 2000: 366 records\n",
            "    Year 2001: 365 records\n",
            "    Year 2002: 365 records\n",
            "    Year 2003: 365 records\n",
            "    Year 2004: 366 records\n",
            "    Year 2005: 365 records\n",
            "    Year 2006: 365 records\n",
            "    Year 2007: 365 records\n",
            "    Year 2008: 366 records\n",
            "    Year 2009: 365 records\n",
            "    Error fetching data for year 2010: HTTPSConnectionPool(host='www.ncdc.noaa.gov', port=443): Read timed out. (read timeout=30)\n",
            "    Year 2011: 365 records\n",
            "    Year 2012: 366 records\n",
            "    Year 2013: 365 records\n",
            "    Year 2014: 365 records\n",
            "    Year 2015: 365 records\n",
            "    Year 2016: 366 records\n",
            "    Year 2017: 365 records\n",
            "    Year 2018: 365 records\n",
            "    Year 2019: 365 records\n",
            "    Year 2020: 366 records\n",
            "    Year 2021: 365 records\n",
            "    Year 2022: 365 records\n",
            "    Year 2023: 365 records\n",
            "    Year 2024: 366 records\n",
            "  Raw NOAA data saved to: /content/climate_outputs/noaa/g42_noaa_raw_data.csv\n",
            "  Fetching E-OBS data for g42...\n",
            "    Creating synthetic E-OBS temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/eobs/g42_eobs_temperature.csv\n",
            "    Note: This is synthetic E-OBS temperature data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "    Creating synthetic E-OBS precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/eobs/g42_eobs_precipitation.csv\n",
            "    Note: This is synthetic E-OBS precipitation data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "\n",
            "Fetching data for site: g44 (68.336643, 17.37986938)\n",
            "  Fetching SeNorge data for g44...\n",
            "    Fetching SeNorge temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/senorge/g44_senorge_temperature.csv\n",
            "    Note: This is synthetic SeNorge temperature data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/senorge/g44_senorge_precipitation.csv\n",
            "    Note: This is synthetic SeNorge precipitation data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge snow depth data...\n",
            "    Snow depth data saved to: /content/climate_outputs/senorge/g44_senorge_snow_depth.csv\n",
            "    Note: This is synthetic SeNorge snow depth data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "  Fetching NOAA data for g44...\n",
            "  No available variables from NOAA for g44\n",
            "  Fetching E-OBS data for g44...\n",
            "    Creating synthetic E-OBS temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/eobs/g44_eobs_temperature.csv\n",
            "    Note: This is synthetic E-OBS temperature data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "    Creating synthetic E-OBS precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/eobs/g44_eobs_precipitation.csv\n",
            "    Note: This is synthetic E-OBS precipitation data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "\n",
            "Fetching data for site: g46 (61.5359, 7.098983188)\n",
            "  Fetching SeNorge data for g46...\n",
            "    Fetching SeNorge temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/senorge/g46_senorge_temperature.csv\n",
            "    Note: This is synthetic SeNorge temperature data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/senorge/g46_senorge_precipitation.csv\n",
            "    Note: This is synthetic SeNorge precipitation data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge snow depth data...\n",
            "    Snow depth data saved to: /content/climate_outputs/senorge/g46_senorge_snow_depth.csv\n",
            "    Note: This is synthetic SeNorge snow depth data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "  Fetching NOAA data for g46...\n",
            "    Year 1970: No data found\n",
            "    Year 1971: No data found\n",
            "    Year 1972: 124 records\n",
            "    Year 1973: 365 records\n",
            "    Year 1974: 365 records\n",
            "    Year 1975: 365 records\n",
            "    Year 1976: 366 records\n",
            "    Year 1977: 365 records\n",
            "    Year 1978: 365 records\n",
            "    Year 1979: 365 records\n",
            "    Year 1980: 366 records\n",
            "    Year 1981: 365 records\n",
            "    Year 1982: 365 records\n",
            "    Year 1983: 365 records\n",
            "    Year 1984: 366 records\n",
            "    Year 1985: 365 records\n",
            "    Year 1986: 365 records\n",
            "    Year 1987: 365 records\n",
            "    Year 1988: 366 records\n",
            "    Year 1989: 365 records\n",
            "    Year 1990: 365 records\n",
            "    Year 1991: 365 records\n",
            "    Year 1992: 366 records\n",
            "    Year 1993: 365 records\n",
            "    Year 1994: 365 records\n",
            "    Year 1995: 365 records\n",
            "    Error fetching data for year 1996: HTTPSConnectionPool(host='www.ncdc.noaa.gov', port=443): Read timed out. (read timeout=30)\n",
            "    Year 1997: 365 records\n",
            "    Year 1998: 365 records\n",
            "    Year 1999: 365 records\n",
            "    Year 2000: 366 records\n",
            "    Year 2001: 365 records\n",
            "    Year 2002: 365 records\n",
            "    Year 2003: 365 records\n",
            "    Year 2004: 366 records\n",
            "    Year 2005: 365 records\n",
            "    Year 2006: 365 records\n",
            "    Year 2007: 365 records\n",
            "    Year 2008: 366 records\n",
            "    Year 2009: 365 records\n",
            "    Year 2010: 365 records\n",
            "    Year 2011: 365 records\n",
            "    Year 2012: 366 records\n",
            "    Year 2013: 365 records\n",
            "    Year 2014: 365 records\n",
            "    Year 2015: 365 records\n",
            "    Year 2016: 366 records\n",
            "    Year 2017: 365 records\n",
            "    Year 2018: 365 records\n",
            "    Year 2019: 365 records\n",
            "    Year 2020: 366 records\n",
            "    Year 2021: 365 records\n",
            "    Year 2022: 365 records\n",
            "    Year 2023: 365 records\n",
            "    Year 2024: 366 records\n",
            "  Raw NOAA data saved to: /content/climate_outputs/noaa/g46_noaa_raw_data.csv\n",
            "  Fetching E-OBS data for g46...\n",
            "    Creating synthetic E-OBS temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/eobs/g46_eobs_temperature.csv\n",
            "    Note: This is synthetic E-OBS temperature data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "    Creating synthetic E-OBS precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/eobs/g46_eobs_precipitation.csv\n",
            "    Note: This is synthetic E-OBS precipitation data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "\n",
            "Fetching data for site: g49 (61.6056965, 7.706948551)\n",
            "  Fetching SeNorge data for g49...\n",
            "    Fetching SeNorge temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/senorge/g49_senorge_temperature.csv\n",
            "    Note: This is synthetic SeNorge temperature data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/senorge/g49_senorge_precipitation.csv\n",
            "    Note: This is synthetic SeNorge precipitation data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge snow depth data...\n",
            "    Snow depth data saved to: /content/climate_outputs/senorge/g49_senorge_snow_depth.csv\n",
            "    Note: This is synthetic SeNorge snow depth data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "  Fetching NOAA data for g49...\n",
            "    Year 1970: No data found\n",
            "    Year 1971: No data found\n",
            "    Year 1972: No data found\n",
            "    Year 1973: No data found\n",
            "    Year 1974: No data found\n",
            "    Year 1975: No data found\n",
            "    Year 1976: No data found\n",
            "    Year 1977: No data found\n",
            "    Year 1978: 94 records\n",
            "    Year 1979: 1000 records\n",
            "    Year 1980: 1000 records\n",
            "    Year 1981: 1000 records\n",
            "    Year 1982: 1000 records\n",
            "    Year 1983: 1000 records\n",
            "    Year 1984: 1000 records\n",
            "    Year 1985: 1000 records\n",
            "    Year 1986: 1000 records\n",
            "    Year 1987: 1000 records\n",
            "    Error fetching data for year 1988: HTTPSConnectionPool(host='www.ncdc.noaa.gov', port=443): Read timed out. (read timeout=30)\n",
            "    Year 1989: 452 records\n",
            "    Year 1990: No data found\n",
            "    Year 1991: No data found\n",
            "    Year 1992: No data found\n",
            "    Year 1993: No data found\n",
            "    Year 1994: No data found\n",
            "    Year 1995: No data found\n",
            "    Year 1996: No data found\n",
            "    Year 1997: 331 records\n",
            "    Year 1998: 730 records\n",
            "    Error fetching data for year 1999: HTTPSConnectionPool(host='www.ncdc.noaa.gov', port=443): Read timed out. (read timeout=30)\n",
            "    Year 2000: 672 records\n",
            "    Error fetching data for year 2001: HTTPSConnectionPool(host='www.ncdc.noaa.gov', port=443): Read timed out. (read timeout=30)\n",
            "    Error fetching data for year 2002: HTTPSConnectionPool(host='www.ncdc.noaa.gov', port=443): Read timed out. (read timeout=30)\n",
            "    Year 2003: 730 records\n",
            "    Year 2004: 732 records\n",
            "    Year 2005: 726 records\n",
            "    Error fetching data for year 2006: HTTPSConnectionPool(host='www.ncdc.noaa.gov', port=443): Read timed out. (read timeout=30)\n",
            "    Year 2007: 730 records\n",
            "    Year 2008: 732 records\n",
            "    Error fetching data for year 2009: HTTPSConnectionPool(host='www.ncdc.noaa.gov', port=443): Read timed out. (read timeout=30)\n",
            "    Year 2010: 730 records\n",
            "    Year 2011: 730 records\n",
            "    Year 2012: 732 records\n",
            "    Year 2013: 730 records\n",
            "    Error fetching data for year 2014: HTTPSConnectionPool(host='www.ncdc.noaa.gov', port=443): Read timed out. (read timeout=30)\n",
            "    Year 2015: 730 records\n",
            "    Error fetching data for year 2016: HTTPSConnectionPool(host='www.ncdc.noaa.gov', port=443): Read timed out. (read timeout=30)\n",
            "    Year 2017: 1000 records\n",
            "    Year 2018: 1000 records\n",
            "    Year 2019: 1000 records\n",
            "    Year 2020: 991 records\n",
            "    Year 2021: 1000 records\n",
            "    Year 2022: 983 records\n",
            "    Year 2023: 923 records\n",
            "    Year 2024: 824 records\n",
            "  Raw NOAA data saved to: /content/climate_outputs/noaa/g49_noaa_raw_data.csv\n",
            "  Fetching E-OBS data for g49...\n",
            "    Creating synthetic E-OBS temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/eobs/g49_eobs_temperature.csv\n",
            "    Note: This is synthetic E-OBS temperature data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "    Creating synthetic E-OBS precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/eobs/g49_eobs_precipitation.csv\n",
            "    Note: This is synthetic E-OBS precipitation data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "\n",
            "Fetching data for site: g50 (69.879229, 20.27749204)\n",
            "  Fetching SeNorge data for g50...\n",
            "    Fetching SeNorge temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/senorge/g50_senorge_temperature.csv\n",
            "    Note: This is synthetic SeNorge temperature data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/senorge/g50_senorge_precipitation.csv\n",
            "    Note: This is synthetic SeNorge precipitation data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "    Fetching SeNorge snow depth data...\n",
            "    Snow depth data saved to: /content/climate_outputs/senorge/g50_senorge_snow_depth.csv\n",
            "    Note: This is synthetic SeNorge snow depth data for demonstration.\n",
            "    In a real scenario, you would fetch data from SeNorge's Thredds server.\n",
            "  Fetching NOAA data for g50...\n",
            "    Year 1970: No data found\n",
            "    Year 1971: No data found\n",
            "    Year 1972: No data found\n",
            "    Year 1973: No data found\n",
            "    Year 1974: No data found\n",
            "    Year 1975: No data found\n",
            "    Year 1976: No data found\n",
            "    Year 1977: No data found\n",
            "    Year 1978: No data found\n",
            "    Year 1979: No data found\n",
            "    Year 1980: No data found\n",
            "    Year 1981: No data found\n",
            "    Year 1982: No data found\n",
            "    Year 1983: No data found\n",
            "    Year 1984: No data found\n",
            "    Year 1985: No data found\n",
            "    Year 1986: No data found\n",
            "    Year 1987: No data found\n",
            "    Year 1988: No data found\n",
            "    Year 1989: No data found\n",
            "    Year 1990: No data found\n",
            "    Year 1991: No data found\n",
            "    Year 1992: No data found\n",
            "    Year 1993: No data found\n",
            "    Year 1994: No data found\n",
            "    Year 1995: No data found\n",
            "    Year 1996: No data found\n",
            "    Year 1997: No data found\n",
            "    Year 1998: No data found\n",
            "    Error fetching data for year 1999: HTTPSConnectionPool(host='www.ncdc.noaa.gov', port=443): Read timed out. (read timeout=30)\n",
            "    Year 2000: No data found\n",
            "    Year 2001: No data found\n",
            "    Year 2002: No data found\n",
            "    Year 2003: No data found\n",
            "    Year 2004: No data found\n",
            "    Year 2005: 238 records\n",
            "    Year 2006: 712 records\n",
            "    Year 2007: 730 records\n",
            "    Year 2008: 732 records\n",
            "    Year 2009: 730 records\n",
            "    Year 2010: 730 records\n",
            "    Year 2011: 730 records\n",
            "    Year 2012: 732 records\n",
            "    Year 2013: 730 records\n",
            "    Year 2014: 730 records\n",
            "    Year 2015: 730 records\n",
            "    Year 2016: 732 records\n",
            "    Year 2017: 730 records\n",
            "    Year 2018: 730 records\n",
            "    Error fetching data for year 2019: HTTPSConnectionPool(host='www.ncdc.noaa.gov', port=443): Read timed out. (read timeout=30)\n",
            "    Year 2020: 732 records\n",
            "    Year 2021: 730 records\n",
            "    Year 2022: 730 records\n",
            "    Year 2023: 730 records\n",
            "    Year 2024: 712 records\n",
            "  Raw NOAA data saved to: /content/climate_outputs/noaa/g50_noaa_raw_data.csv\n",
            "  Fetching E-OBS data for g50...\n",
            "    Creating synthetic E-OBS temperature data...\n",
            "    Temperature data saved to: /content/climate_outputs/eobs/g50_eobs_temperature.csv\n",
            "    Note: This is synthetic E-OBS temperature data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "    Creating synthetic E-OBS precipitation data...\n",
            "    Precipitation data saved to: /content/climate_outputs/eobs/g50_eobs_precipitation.csv\n",
            "    Note: This is synthetic E-OBS precipitation data for demonstration.\n",
            "    In a real scenario, you would download and process E-OBS netCDF files.\n",
            "\n",
            "Step 4: Integrating data from different sources\n",
            "\n",
            "Integrating data for g01...\n",
            "  Processing SeNorge temperature data...\n",
            "  Processing SeNorge precipitation data...\n",
            "  Processing SeNorge snow depth data...\n",
            "  Processing E-OBS temperature data...\n",
            "  Processing E-OBS precipitation data...\n",
            "  Creating combined temperature variable...\n",
            "  Temperature trend: 0.0020°C/year (p=0.0276, r²=0.0883)\n",
            "  Creating combined precipitation variable...\n",
            "  Precipitation trend: 0.03mm/year (p=0.8441, r²=0.0007)\n",
            "  Creating combined snow variable...\n",
            "\n",
            "Integrating data for g11...\n",
            "  Processing SeNorge temperature data...\n",
            "  Processing SeNorge precipitation data...\n",
            "  Processing SeNorge snow depth data...\n",
            "  Processing E-OBS temperature data...\n",
            "  Processing E-OBS precipitation data...\n",
            "  Creating combined temperature variable...\n",
            "  Temperature trend: -0.0005°C/year (p=0.5632, r²=0.0063)\n",
            "  Creating combined precipitation variable...\n",
            "  Precipitation trend: -0.01mm/year (p=0.9738, r²=0.0000)\n",
            "  Creating combined snow variable...\n",
            "\n",
            "Integrating data for g12...\n",
            "  Processing SeNorge temperature data...\n",
            "  Processing SeNorge precipitation data...\n",
            "  Processing SeNorge snow depth data...\n",
            "  Processing E-OBS temperature data...\n",
            "  Processing E-OBS precipitation data...\n",
            "  Creating combined temperature variable...\n",
            "  Temperature trend: -0.0011°C/year (p=0.2334, r²=0.0267)\n",
            "  Creating combined precipitation variable...\n",
            "  Precipitation trend: 0.01mm/year (p=0.9665, r²=0.0000)\n",
            "  Creating combined snow variable...\n",
            "\n",
            "Integrating data for g13...\n",
            "  Processing SeNorge temperature data...\n",
            "  Processing SeNorge precipitation data...\n",
            "  Processing SeNorge snow depth data...\n",
            "  Processing E-OBS temperature data...\n",
            "  Processing E-OBS precipitation data...\n",
            "  Creating combined temperature variable...\n",
            "  Temperature trend: -0.0003°C/year (p=0.7112, r²=0.0026)\n",
            "  Creating combined precipitation variable...\n",
            "  Precipitation trend: 0.17mm/year (p=0.3363, r²=0.0175)\n",
            "  Creating combined snow variable...\n",
            "\n",
            "Integrating data for g19...\n",
            "  Processing SeNorge temperature data...\n",
            "  Processing SeNorge precipitation data...\n",
            "  Processing SeNorge snow depth data...\n",
            "  Processing NOAA precipitation data...\n",
            "  Processing E-OBS temperature data...\n",
            "  Processing E-OBS precipitation data...\n",
            "  Creating combined temperature variable...\n",
            "  Temperature trend: 0.0004°C/year (p=0.5901, r²=0.0055)\n",
            "  Creating combined precipitation variable...\n",
            "  Precipitation trend: 0.16mm/year (p=0.3046, r²=0.0199)\n",
            "  Creating combined snow variable...\n",
            "\n",
            "Integrating data for g20...\n",
            "  Processing SeNorge temperature data...\n",
            "  Processing SeNorge precipitation data...\n",
            "  Processing SeNorge snow depth data...\n",
            "  Processing E-OBS temperature data...\n",
            "  Processing E-OBS precipitation data...\n",
            "  Creating combined temperature variable...\n",
            "  Temperature trend: 0.0006°C/year (p=0.5290, r²=0.0075)\n",
            "  Creating combined precipitation variable...\n",
            "  Precipitation trend: 0.01mm/year (p=0.9487, r²=0.0001)\n",
            "  Creating combined snow variable...\n",
            "\n",
            "Integrating data for g23...\n",
            "  Processing SeNorge temperature data...\n",
            "  Processing SeNorge precipitation data...\n",
            "  Processing SeNorge snow depth data...\n",
            "  Processing E-OBS temperature data...\n",
            "  Processing E-OBS precipitation data...\n",
            "  Creating combined temperature variable...\n",
            "  Temperature trend: 0.0004°C/year (p=0.5849, r²=0.0057)\n",
            "  Creating combined precipitation variable...\n",
            "  Precipitation trend: -0.07mm/year (p=0.7067, r²=0.0027)\n",
            "  Creating combined snow variable...\n",
            "\n",
            "Integrating data for g25...\n",
            "  Processing SeNorge temperature data...\n",
            "  Processing SeNorge precipitation data...\n",
            "  Processing SeNorge snow depth data...\n",
            "  Processing E-OBS temperature data...\n",
            "  Processing E-OBS precipitation data...\n",
            "  Creating combined temperature variable...\n",
            "  Temperature trend: -0.0000°C/year (p=0.9962, r²=0.0000)\n",
            "  Creating combined precipitation variable...\n",
            "  Precipitation trend: -0.12mm/year (p=0.4585, r²=0.0104)\n",
            "  Creating combined snow variable...\n",
            "\n",
            "Integrating data for g26...\n",
            "  Processing SeNorge temperature data...\n",
            "  Processing SeNorge precipitation data...\n",
            "  Processing SeNorge snow depth data...\n",
            "  Processing NOAA precipitation data...\n",
            "  Processing E-OBS temperature data...\n",
            "  Processing E-OBS precipitation data...\n",
            "  Creating combined temperature variable...\n",
            "  Temperature trend: -0.0002°C/year (p=0.8045, r²=0.0012)\n",
            "  Creating combined precipitation variable...\n",
            "  Precipitation trend: 0.04mm/year (p=0.8229, r²=0.0010)\n",
            "  Creating combined snow variable...\n",
            "\n",
            "Integrating data for g30...\n",
            "  Processing SeNorge temperature data...\n",
            "  Processing SeNorge precipitation data...\n",
            "  Processing SeNorge snow depth data...\n",
            "  Processing NOAA maximum temperature data...\n",
            "  Processing NOAA minimum temperature data...\n",
            "  Processing NOAA precipitation data...\n",
            "  Processing E-OBS temperature data...\n",
            "  Processing E-OBS precipitation data...\n",
            "  Creating combined temperature variable...\n",
            "  Temperature trend: -0.0006°C/year (p=0.5471, r²=0.0069)\n",
            "  Creating combined precipitation variable...\n",
            "  Precipitation trend: -0.24mm/year (p=0.1232, r²=0.0442)\n",
            "  Creating combined snow variable...\n",
            "\n",
            "Integrating data for g35...\n",
            "  Processing SeNorge temperature data...\n",
            "  Processing SeNorge precipitation data...\n",
            "  Processing SeNorge snow depth data...\n",
            "  Processing NOAA precipitation data...\n",
            "  Processing E-OBS temperature data...\n",
            "  Processing E-OBS precipitation data...\n",
            "  Creating combined temperature variable...\n",
            "  Temperature trend: -0.0006°C/year (p=0.4842, r²=0.0093)\n",
            "  Creating combined precipitation variable...\n",
            "  Precipitation trend: 0.06mm/year (p=0.7218, r²=0.0024)\n",
            "  Creating combined snow variable...\n",
            "\n",
            "Integrating data for g36...\n",
            "  Processing SeNorge temperature data...\n",
            "  Processing SeNorge precipitation data...\n",
            "  Processing SeNorge snow depth data...\n",
            "  Processing NOAA maximum temperature data...\n",
            "  Processing NOAA minimum temperature data...\n",
            "  Processing NOAA precipitation data...\n",
            "  Processing E-OBS temperature data...\n",
            "  Processing E-OBS precipitation data...\n",
            "  Creating combined temperature variable...\n",
            "  Temperature trend: 0.0006°C/year (p=0.4623, r²=0.0102)\n",
            "  Creating combined precipitation variable...\n",
            "  Precipitation trend: 0.20mm/year (p=0.2477, r²=0.0251)\n",
            "  Creating combined snow variable...\n",
            "\n",
            "Integrating data for g37...\n",
            "  Processing SeNorge temperature data...\n",
            "  Processing SeNorge precipitation data...\n",
            "  Processing SeNorge snow depth data...\n",
            "  Processing NOAA precipitation data...\n",
            "  Processing E-OBS temperature data...\n",
            "  Processing E-OBS precipitation data...\n",
            "  Creating combined temperature variable...\n",
            "  Temperature trend: -0.0009°C/year (p=0.2734, r²=0.0226)\n",
            "  Creating combined precipitation variable...\n",
            "  Precipitation trend: -0.26mm/year (p=0.1051, r²=0.0488)\n",
            "  Creating combined snow variable...\n",
            "\n",
            "Integrating data for g39...\n",
            "  Processing SeNorge temperature data...\n",
            "  Processing SeNorge precipitation data...\n",
            "  Processing SeNorge snow depth data...\n",
            "  Processing NOAA maximum temperature data...\n",
            "  Processing NOAA minimum temperature data...\n",
            "  Processing NOAA precipitation data...\n",
            "  Processing E-OBS temperature data...\n",
            "  Processing E-OBS precipitation data...\n",
            "  Creating combined temperature variable...\n",
            "  Temperature trend: -0.0001°C/year (p=0.9249, r²=0.0002)\n",
            "  Creating combined precipitation variable...\n",
            "  Precipitation trend: 0.08mm/year (p=0.6407, r²=0.0041)\n",
            "  Creating combined snow variable...\n",
            "\n",
            "Integrating data for g40...\n",
            "  Processing SeNorge temperature data...\n",
            "  Processing SeNorge precipitation data...\n",
            "  Processing SeNorge snow depth data...\n",
            "  Processing E-OBS temperature data...\n",
            "  Processing E-OBS precipitation data...\n",
            "  Creating combined temperature variable...\n",
            "  Temperature trend: 0.0008°C/year (p=0.4546, r²=0.0106)\n",
            "  Creating combined precipitation variable...\n",
            "  Precipitation trend: 0.10mm/year (p=0.4984, r²=0.0087)\n",
            "  Creating combined snow variable...\n",
            "\n",
            "Integrating data for g42...\n",
            "  Processing SeNorge temperature data...\n",
            "  Processing SeNorge precipitation data...\n",
            "  Processing SeNorge snow depth data...\n",
            "  Processing NOAA precipitation data...\n",
            "  Processing E-OBS temperature data...\n",
            "  Processing E-OBS precipitation data...\n",
            "  Creating combined temperature variable...\n",
            "  Temperature trend: 0.0002°C/year (p=0.8076, r²=0.0011)\n",
            "  Creating combined precipitation variable...\n",
            "  Precipitation trend: 0.10mm/year (p=0.4970, r²=0.0087)\n",
            "  Creating combined snow variable...\n",
            "\n",
            "Integrating data for g44...\n",
            "  Processing SeNorge temperature data...\n",
            "  Processing SeNorge precipitation data...\n",
            "  Processing SeNorge snow depth data...\n",
            "  Processing E-OBS temperature data...\n",
            "  Processing E-OBS precipitation data...\n",
            "  Creating combined temperature variable...\n",
            "  Temperature trend: -0.0002°C/year (p=0.7806, r²=0.0015)\n",
            "  Creating combined precipitation variable...\n",
            "  Precipitation trend: -0.14mm/year (p=0.3476, r²=0.0167)\n",
            "  Creating combined snow variable...\n",
            "\n",
            "Integrating data for g46...\n",
            "  Processing SeNorge temperature data...\n",
            "  Processing SeNorge precipitation data...\n",
            "  Processing SeNorge snow depth data...\n",
            "  Processing NOAA precipitation data...\n",
            "  Processing E-OBS temperature data...\n",
            "  Processing E-OBS precipitation data...\n",
            "  Creating combined temperature variable...\n",
            "  Temperature trend: 0.0010°C/year (p=0.2475, r²=0.0251)\n",
            "  Creating combined precipitation variable...\n",
            "  Precipitation trend: -0.05mm/year (p=0.7464, r²=0.0020)\n",
            "  Creating combined snow variable...\n",
            "\n",
            "Integrating data for g49...\n",
            "  Processing SeNorge temperature data...\n",
            "  Processing SeNorge precipitation data...\n",
            "  Processing SeNorge snow depth data...\n",
            "  Processing NOAA maximum temperature data...\n",
            "  Processing NOAA minimum temperature data...\n",
            "  Processing NOAA precipitation data...\n",
            "  Processing E-OBS temperature data...\n",
            "  Processing E-OBS precipitation data...\n",
            "  Creating combined temperature variable...\n",
            "  Temperature trend: -0.0009°C/year (p=0.2938, r²=0.0208)\n",
            "  Creating combined precipitation variable...\n",
            "  Precipitation trend: -0.07mm/year (p=0.6881, r²=0.0031)\n",
            "  Creating combined snow variable...\n",
            "\n",
            "Integrating data for g50...\n",
            "  Processing SeNorge temperature data...\n",
            "  Processing SeNorge precipitation data...\n",
            "  Processing SeNorge snow depth data...\n",
            "  Processing NOAA maximum temperature data...\n",
            "  Processing NOAA minimum temperature data...\n",
            "  Processing E-OBS temperature data...\n",
            "  Processing E-OBS precipitation data...\n",
            "  Creating combined temperature variable...\n",
            "  Temperature trend: -0.0008°C/year (p=0.3521, r²=0.0164)\n",
            "  Creating combined precipitation variable...\n",
            "  Precipitation trend: 0.19mm/year (p=0.2750, r²=0.0224)\n",
            "  Creating combined snow variable...\n",
            "\n",
            "Step 5: Exporting and visualizing the integrated data\n",
            "\n",
            "===== Exporting Integrated Data for g01 =====\n",
            "Metadata saved to: /content/climate_outputs/integrated/g01/metadata.json\n",
            "Temperature data saved to: /content/climate_outputs/integrated/g01/temperature.csv\n",
            "Temperature plot saved to: /content/climate_outputs/plots/g01/temperature_trend.png\n",
            "Precipitation data saved to: /content/climate_outputs/integrated/g01/precipitation.csv\n",
            "Precipitation plot saved to: /content/climate_outputs/plots/g01/precipitation_trend.png\n",
            "Snow data saved to: /content/climate_outputs/integrated/g01/snow.csv\n",
            "Creating comprehensive dataset for g01...\n",
            "Comprehensive climate data saved to: /content/climate_outputs/integrated/g01/comprehensive_climate_data.csv\n",
            "\n",
            "===== Exporting Integrated Data for g11 =====\n",
            "Metadata saved to: /content/climate_outputs/integrated/g11/metadata.json\n",
            "Temperature data saved to: /content/climate_outputs/integrated/g11/temperature.csv\n",
            "Temperature plot saved to: /content/climate_outputs/plots/g11/temperature_trend.png\n",
            "Precipitation data saved to: /content/climate_outputs/integrated/g11/precipitation.csv\n",
            "Precipitation plot saved to: /content/climate_outputs/plots/g11/precipitation_trend.png\n",
            "Snow data saved to: /content/climate_outputs/integrated/g11/snow.csv\n",
            "Creating comprehensive dataset for g11...\n",
            "Comprehensive climate data saved to: /content/climate_outputs/integrated/g11/comprehensive_climate_data.csv\n",
            "\n",
            "===== Exporting Integrated Data for g12 =====\n",
            "Metadata saved to: /content/climate_outputs/integrated/g12/metadata.json\n",
            "Temperature data saved to: /content/climate_outputs/integrated/g12/temperature.csv\n",
            "Temperature plot saved to: /content/climate_outputs/plots/g12/temperature_trend.png\n",
            "Precipitation data saved to: /content/climate_outputs/integrated/g12/precipitation.csv\n",
            "Precipitation plot saved to: /content/climate_outputs/plots/g12/precipitation_trend.png\n",
            "Snow data saved to: /content/climate_outputs/integrated/g12/snow.csv\n",
            "Creating comprehensive dataset for g12...\n",
            "Comprehensive climate data saved to: /content/climate_outputs/integrated/g12/comprehensive_climate_data.csv\n",
            "\n",
            "===== Exporting Integrated Data for g13 =====\n",
            "Metadata saved to: /content/climate_outputs/integrated/g13/metadata.json\n",
            "Temperature data saved to: /content/climate_outputs/integrated/g13/temperature.csv\n",
            "Temperature plot saved to: /content/climate_outputs/plots/g13/temperature_trend.png\n",
            "Precipitation data saved to: /content/climate_outputs/integrated/g13/precipitation.csv\n",
            "Precipitation plot saved to: /content/climate_outputs/plots/g13/precipitation_trend.png\n",
            "Snow data saved to: /content/climate_outputs/integrated/g13/snow.csv\n",
            "Creating comprehensive dataset for g13...\n",
            "Comprehensive climate data saved to: /content/climate_outputs/integrated/g13/comprehensive_climate_data.csv\n",
            "\n",
            "===== Exporting Integrated Data for g19 =====\n",
            "Metadata saved to: /content/climate_outputs/integrated/g19/metadata.json\n",
            "Temperature data saved to: /content/climate_outputs/integrated/g19/temperature.csv\n",
            "Temperature plot saved to: /content/climate_outputs/plots/g19/temperature_trend.png\n",
            "Precipitation data saved to: /content/climate_outputs/integrated/g19/precipitation.csv\n",
            "Precipitation plot saved to: /content/climate_outputs/plots/g19/precipitation_trend.png\n",
            "Snow data saved to: /content/climate_outputs/integrated/g19/snow.csv\n",
            "Creating comprehensive dataset for g19...\n",
            "Comprehensive climate data saved to: /content/climate_outputs/integrated/g19/comprehensive_climate_data.csv\n",
            "\n",
            "===== Exporting Integrated Data for g20 =====\n",
            "Metadata saved to: /content/climate_outputs/integrated/g20/metadata.json\n",
            "Temperature data saved to: /content/climate_outputs/integrated/g20/temperature.csv\n",
            "Temperature plot saved to: /content/climate_outputs/plots/g20/temperature_trend.png\n",
            "Precipitation data saved to: /content/climate_outputs/integrated/g20/precipitation.csv\n",
            "Precipitation plot saved to: /content/climate_outputs/plots/g20/precipitation_trend.png\n",
            "Snow data saved to: /content/climate_outputs/integrated/g20/snow.csv\n",
            "Creating comprehensive dataset for g20...\n",
            "Comprehensive climate data saved to: /content/climate_outputs/integrated/g20/comprehensive_climate_data.csv\n",
            "\n",
            "===== Exporting Integrated Data for g23 =====\n",
            "Metadata saved to: /content/climate_outputs/integrated/g23/metadata.json\n",
            "Temperature data saved to: /content/climate_outputs/integrated/g23/temperature.csv\n",
            "Temperature plot saved to: /content/climate_outputs/plots/g23/temperature_trend.png\n",
            "Precipitation data saved to: /content/climate_outputs/integrated/g23/precipitation.csv\n",
            "Precipitation plot saved to: /content/climate_outputs/plots/g23/precipitation_trend.png\n",
            "Snow data saved to: /content/climate_outputs/integrated/g23/snow.csv\n",
            "Creating comprehensive dataset for g23...\n",
            "Comprehensive climate data saved to: /content/climate_outputs/integrated/g23/comprehensive_climate_data.csv\n",
            "\n",
            "===== Exporting Integrated Data for g25 =====\n",
            "Metadata saved to: /content/climate_outputs/integrated/g25/metadata.json\n",
            "Temperature data saved to: /content/climate_outputs/integrated/g25/temperature.csv\n",
            "Temperature plot saved to: /content/climate_outputs/plots/g25/temperature_trend.png\n",
            "Precipitation data saved to: /content/climate_outputs/integrated/g25/precipitation.csv\n",
            "Precipitation plot saved to: /content/climate_outputs/plots/g25/precipitation_trend.png\n",
            "Snow data saved to: /content/climate_outputs/integrated/g25/snow.csv\n",
            "Creating comprehensive dataset for g25...\n",
            "Comprehensive climate data saved to: /content/climate_outputs/integrated/g25/comprehensive_climate_data.csv\n",
            "\n",
            "===== Exporting Integrated Data for g26 =====\n",
            "Metadata saved to: /content/climate_outputs/integrated/g26/metadata.json\n",
            "Temperature data saved to: /content/climate_outputs/integrated/g26/temperature.csv\n",
            "Temperature plot saved to: /content/climate_outputs/plots/g26/temperature_trend.png\n",
            "Precipitation data saved to: /content/climate_outputs/integrated/g26/precipitation.csv\n",
            "Precipitation plot saved to: /content/climate_outputs/plots/g26/precipitation_trend.png\n",
            "Snow data saved to: /content/climate_outputs/integrated/g26/snow.csv\n",
            "Creating comprehensive dataset for g26...\n",
            "Comprehensive climate data saved to: /content/climate_outputs/integrated/g26/comprehensive_climate_data.csv\n",
            "\n",
            "===== Exporting Integrated Data for g30 =====\n",
            "Metadata saved to: /content/climate_outputs/integrated/g30/metadata.json\n",
            "Temperature data saved to: /content/climate_outputs/integrated/g30/temperature.csv\n",
            "Temperature plot saved to: /content/climate_outputs/plots/g30/temperature_trend.png\n",
            "Precipitation data saved to: /content/climate_outputs/integrated/g30/precipitation.csv\n",
            "Precipitation plot saved to: /content/climate_outputs/plots/g30/precipitation_trend.png\n",
            "Snow data saved to: /content/climate_outputs/integrated/g30/snow.csv\n",
            "Creating comprehensive dataset for g30...\n",
            "Comprehensive climate data saved to: /content/climate_outputs/integrated/g30/comprehensive_climate_data.csv\n",
            "\n",
            "===== Exporting Integrated Data for g35 =====\n",
            "Metadata saved to: /content/climate_outputs/integrated/g35/metadata.json\n",
            "Temperature data saved to: /content/climate_outputs/integrated/g35/temperature.csv\n",
            "Temperature plot saved to: /content/climate_outputs/plots/g35/temperature_trend.png\n",
            "Precipitation data saved to: /content/climate_outputs/integrated/g35/precipitation.csv\n",
            "Precipitation plot saved to: /content/climate_outputs/plots/g35/precipitation_trend.png\n",
            "Snow data saved to: /content/climate_outputs/integrated/g35/snow.csv\n",
            "Creating comprehensive dataset for g35...\n",
            "Comprehensive climate data saved to: /content/climate_outputs/integrated/g35/comprehensive_climate_data.csv\n",
            "\n",
            "===== Exporting Integrated Data for g36 =====\n",
            "Metadata saved to: /content/climate_outputs/integrated/g36/metadata.json\n",
            "Temperature data saved to: /content/climate_outputs/integrated/g36/temperature.csv\n",
            "Temperature plot saved to: /content/climate_outputs/plots/g36/temperature_trend.png\n",
            "Precipitation data saved to: /content/climate_outputs/integrated/g36/precipitation.csv\n",
            "Precipitation plot saved to: /content/climate_outputs/plots/g36/precipitation_trend.png\n",
            "Snow data saved to: /content/climate_outputs/integrated/g36/snow.csv\n",
            "Creating comprehensive dataset for g36...\n",
            "Comprehensive climate data saved to: /content/climate_outputs/integrated/g36/comprehensive_climate_data.csv\n",
            "\n",
            "===== Exporting Integrated Data for g37 =====\n",
            "Metadata saved to: /content/climate_outputs/integrated/g37/metadata.json\n",
            "Temperature data saved to: /content/climate_outputs/integrated/g37/temperature.csv\n",
            "Temperature plot saved to: /content/climate_outputs/plots/g37/temperature_trend.png\n",
            "Precipitation data saved to: /content/climate_outputs/integrated/g37/precipitation.csv\n",
            "Precipitation plot saved to: /content/climate_outputs/plots/g37/precipitation_trend.png\n",
            "Snow data saved to: /content/climate_outputs/integrated/g37/snow.csv\n",
            "Creating comprehensive dataset for g37...\n",
            "Comprehensive climate data saved to: /content/climate_outputs/integrated/g37/comprehensive_climate_data.csv\n",
            "\n",
            "===== Exporting Integrated Data for g39 =====\n",
            "Metadata saved to: /content/climate_outputs/integrated/g39/metadata.json\n",
            "Temperature data saved to: /content/climate_outputs/integrated/g39/temperature.csv\n",
            "Temperature plot saved to: /content/climate_outputs/plots/g39/temperature_trend.png\n",
            "Precipitation data saved to: /content/climate_outputs/integrated/g39/precipitation.csv\n",
            "Precipitation plot saved to: /content/climate_outputs/plots/g39/precipitation_trend.png\n",
            "Snow data saved to: /content/climate_outputs/integrated/g39/snow.csv\n",
            "Creating comprehensive dataset for g39...\n",
            "Comprehensive climate data saved to: /content/climate_outputs/integrated/g39/comprehensive_climate_data.csv\n",
            "\n",
            "===== Exporting Integrated Data for g40 =====\n",
            "Metadata saved to: /content/climate_outputs/integrated/g40/metadata.json\n",
            "Temperature data saved to: /content/climate_outputs/integrated/g40/temperature.csv\n",
            "Temperature plot saved to: /content/climate_outputs/plots/g40/temperature_trend.png\n",
            "Precipitation data saved to: /content/climate_outputs/integrated/g40/precipitation.csv\n",
            "Precipitation plot saved to: /content/climate_outputs/plots/g40/precipitation_trend.png\n",
            "Snow data saved to: /content/climate_outputs/integrated/g40/snow.csv\n",
            "Creating comprehensive dataset for g40...\n",
            "Comprehensive climate data saved to: /content/climate_outputs/integrated/g40/comprehensive_climate_data.csv\n",
            "\n",
            "===== Exporting Integrated Data for g42 =====\n",
            "Metadata saved to: /content/climate_outputs/integrated/g42/metadata.json\n",
            "Temperature data saved to: /content/climate_outputs/integrated/g42/temperature.csv\n",
            "Temperature plot saved to: /content/climate_outputs/plots/g42/temperature_trend.png\n",
            "Precipitation data saved to: /content/climate_outputs/integrated/g42/precipitation.csv\n",
            "Precipitation plot saved to: /content/climate_outputs/plots/g42/precipitation_trend.png\n",
            "Snow data saved to: /content/climate_outputs/integrated/g42/snow.csv\n",
            "Creating comprehensive dataset for g42...\n",
            "Comprehensive climate data saved to: /content/climate_outputs/integrated/g42/comprehensive_climate_data.csv\n",
            "\n",
            "===== Exporting Integrated Data for g44 =====\n",
            "Metadata saved to: /content/climate_outputs/integrated/g44/metadata.json\n",
            "Temperature data saved to: /content/climate_outputs/integrated/g44/temperature.csv\n",
            "Temperature plot saved to: /content/climate_outputs/plots/g44/temperature_trend.png\n",
            "Precipitation data saved to: /content/climate_outputs/integrated/g44/precipitation.csv\n",
            "Precipitation plot saved to: /content/climate_outputs/plots/g44/precipitation_trend.png\n",
            "Snow data saved to: /content/climate_outputs/integrated/g44/snow.csv\n",
            "Creating comprehensive dataset for g44...\n",
            "Comprehensive climate data saved to: /content/climate_outputs/integrated/g44/comprehensive_climate_data.csv\n",
            "\n",
            "===== Exporting Integrated Data for g46 =====\n",
            "Metadata saved to: /content/climate_outputs/integrated/g46/metadata.json\n",
            "Temperature data saved to: /content/climate_outputs/integrated/g46/temperature.csv\n",
            "Temperature plot saved to: /content/climate_outputs/plots/g46/temperature_trend.png\n",
            "Precipitation data saved to: /content/climate_outputs/integrated/g46/precipitation.csv\n",
            "Precipitation plot saved to: /content/climate_outputs/plots/g46/precipitation_trend.png\n",
            "Snow data saved to: /content/climate_outputs/integrated/g46/snow.csv\n",
            "Creating comprehensive dataset for g46...\n",
            "Comprehensive climate data saved to: /content/climate_outputs/integrated/g46/comprehensive_climate_data.csv\n",
            "\n",
            "===== Exporting Integrated Data for g49 =====\n",
            "Metadata saved to: /content/climate_outputs/integrated/g49/metadata.json\n",
            "Temperature data saved to: /content/climate_outputs/integrated/g49/temperature.csv\n",
            "Temperature plot saved to: /content/climate_outputs/plots/g49/temperature_trend.png\n",
            "Precipitation data saved to: /content/climate_outputs/integrated/g49/precipitation.csv\n",
            "Precipitation plot saved to: /content/climate_outputs/plots/g49/precipitation_trend.png\n",
            "Snow data saved to: /content/climate_outputs/integrated/g49/snow.csv\n",
            "Creating comprehensive dataset for g49...\n",
            "Comprehensive climate data saved to: /content/climate_outputs/integrated/g49/comprehensive_climate_data.csv\n",
            "\n",
            "===== Exporting Integrated Data for g50 =====\n",
            "Metadata saved to: /content/climate_outputs/integrated/g50/metadata.json\n",
            "Temperature data saved to: /content/climate_outputs/integrated/g50/temperature.csv\n",
            "Temperature plot saved to: /content/climate_outputs/plots/g50/temperature_trend.png\n",
            "Precipitation data saved to: /content/climate_outputs/integrated/g50/precipitation.csv\n",
            "Precipitation plot saved to: /content/climate_outputs/plots/g50/precipitation_trend.png\n",
            "Snow data saved to: /content/climate_outputs/integrated/g50/snow.csv\n",
            "Creating comprehensive dataset for g50...\n",
            "Comprehensive climate data saved to: /content/climate_outputs/integrated/g50/comprehensive_climate_data.csv\n",
            "\n",
            "===== ANALYSIS COMPLETE =====\n",
            "All results saved to: /content/climate_outputs\n",
            "\n",
            "Creating zip file for download...\n",
            "Creating zip file of all outputs for download: climate_data_outputs.zip\n",
            "Zip file created: climate_data_outputs.zip\n",
            "\n",
            "Analysis complete!\n",
            "\n",
            "To download all results as a zip file, run:\n",
            "from google.colab import files\n",
            "files.download('climate_data_outputs.zip')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('climate_data_outputs.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "CCE_qtAmeNRr",
        "outputId": "1f50fb16-93db-4ef9-8fc6-48640f4cc3db"
      },
      "id": "CCE_qtAmeNRr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_59eaebd5-0a4e-43a0-bc73-710149b05546\", \"climate_data_outputs.zip\", 105337102)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}